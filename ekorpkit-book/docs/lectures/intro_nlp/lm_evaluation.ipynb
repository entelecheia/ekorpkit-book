{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {},
   "source": [
    "# Language Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {},
   "source": [
    "## Language Model\n",
    "\n",
    "A language model is a model that predicts the next word in a sequence of words. For example, given the sentence \"I like to eat\", a language model can predict the next word \"apples\" with high probability.\n",
    "\n",
    "- A language model assigns a probability to a sequence of words.\n",
    "- It predicts the next word $w$ given the previous words $w_1, \\ldots, w_{n-1}$.\n",
    "- Given the sentence `I like to eat`, the probability of the next word `apples` is higher than the probability of the next word `pencils`. In a mathematical notation, we can write this as:\n",
    "\n",
    "    $$\n",
    "    P(\\text{apples} \\mid \\text{I like to eat}) > P(\\text{pencils} \\mid \\text{I like to eat})\n",
    "    $$\n",
    "    \n",
    "- A unigram model only depends on the current word $w_n$:\n",
    "\n",
    "    $$\n",
    "    P(w_n \\mid w_1, \\ldots, w_{n-1}) = P(w_n)\n",
    "    $$\n",
    "\n",
    "- The probability of a sequence of words is the product of the probabilities of the individual words:\n",
    "\n",
    "    $$\n",
    "    P(\\text{I like to eat apples}) = P(\\text{I}) \\times P(\\text{like}) \\times P(\\text{to}) \\times P(\\text{eat}) \\times P(\\text{apples})\n",
    "    $$\n",
    "\n",
    "- An n-gram model looks back at the previous $n-1$ words:\n",
    "\n",
    "    $$\n",
    "    P(w_n \\mid w_1, \\ldots, w_{n-1}) = P(w_n \\mid w_{n-1}, \\ldots, w_{n-n+1})\n",
    "    $$\n",
    "\n",
    "- The probability of a sequence of words $W$ in an n-gram model is the product of the probabilities of the individual words:\n",
    "\n",
    "    $$\n",
    "    P(W) = \\prod_{i=1}^N P(w_i \\mid w_{i-1}, \\ldots, w_{i-n+1})\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d0ae24",
   "metadata": {},
   "source": [
    "## Evaluation of Language Models\n",
    "\n",
    "There are two main ways to evaluate language models:\n",
    "\n",
    "**Extrinsic evaluation**\n",
    "  - Evaluate the language model on a downstream task such as machine translation.\n",
    "  - This is the best way to evaluate a language model as it is the most realistic evaluation.\n",
    "  - This requires a full pipeline from the language model to the downstream task.\n",
    "  - The GLUE benchmark score is one example of broader, multi-task evaluation for language models.\n",
    "\n",
    "**Intrinsic evaluation**\n",
    "  - Intrinsic evaluation uses intricsic metrics to evaluate the language model itself.\n",
    "  - This is easier to do as it does not require a downstream task.\n",
    "  - Intrinsic evaluation is not as realistic as extrinsic evaluation.\n",
    "  - Metrics such as perplexity and cross-entropy fit into this category.\n",
    "  - Unlike metrics such as accuracy, perplexity and cross-entropy are not directly interpretable.\n",
    "  - While 90% accuracy is superior to 80% accuracy regardless of the model, comparing perplexity values is not as straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b892b60",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf)\n",
    "- [Evaluation Metrics for Language Modeling](https://thegradient.pub/understanding-evaluation-metrics-for-language-models)\n",
    "- [Perplexity in Language Models](https://towardsdatascience.com/perplexity-in-language-models-87a196019a94)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
