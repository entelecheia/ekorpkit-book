{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "[On Transformers, TimeSformers, And Attention](https://www.topbots.com/transformers-timesformers-and-attention/)\n",
    "\n",
    "![](../figs/deep_nlp/transformers/entelecheia_transformers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {},
   "source": [
    "Transformers are a very powerful Deep Learning model that has been able to become a standard in many Natural Language Processing tasks and is poised to revolutionize the field of Computer Vision as well.\n",
    "\n",
    "- Google Brain published the paper \"Attention Is All You Need\" in 2017 {cite}`vaswani2017attention`.\n",
    "- The paper introduced the Transformer model, which is a deep learning model that is able to perform well on many NLP tasks.\n",
    "- The model is based on the idea of attention, which is a way of focusing on certain parts of the input.\n",
    "- The model is able to perform well on many NLP tasks, including machine translation, summarization, and question answering.\n",
    "- The model is also able to perform well on many other tasks, including image classification and speech recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dcc26",
   "metadata": {},
   "source": [
    "![](../figs/deep_nlp/transformers/transformers-history.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35611272",
   "metadata": {},
   "source": [
    "In 2020, Google Brain asks \"will they be as effective on images?\"\n",
    "\n",
    "- The paper \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" {cite}`dosovitskiy2020image` was published in 2020.\n",
    "- The model is able to perform well on many Computer Vision tasks, including image classification and object detection.\n",
    "\n",
    "At the beginning of 2021, Facebook researchers published a new version of the Transformers model, called TimeSformer.\n",
    "\n",
    "- The paper \"Is space-time attention all you need for video understanding?\" {cite}`bertasius2021space` was published in 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa86b577",
   "metadata": {},
   "source": [
    "## Why do we need transformers?\n",
    "\n",
    "What are the problems with the previous models?\n",
    "\n",
    "- The previous models were based on Recurrent Neural Networks (RNNs).\n",
    "- RNNs are able to process sequences of data, such as text or audio.\n",
    "- One of the main problems is its sequential operation.\n",
    "- The model needs to process the input sequentially, which means that it needs to process the first word, then the second word, and so on.\n",
    "- This sequential operation makes it difficult to parallelize the model.\n",
    "- There are also other problems such as gradient explosion, inability to detect dependencies between distant words in the same sentence, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1603f04",
   "metadata": {},
   "source": [
    " For example, to translate a sentence from English to Italian, with this type of networks, the first word of the sentence to be translated was passed into an encoder together with an initial state, and the next state was then passed into a second encoder with the second word of the sentence, and so on until the last word. The resulting state from the last encoder is then passed to a decoder that returns as output both the first translated word and a subsequent state, which is passed to another decoder, and so on.\n",
    "\n",
    " ![](../figs/deep_nlp/transformers/problem-rnn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7850332",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
