{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {},
   "source": [
    "# Transformers\n",
    "\n",
    "[On Transformers, TimeSformers, And Attention](https://www.topbots.com/transformers-timesformers-and-attention/)\n",
    "\n",
    "![](../figs/deep_nlp/transformers/entelecheia_transformers.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {},
   "source": [
    "Transformers are a very powerful Deep Learning model that has been able to become a standard in many Natural Language Processing tasks and is poised to revolutionize the field of Computer Vision as well.\n",
    "\n",
    "- Google Brain published the paper \"Attention Is All You Need\" in 2017 {cite}`vaswani2017attention`.\n",
    "- The paper introduced the Transformer model, which is a deep learning model that is able to perform well on many NLP tasks.\n",
    "- The model is based on the idea of attention, which is a way of focusing on certain parts of the input.\n",
    "- The model is able to perform well on many NLP tasks, including machine translation, summarization, and question answering.\n",
    "- The model is also able to perform well on many other tasks, including image classification and speech recognition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74dcc26",
   "metadata": {},
   "source": [
    "![](../figs/deep_nlp/transformers/transformers-history.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35611272",
   "metadata": {},
   "source": [
    "In 2020, Google Brain asks \"will they be as effective on images?\"\n",
    "\n",
    "- The paper \"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale\" {cite}`dosovitskiy2020image` was published in 2020.\n",
    "- The model is able to perform well on many Computer Vision tasks, including image classification and object detection.\n",
    "\n",
    "At the beginning of 2021, Facebook researchers published a new version of the Transformers model, called TimeSformer.\n",
    "\n",
    "- The paper \"Is space-time attention all you need for video understanding?\" {cite}`bertasius2021space` was published in 2021.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa86b577",
   "metadata": {},
   "source": [
    "## Why do we need transformers?\n",
    "\n",
    "What are the problems with the previous models?\n",
    "\n",
    "- The previous models were based on Recurrent Neural Networks (RNNs).\n",
    "- RNNs are able to process sequences of data, such as text or audio.\n",
    "- One of the main problems is its sequential operation.\n",
    "- The model needs to process the input sequentially, which means that it needs to process the first word, then the second word, and so on.\n",
    "- This sequential operation makes it difficult to parallelize the model.\n",
    "- There are also other problems such as gradient explosion, inability to detect dependencies between distant words in the same sentence, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1603f04",
   "metadata": {},
   "source": [
    " For example, to translate a sentence from English to Italian, with this type of networks, the first word of the sentence to be translated was passed into an encoder together with an initial state, and the next state was then passed into a second encoder with the second word of the sentence, and so on until the last word. The resulting state from the last encoder is then passed to a decoder that returns as output both the first translated word and a subsequent state, which is passed to another decoder, and so on.\n",
    "\n",
    " ![](../figs/deep_nlp/transformers/problem-rnn.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7850332",
   "metadata": {},
   "source": [
    "## Attention is all you need?\n",
    "\n",
    "Is there a mechanism that we can compute in a parallelized manner that allows us to extract the information we need from the sentence? \n",
    "\n",
    "![](../figs/deep_nlp/transformers/attention.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d56947",
   "metadata": {},
   "source": [
    "> `I gave my dog Charlie some food.`\n",
    "\n",
    "- Focusing on the word “gave,” what other words in the sentence should we pay attention on to add context to the word “gave”?\n",
    "- You might ask yourself, “Who gave the food to the dog?”\n",
    "- In this case, the attention mechanism would focus on the words “I.”\n",
    "- If you were to ask yourself, “To whom did I give the food?”\n",
    "- The attention mechanism would focus on the words “dog” and “Charlie.”\n",
    "- If you were to ask yourself, “What did I give to the dog?”\n",
    "- The attention mechanism would focus on the words “food.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934872e2",
   "metadata": {},
   "source": [
    "### How do we implement this attention mechanism?\n",
    "\n",
    "- To understand the computation of attention we can draw parallels to the world of databases.\n",
    "- When we do a search in the database we submit a query (Q) and we search among the available data for one or more keys that satisfy the query.\n",
    "- The keys are the words in the sentence and the query is the word we want to focus on.\n",
    "- The result of the search is the value of the key that satisfies the query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044f4f5",
   "metadata": {},
   "source": [
    "![](../figs/deep_nlp/transformers/attention-calculate.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc9f13",
   "metadata": {},
   "source": [
    "- We begin by looking at the sentence on which to compute attention as a set of vectors.\n",
    "- Each word, via a word embedding mechanism, is encoded into a vector K.\n",
    "- These vectors are the keys to search for with respect to a query.\n",
    "- A query is a vector Q that represents the word we want to focus on.\n",
    "- The query could be a word from the same sentence (self-attention) or a word from another sentence (cross-attention).\n",
    "- When then compute the similarity between the query Q and each of the available keys K.\n",
    "- The similarity is computed by multiplying the query Q by the transpose of the keys K.\n",
    "- The result of this operation is a vector of scores that represent the similarity between the query and each of the keys.\n",
    "- The scores are then normalized to obtain a probability distribution by applying the softmax function.\n",
    "- The result of the softmax function is a vector of probabilities that represent the attention weights.\n",
    "- The attention weights are then multiplied by the sentence vector, which is a vector of the same dimension as the keys, where each value represents the word in the sentence.\n",
    "- The result of this operation is a vector that represents the context of the word we want to focus on.\n",
    "- The context vector C is a vector of the same dimensionality as the keys K, where each element is a weighted sum of the keys K.\n",
    "- The context vector C is then passed to a linear layer, which is a fully connected layer, to obtain the final result of the attention mechanism.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a76a477",
   "metadata": {},
   "source": [
    "![](../figs/deep_nlp/transformers/attention-focus.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1350d4f5",
   "metadata": {},
   "source": [
    "- Each vector represents a word in the sentence.\n",
    "- The word we want to focus on is represented by the vector Q.\n",
    "- We then compute the similarity between the vector Q and each of the vectors in the sentence.\n",
    "- The similarity is computed by multiplying the vector Q by the vector of each word in the sentence.\n",
    "- The result of the multiplication is a scalar value that represents the similarity between the vector Q and the vector of the word in the sentence.\n",
    "- The scalar value is then passed through a softmax function, which normalizes the values between 0 and 1.\n",
    "- The result of the softmax function is the attention vector.\n",
    "- The attention vector is a vector of the same size as the sentence, where each value represents the attention that should be given to each word in the sentence.\n",
    "- The attention vector is then multiplied by the sentence vector, which is a vector of the same size as the sentence, where each value represents the word in the sentence.\n",
    "- The result of the multiplication is a vector of the same size as the sentence, where each value represents the weighted sum of the words in the sentence.\n",
    "- The weighted sum is then passed through a linear layer, which is a fully connected layer, to obtain the final result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e7468",
   "metadata": {},
   "source": [
    "### Multi-head attention\n",
    "\n",
    "This mechanism would be sufficient if we wanted to focus on a single word. However, we want to focus on from several points of view.\n",
    "\n",
    "- With a simliar mechanism, we can use multiple keys to focus on different words in the sentence.\n",
    "- The results are then concatenated to obtain a single, summarized vector of all the attention mechanisms.\n",
    "- This mechanism is called multi-head attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74d063",
   "metadata": {},
   "source": [
    "![](../figs/deep_nlp/transformers/attention-multihead.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a847d",
   "metadata": {},
   "source": [
    "## Tranformer Architecture\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21460df4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
