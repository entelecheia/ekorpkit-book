{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AESO0odcxhzs",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Measuring Document Similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T12:02:50.293005Z",
     "iopub.status.busy": "2023-02-04T12:02:50.292726Z",
     "iopub.status.idle": "2023-02-04T12:02:53.079486Z",
     "shell.execute_reply": "2023-02-04T12:02:53.078645Z",
     "shell.execute_reply.started": "2023-02-04T12:02:50.292985Z"
    },
    "id": "EJ0AoNl-xif_",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ekorpkit.hyfi.utils.logging:Set environment variable EKORPKIT_DATA_ROOT=/workspace/data\n",
      "INFO:ekorpkit.hyfi.utils.logging:Set environment variable CACHED_PATH_CACHE_ROOT=/workspace/.cache/cached_path\n",
      "INFO:ekorpkit.hyfi.utils.logging:Set environment variable WANDB_DIR=/workspace/projects/ekorpkit-book/exmaples/logs\n",
      "INFO:ekorpkit.hyfi.utils.logging:Set environment variable WANDB_PROJECT=ekorpkit-book-exmaples\n",
      "INFO:ekorpkit.hyfi.utils.logging:Set environment variable WANDB_NOTEBOOK_NAME=/workspace/projects/ekorpkit-book/exmaples/logs/esg-nb\n",
      "INFO:ekorpkit.hyfi.utils.logging:Set environment variable WANDB_SILENT=False\n",
      "INFO:ekorpkit.hyfi.utils.logging:Loaded .env from /workspace/projects/ekorpkit-book/config/.env\n",
      "INFO:ekorpkit.hyfi.utils.logging:initialized batcher with <ekorpkit.hyfi.utils.batch.batcher.Batcher object at 0x7f405c2ab520>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 0.1.40.post0.dev90\n",
      "project_dir: /workspace/projects/ekorpkit-book/exmaples\n",
      "time: 1.41 s (started: 2023-02-10 03:22:55 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from ekorpkit import eKonf\n",
    "\n",
    "if eKonf.is_colab():\n",
    "    eKonf.mount_google_drive()\n",
    "ws = eKonf.set_workspace(\n",
    "    workspace=\"/workspace\", \n",
    "    project=\"ekorpkit-book/exmaples\", \n",
    "    task=\"esg\", \n",
    "    log_level=\"INFO\",\n",
    "    verbose=True\n",
    ")\n",
    "print(\"version:\", ws.version)\n",
    "print(\"project_dir:\", ws.project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/projects/ekorpkit/ekorpkit\n",
      "/workspace/projects/ekorpkit/ekorpkit/hyfi\n",
      "time: 377 µs (started: 2023-02-10 03:23:01 +00:00)\n"
     ]
    }
   ],
   "source": [
    "print(eKonf.__ekorpkit_path__)\n",
    "print(eKonf.__hyfi_path__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data to predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-04T12:03:06.188123Z",
     "iopub.status.busy": "2023-02-04T12:03:06.187109Z",
     "iopub.status.idle": "2023-02-04T12:03:13.047506Z",
     "shell.execute_reply": "2023-02-04T12:03:13.046637Z",
     "shell.execute_reply.started": "2023-02-04T12:03:06.188091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>filename</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>◆ 2020 경제기상도 / 업종별 전망 (반도체) ◆ 지난해 미·중 무역분쟁과 공...</td>\n",
       "      <td>02100101.20200101040200001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>◆ 2020 경제기상도 / 업종별 전망 (가전) ◆ TV, 냉장고, 세탁기 등 전...</td>\n",
       "      <td>02100101.20200101040200002.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>066570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>◆ 2020 경제기상도 / 업종별 전망 (가전) ◆ TV, 냉장고, 세탁기 등 전...</td>\n",
       "      <td>02100101.20200101040200002.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>◆ 2020 경제기상도 / 업종별 전망 (디스플레이) ◆ 액정표시장치(LCD) 시...</td>\n",
       "      <td>02100101.20200101040201001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>034220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>디스플레이 업계 등에서는 삼성과 LG가 글로벌 디스플레이 시장에서 중국 업체의 L...</td>\n",
       "      <td>02100101.20200101040201001.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>003550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0   ◆ 2020 경제기상도 / 업종별 전망 (반도체) ◆ 지난해 미·중 무역분쟁과 공...   \n",
       "2   ◆ 2020 경제기상도 / 업종별 전망 (가전) ◆ TV, 냉장고, 세탁기 등 전...   \n",
       "3   ◆ 2020 경제기상도 / 업종별 전망 (가전) ◆ TV, 냉장고, 세탁기 등 전...   \n",
       "4   ◆ 2020 경제기상도 / 업종별 전망 (디스플레이) ◆ 액정표시장치(LCD) 시...   \n",
       "5   디스플레이 업계 등에서는 삼성과 LG가 글로벌 디스플레이 시장에서 중국 업체의 L...   \n",
       "\n",
       "                         filename  chunk_id   codes  \n",
       "0  02100101.20200101040200001.txt         0  000660  \n",
       "2  02100101.20200101040200002.txt         0  066570  \n",
       "3  02100101.20200101040200002.txt         0  005930  \n",
       "4  02100101.20200101040201001.txt         0  034220  \n",
       "5  02100101.20200101040201001.txt         1  003550  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.42 s (started: 2023-02-10 02:55:08 +00:00)\n"
     ]
    }
   ],
   "source": [
    "news_data_dir = ws.project_dir / \"esg/data/econ_news_kr/news_slice\"\n",
    "filename = \"esg_news_valid_20221229.parquet\"\n",
    "\n",
    "valid_data = eKonf.load_data(filename, news_data_dir)\n",
    "cols = [\"text\", \"filename\", \"chunk_id\", \"codes\"]\n",
    "valid_data[cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.1 ms (started: 2023-02-10 02:55:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "data = valid_data.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ekorpkit.preprocessors.tokenizer:Initializing mecab with {'userdic_path': '/workspace/projects/ekorpkit/ekorpkit/resources/dictionaries/mecab/ekon_v1.dic', 'backend': 'mecab-python3', 'verbose': True}...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:instantiating ekorpkit.preprocessors.normalizer.Normalizer...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:instantiating ekorpkit.preprocessors.stopwords.Stopwords...\n",
      "INFO:ekorpkit.hyfi.utils.logging:instantiating ekorpkit.preprocessors.stopwords.Stopwords ...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:MecabTokenizer initialized with:\n",
      "INFO:ekorpkit.preprocessors.tokenizer:\treturn_as_list: False\n",
      "INFO:ekorpkit.tokenizers.mecab:MeCab uses mecab-python3 as backend.\n",
      "INFO:ekorpkit.tokenizers.mecab:Mecab uses system dictionary: /opt/conda/lib/python3.8/site-packages/mecab_ko_dic/dicdir, user dictionary: /workspace/projects/ekorpkit/ekorpkit/resources/dictionaries/mecab/ekon_v1.dic\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.07 s (started: 2023-02-10 02:55:14 +00:00)\n"
     ]
    }
   ],
   "source": [
    "cfg_norm = eKonf.compose(\"preprocessor/normalizer=formal_ko\")\n",
    "cfg_mcb = eKonf.compose(\"preprocessor/tokenizer=mecab_econ\")\n",
    "cfg_mcb.normalize = cfg_norm\n",
    "mecab = eKonf.instantiate(cfg_mcb, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ekorpkit.hyfi.utils.logging:Applying pipe: functools.partial(<function tokenize at 0x7f20e743e940>)\n",
      "INFO:ekorpkit.pipelines.pipe:instantiating tokenizer\n",
      "INFO:ekorpkit.hyfi.utils.logging:instantiating ekorpkit.preprocessors.tokenizer.MecabTokenizer ...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:Initializing mecab with {'userdic_path': None, 'backend': 'mecab-python3', 'verbose': True}...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:instantiating ekorpkit.preprocessors.stopwords.Stopwords...\n",
      "INFO:ekorpkit.hyfi.utils.logging:instantiating ekorpkit.preprocessors.stopwords.Stopwords ...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:MecabTokenizer initialized with:\n",
      "INFO:ekorpkit.preprocessors.tokenizer:\treturn_as_list: False\n",
      "INFO:ekorpkit.tokenizers.mecab:MeCab uses mecab-python3 as backend.\n",
      "INFO:ekorpkit.tokenizers.mecab:Mecab uses system dictionary: /opt/conda/lib/python3.8/site-packages/mecab_ko_dic/dicdir, user dictionary: None\n",
      "INFO:ekorpkit.hyfi.utils.logging:Using batcher with minibatch size: 21\n",
      "INFO:ekorpkit.hyfi.utils.batch.batcher: backend: joblib  minibatch_size: 21  procs: 50  input_split: False  merge_output: True  len(data): 1000 len(args): 5\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0057353973388671875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Tokenizing column: text",
       "rate": null,
       "total": 48,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b27f758fcd4fdf8391def57919a03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing column: text:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ekorpkit.pipelines.pipe: >> elapsed time to segment: 0:00:03.707165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505565</th>\n",
       "      <td>02100851.20210520123331001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>에스/NNP 씨/NNB 디/NNG 가/JKS /SP 코스닥/NNG /SP 시장/NN...</td>\n",
       "      <td>042110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428505</th>\n",
       "      <td>02100311.20210218191853001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>지난해/NNG /SP 9/SN 월/NNBC 에/JKB 도/JX /SP 2/SN ,/...</td>\n",
       "      <td>012330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511819</th>\n",
       "      <td>02100201.20210401153611001.txt</td>\n",
       "      <td>2</td>\n",
       "      <td>오명훈/NNP /SP CFO/SL 는/JX /SP 2001/SN 년/NNBC /SP...</td>\n",
       "      <td>017670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697962</th>\n",
       "      <td>02100201.20211212103613001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[/SSO 머니/NNP 투데이/NNP /SP 변/XSN 휘/MAG /SP 기자/NN...</td>\n",
       "      <td>017670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191882</th>\n",
       "      <td>02100851.20200903183248001.txt</td>\n",
       "      <td>0</td>\n",
       "      <td>[/SSO 사진/NNG =/SY IBK/SL 기업/NNG 은행/NNG ]/SSC /...</td>\n",
       "      <td>024110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              filename  chunk_id  \\\n",
       "505565  02100851.20210520123331001.txt         0   \n",
       "428505  02100311.20210218191853001.txt         0   \n",
       "511819  02100201.20210401153611001.txt         2   \n",
       "697962  02100201.20211212103613001.txt         0   \n",
       "191882  02100851.20200903183248001.txt         0   \n",
       "\n",
       "                                                     text   codes  \n",
       "505565  에스/NNP 씨/NNB 디/NNG 가/JKS /SP 코스닥/NNG /SP 시장/NN...  042110  \n",
       "428505  지난해/NNG /SP 9/SN 월/NNBC 에/JKB 도/JX /SP 2/SN ,/...  012330  \n",
       "511819  오명훈/NNP /SP CFO/SL 는/JX /SP 2001/SN 년/NNBC /SP...  017670  \n",
       "697962  [/SSO 머니/NNP 투데이/NNP /SP 변/XSN 휘/MAG /SP 기자/NN...  017670  \n",
       "191882  [/SSO 사진/NNG =/SY IBK/SL 기업/NNG 은행/NNG ]/SSC /...  024110  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.03 s (started: 2023-02-10 02:55:15 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "\n",
    "cfg = eKonf.compose(\"pipeline/tokenize\")\n",
    "data = eKonf.pipe(data, cfg)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ekorpkit.hyfi.utils.logging:Applying pipe: functools.partial(<function extract_tokens at 0x7f20e743e9d0>)\n",
      "INFO:ekorpkit.pipelines.pipe:instantiating tokenizer\n",
      "INFO:ekorpkit.hyfi.utils.logging:instantiating ekorpkit.preprocessors.tokenizer.MecabTokenizer ...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:Initializing mecab with {'userdic_path': '/workspace/projects/ekorpkit/ekorpkit/resources/dictionaries/mecab/ekon_v1.dic', 'backend': 'mecab-python3', 'verbose': True}...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:instantiating ekorpkit.preprocessors.stopwords.Stopwords...\n",
      "INFO:ekorpkit.hyfi.utils.logging:instantiating ekorpkit.preprocessors.stopwords.Stopwords ...\n",
      "INFO:ekorpkit.preprocessors.tokenizer:MecabTokenizer initialized with:\n",
      "INFO:ekorpkit.preprocessors.tokenizer:\treturn_as_list: False\n",
      "INFO:ekorpkit.tokenizers.mecab:MeCab uses mecab-python3 as backend.\n",
      "INFO:ekorpkit.tokenizers.mecab:Mecab uses system dictionary: /opt/conda/lib/python3.8/site-packages/mecab_ko_dic/dicdir, user dictionary: /workspace/projects/ekorpkit/ekorpkit/resources/dictionaries/mecab/ekon_v1.dic\n",
      "INFO:ekorpkit.pipelines.pipe:extract_func: <bound method Tokenizer.extract_tokens of <ekorpkit.preprocessors.tokenizer.MecabTokenizer object at 0x7f20c6901d90>>\n",
      "INFO:ekorpkit.hyfi.utils.logging:Using batcher with minibatch size: 21\n",
      "INFO:ekorpkit.hyfi.utils.batch.batcher: backend: joblib  minibatch_size: 21  procs: 50  input_split: False  merge_output: True  len(data): 1000 len(args): 5\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005887031555175781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Extracting column: text",
       "rate": null,
       "total": 48,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960f68be7cea4105a2d5ca8320193887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting column: text:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ekorpkit.pipelines.pipe: >> elapsed time to extract tokens: 0:00:00.848701\n",
      "INFO:ekorpkit.hyfi.io.file:Saving dataframe to /workspace/projects/ekorpkit-book/exmaples/esg/data/similarity/tokenized_data.parquet\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.55 s (started: 2023-02-10 02:55:19 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Extract tokens\n",
    "# stopwords_file = ws.project_dir / \"esg/data/stopwords/stopwords.txt\"\n",
    "tkn_cfg = eKonf.compose(\"preprocessor/tokenizer=mecab_econ\")\n",
    "# tkn_cfg.extract.strip_pos = False\n",
    "\n",
    "cfg = eKonf.compose(\"pipeline/extract_tokens\")\n",
    "cfg.preprocessor.tokenizer = tkn_cfg\n",
    "cfg.nouns_only = False\n",
    "# cfg.stopwords_path = str(stopwords_file)\n",
    "# eKonf.print(cfg)\n",
    "data = eKonf.pipe(data, cfg)\n",
    "\n",
    "tokenized_data_file = ws.project_dir / \"esg/data/similarity/tokenized_data.parquet\"\n",
    "eKonf.save_data(data, tokenized_data_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict similarity\n",
    "\n",
    "Similarity will be measured among the news articles on the same day. The similarity is measured by the cosine similarity of the document vectors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at entelecheia/ekonelectra-base-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.78 s (started: 2023-01-19 08:56:23 +00:00)\n"
     ]
    }
   ],
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer\n",
    "\n",
    "# Initialize the Electra model and tokenizer\n",
    "model = ElectraModel.from_pretrained('entelecheia/ekonelectra-base-discriminator')\n",
    "tokenizer = ElectraTokenizer.from_pretrained('entelecheia/ekonelectra-base-discriminator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.7 ms (started: 2023-01-19 08:56:26 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and encode the documents\n",
    "encoded_docs = [tokenizer.encode(doc, return_tensors='pt', truncation=True) for doc in documents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.47 s (started: 2023-01-19 08:56:27 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Generate the embeddings for the documents\n",
    "embeddings = [model(doc)[0][:, 0, :].detach().numpy() for doc in encoded_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.38 ms (started: 2023-01-19 08:59:45 +00:00)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get the mean of the embeddings\n",
    "mean_embeddings = [np.mean(embedding, axis=0) for embedding in embeddings]\n",
    "# Gey CLS token embedding\n",
    "cls_embeddings = [embedding[0] for embedding in embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001  0.968363   0.92001873 0.9597888  0.9621922  0.9525209\n",
      "  0.96460295 0.9683971  0.9587421  0.9609047 ]\n",
      " [0.968363   1.         0.9243116  0.99047786 0.9818795  0.974076\n",
      "  0.9874664  0.99173224 0.9730664  0.9540314 ]\n",
      " [0.92001873 0.9243116  1.0000002  0.90941644 0.9215709  0.91559356\n",
      "  0.92173624 0.9292955  0.94094986 0.9056404 ]\n",
      " [0.9597888  0.99047786 0.90941644 1.0000002  0.9848912  0.97961116\n",
      "  0.9907066  0.9894204  0.9725035  0.9612313 ]\n",
      " [0.9621922  0.9818795  0.9215709  0.9848912  1.         0.9741106\n",
      "  0.9906047  0.9855628  0.9789446  0.9729687 ]\n",
      " [0.9525209  0.974076   0.91559356 0.97961116 0.9741106  1.\n",
      "  0.9774029  0.9789716  0.97945994 0.96554124]\n",
      " [0.96460295 0.9874664  0.92173624 0.9907066  0.9906047  0.9774029\n",
      "  0.9999999  0.99083006 0.97806597 0.9706383 ]\n",
      " [0.9683971  0.99173224 0.9292955  0.9894204  0.9855628  0.9789716\n",
      "  0.99083006 0.9999997  0.9804057  0.9656478 ]\n",
      " [0.9587421  0.9730664  0.94094986 0.9725035  0.9789446  0.97945994\n",
      "  0.97806597 0.9804057  1.         0.9752598 ]\n",
      " [0.9609047  0.9540314  0.9056404  0.9612313  0.9729687  0.96554124\n",
      "  0.9706383  0.9656478  0.9752598  0.9999999 ]]\n",
      "time: 2.3 ms (started: 2023-01-19 08:59:46 +00:00)\n"
     ]
    }
   ],
   "source": [
    "# Compute the similarity matrix using cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity_matrix = cosine_similarity(cls_embeddings)\n",
    "\n",
    "print(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "include_colab_link": true,
   "name": "preprocessor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
