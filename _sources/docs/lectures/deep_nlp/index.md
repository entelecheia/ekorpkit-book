# Deep Learning for NLP

## ğŸ“œ Course Description

This course aims to cover cutting-edge deep learning methods for natural language processing. The topics include word embeddings and contextualized word embeddings; language models; transformers; pre-training and fine-tuning; sequence tagging (NER, question answering); sequence generation (summarization, machine translation), zero-shot learning, etc.

## â™¾ï¸Â Learning Goals

By the end of this course, students will be able to: Understand fundamental concepts in natural language processing, including text representation, sequence modeling, and neural machine translation. Understand the state-of-the-art deep learning methods for natural language processing, including word embeddings and contextualized word embeddings; language models; transformers; pre-training and fine-tuning; sequence tagging (NER, question answering); sequence generation (summarization, machine translation), zero-shot learning, etc. Implement key algorithms in natural language processing using deep learning frameworks such as PyTorch or TensorFlow. Train and tune state-of-the-art models on large-scale datasets. Read and understand recent research papers in natural language processing.

## ğŸ† **Grading**

- Participation: **10%**
- Midterm: **30%**
- Term Project: **60%**

## ğŸ§  Term Project

Students will be required to complete a term project as part of this course. The term project can take the form of either a research paper or a practical implementation. Students interested in pursuing a research paper should consult with the instructor at the beginning of the term to discuss potential topics. Students interested in pursuing a practical implementation should consult with the instructor at the beginning of the term to discuss datasets and evaluation metrics.

## ğŸ—“ï¸Â Course Table of Contents

```{tableofcontents}

```
