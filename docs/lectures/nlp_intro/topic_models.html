

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Topic Models &#8212; eKorpkit Tutorials</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/ekorpkit.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-FN4GFT8HP8"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-FN4GFT8HP8');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'docs/lectures/nlp_intro/topic_models';</script>
    <link rel="canonical" href="https://entelecheia.cc/docs/lectures/nlp_intro/topic_models.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Topic Coherence Measures" href="topic_coherence.html" />
    <link rel="prev" title="Topic Modeling" href="topic.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/ekorpkit.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../../_static/ekorpkit.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    eKonomic Research Python Toolkit
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../basics/index.html">Getting started</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../basics/install.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/usage.html">Usage</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../basics/features/index.html">Key features</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../basics/features/easy_config.html">Easy Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/features/no_boiler.html">No Boilerplate</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/features/workflows.html">Workflows</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/features/share.html">Sharable and Reproducible</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../basics/features/plug.html">Pluggable Architece</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/config/index.html">Configuring ekorpkit</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/config/eKonf.html">Using eKonf class</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/datasets/index.html">Datasets</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/corpora/corpus.html">Build and Load Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/datasets/dataset.html">Build and Load Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/corpora/pipeline.html">Corpus task pipelines</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/models/index.html">Models</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/models/automl/index.html">Auto ML</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/models/embeddings/index.html">Word Embeddings</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/embeddings/word2vec_basics.html">Word2Vec Basics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/embeddings/eval_vectors.html">Evaluate pretrained embeddings</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/models/ngram/index.html">N-Grams</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/ngram/ngram.html">N-Grams</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/ngram/ngram_for_lexicons.html">N-Gram model for ngram lexicon features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/ngram/ngram_for_words.html">N-Gram model for unigram lexicon features</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/models/sentiment/index.html">Sentiment Analyers</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/sentiment/lbsa_en.html">Lexicon-based Sentiment Analysis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/sentiment/financial_phrasebank_lm.html">Evaluate LM with financial phrasebank</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/models/sentiment/sentiment.html">LM Dictionary vs. finbert vs. T5</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/models/transformers/index.html">Transformers</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/pipelines/index.html">Pipelines</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/pipelines/pipeline.html">Instantiating pipeline</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/preprocessors/index.html">Preprocessors</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/preprocessors/normalizer/index.html">Normalizers</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/preprocessors/normalizer/normalizer.html">Normalizers</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/preprocessors/segmenter/index.html">Segmenters</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/preprocessors/segmenter/segmenter.html">Segmenters</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../tutorials/preprocessors/tokenizer/index.html">Tokenizers</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../tutorials/preprocessors/tokenizer/mecab.html">Mecab Tokenizer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../tutorials/visualizers/index.html">Visualizers</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../tutorials/visualizers/plot.html">Plots</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/workflow/index.html">Workflows</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Datasets</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../corpus/ekorpkot_corpus.html">The eKorpkit Corpus</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Use Cases</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usecases/fomc/index.html">FOMC</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/02_FOMC_numerical_data.html">Preparing Numerical Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/03_FOMC_corpus.html">Preparing Textual Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/04_FOMC_EDA_numericals.html">EDA on Numerical Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/05_FOMC_features.html">Visualizing Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/06_FOMC_AutoML.html">Checking Baseline with AutoML</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/07_FOMC_sentiments.html">Predicting Sentiments of FOMC Corpus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/08_FOMC_EDA_sentiments.html">EDA on Sentiment Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/fomc/09_FOMC_AutoML_with_tones.html">Predicting the next decisions with tones</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../usecases/bok/index.html">Bank of Korea</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usecases/edgar/index.html">EDGAR</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/edgar/predict_edgar.html">Prediciting Sentiments</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usecases/esg/index.html">ESG</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/prepare_datasets.html">Preparing training datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/improve_datasets.html">Improving classification datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/train_classifiers.html">Training Classifiers for ESG Ratings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/build_news_corpus.html">Building <code class="docutils literal notranslate"><span class="pre">econ_news_kr</span></code> corpus</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/predict_esg_classes.html">Predicting ESG Categories and Polarities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/cross_validate_datasets.html">Cross validating datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/prepare_datasets_for_labeling.html">Preparing active learning data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg/all_in_one_pipeline.html">Putting them together in a pipeline</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usecases/esg-en/index.html">ESG (English)</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/esg-en/esg_corpus.html">Building <code class="docutils literal notranslate"><span class="pre">JOCo</span></code> corpus</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../usecases/cointax/index.html">Taxation on Cryptocurrency</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../usecases/cointax/coin_dataset.html">Improving classification datasets</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Research</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../research/esg_topics/analyst.html">ESG Topic Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../research/esg_topics/rethink_esg.html">Rethinking ESG</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Lectures</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active has-children"><a class="reference internal" href="index.html">Introduction to NLP</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-20"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="ekorpkit.html">Getting started with ekorpkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="research.html">Research Applications</a></li>
<li class="toctree-l2"><a class="reference internal" href="language_models.html">Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="topic.html">Topic Modeling</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Topic Models </a></li>
<li class="toctree-l2"><a class="reference internal" href="topic_coherence.html">Topic Coherence Measures</a></li>
<li class="toctree-l2"><a class="reference internal" href="sentiments.html">Sentiment Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="word_segmentation.html">Word Segmentation and Association</a></li>
<li class="toctree-l2"><a class="reference internal" href="vectorization.html">Vector Semantics and Representation</a></li>
<li class="toctree-l2"><a class="reference internal" href="word_embeddings.html">Word Embeddings</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab1-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="lab2-corpus-eda.html">Lab 2: EDA on Corpora</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../nlp_deep/index.html">Deep Learning for NLP</a><input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-21"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/ekorpkit.html">Getting started with ekorpkit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/zeroshot.html">Zero Shot, Prompt, and Search Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/bloom.html">What is BLOOM?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/bloom_apps.html">Bloom Examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/transformers.html">Transformers </a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/bert.html">BERT: Bidirectional Encoder Representations from Transformers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/t5.html">T5: Text-To-Text Transfer Transformer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/tokenization.html">Tokenization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/sentencepiece.html">SentencePiece Tokenizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/byt5.html">ByT5: Towards a token-free future with pre-trained byte-to-byte models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/plms.html">Pretrained Language Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab1-corpus.html">Lab 1: Preparing Wikipedia Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab2-corpus-eda.html">Lab 2: EDA on Corpora</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab3-train-tokenizers.html">Lab 3: Training Tokenizers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nlp_deep/lab4-pretraining-lms.html">Lab 4: Pretraining Language Models</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nlp_apps/index.html">NLP Applications</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../aiart/index.html">AI Art (Text-to-Image)</a><input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-22"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../aiart/intro.html">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/project-themes.html">Project Themes - A Brave New World</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle1.html">DALL·E 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle2.html">DALL·E 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/imagen.html">Imagen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/dalle-mini.html">DALL·E Mini</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/stable-diffusion.html">Stable Diffusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/prompt-generator.html">Prompt Generator for Stable Diffusion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/textual-inversion.html">Textual Inversion (Dreambooth)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/whisper.html">Automatic Speech Recognition (Whisper)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/text2music.html">Text to Music</a></li>
<li class="toctree-l2"><a class="reference internal" href="../aiart/image2music.html">Image to Music</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../mlops/index.html">Machine Learning Systems Design</a><input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-23"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../mlops/dev-env.html">Development Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../mlops/dotfiles.html">Dotfiles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ds/index.html">Data Science for Economics and Finance</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Projects</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../projects/robot_drawing/index.html">Robot Drawing System</a><input class="toctree-checkbox" id="toctree-checkbox-24" name="toctree-checkbox-24" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-24"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../projects/robot_drawing/intro.html">Introduction to Robot Drawing Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../projects/robot_drawing/proposal.html">Proposal for a Robot Drawing System</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../projects/robot_drawing/sketch_generation.html">Reference - Sketch Generation with Drawing Process Guided by Vector Flow and Grayscale</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../projects/robot_drawing/robocodraw.html">Reference - Avatar-GAN (RoboCoDraw)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../projects/robot_drawing/fast_robotic_pencil_drawing.html">Reference - Fast Robotic Pencil Drawing</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">About</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference external" href="https://entelecheia.me">entelecheia.me</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about/index.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../about/cite.html">Citation</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/entelecheia/ekorpkit-book/blob/main/ekorpkit-book/docs/lectures/nlp_intro/topic_models.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/entelecheia/ekorpkit-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/entelecheia/ekorpkit-book/issues/new?title=Issue%20on%20page%20%2Fdocs/lectures/nlp_intro/topic_models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/docs/lectures/nlp_intro/topic_models.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Topic Models </h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-tomotopy">What is tomotopy?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting Started</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-save-and-load">Model Save and Load</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#documents-in-the-model-and-out-of-the-model">Documents in the Model and out of the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-for-unseen-documents">Inference for Unseen Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-and-transform">Corpus and transform</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pining-topics-using-word-priors">Pining Topics using Word Priors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#install-or-upgrade-of-ekorpkit">Install or upgrade of ekorpkit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-a-dataset">Load a dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lda-basics">LDA Basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lda-visualization">LDA Visualization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lda-coherence">LDA coherence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Pining Topics using Word Priors</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="topic-models-jupyter-book-badge">
<h1>Topic Models <a class="reference external" href="https://entelecheia.github.io/ekorpkit-book/"><img alt="Jupyter Book Badge" src="https://jupyterbook.org/badge.svg" /></a><a class="headerlink" href="#topic-models-jupyter-book-badge" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://github.com/bab2min/tomotopy"><img alt="tomoto" src="../../../_images/tomoto.png" /></a></p>
<p>Package tomotopy <span id="id1">[<a class="reference internal" href="../../about/index.html#id13" title="Minchul Lee. Bab2min/tomotopy: 0.12.3. July 2022. URL: https://doi.org/10.5281/zenodo.6868418, doi:10.5281/zenodo.6868418.">Lee, 2022</a>]</span></p>
<section id="what-is-tomotopy">
<h2>What is tomotopy?<a class="headerlink" href="#what-is-tomotopy" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">tomotopy</span></code> is a Python extension of <code class="docutils literal notranslate"><span class="pre">tomoto</span></code> (Topic Modeling Tool) which is a Gibbs-sampling based topic model library written in C++.
The current version of <code class="docutils literal notranslate"><span class="pre">tomoto</span></code> supports several major topic models including</p>
<ul class="simple">
<li><p>Latent Dirichlet Allocation (<code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel</span></code>)</p></li>
<li><p>Labeled LDA (<code class="docutils literal notranslate"><span class="pre">tomotopy.LLDAModel</span></code>)</p></li>
<li><p>Partially Labeled LDA (<code class="docutils literal notranslate"><span class="pre">tomotopy.PLDAModel</span></code>)</p></li>
<li><p>Supervised LDA (<code class="docutils literal notranslate"><span class="pre">tomotopy.SLDAModel</span></code>)</p></li>
<li><p>Dirichlet Multinomial Regression (<code class="docutils literal notranslate"><span class="pre">tomotopy.DMRModel</span></code>)</p></li>
<li><p>Generalized Dirichlet Multinomial Regression (<code class="docutils literal notranslate"><span class="pre">tomotopy.GDMRModel</span></code>)</p></li>
<li><p>Hierarchical Dirichlet Process (<code class="docutils literal notranslate"><span class="pre">tomotopy.HDPModel</span></code>)</p></li>
<li><p>Hierarchical LDA (<code class="docutils literal notranslate"><span class="pre">tomotopy.HLDAModel</span></code>)</p></li>
<li><p>Multi Grain LDA (<code class="docutils literal notranslate"><span class="pre">tomotopy.MGLDAModel</span></code>)</p></li>
<li><p>Pachinko Allocation (<code class="docutils literal notranslate"><span class="pre">tomotopy.PAModel</span></code>)</p></li>
<li><p>Hierarchical PA (<code class="docutils literal notranslate"><span class="pre">tomotopy.HPAModel</span></code>)</p></li>
<li><p>Correlated Topic Model (<code class="docutils literal notranslate"><span class="pre">tomotopy.CTModel</span></code>)</p></li>
<li><p>Dynamic Topic Model (<code class="docutils literal notranslate"><span class="pre">tomotopy.DTModel</span></code>)</p></li>
<li><p>Pseudo-document based Topic Model (<code class="docutils literal notranslate"><span class="pre">tomotopy.PTModel</span></code>).</p></li>
</ul>
</section>
<section id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">#</a></h2>
<p>You can install tomotopy easily using pip. (<a class="reference external" href="https://pypi.org/project/tomotopy/">https://pypi.org/project/tomotopy/</a>)</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
pip<span class="w"> </span>install<span class="w"> </span>tomotopy
</pre></div>
</div>
<p>After installing, you can start tomotopy by just importing.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">isa</span><span class="p">)</span> <span class="c1"># prints &#39;avx2&#39;, &#39;avx&#39;, &#39;sse2&#39; or &#39;none&#39;</span>
</pre></div>
</div>
<p>Here is a sample code for simple LDA training of texts from ‘sample.txt’ file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sample.txt&#39;</span><span class="p">):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="se">\t</span><span class="s1">Log-likelihood: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">ll_per_word</span><span class="p">))</span>

<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top 10 words of topic #</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_words</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="n">mdl</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="model-save-and-load">
<h2>Model Save and Load<a class="headerlink" href="#model-save-and-load" title="Permalink to this headline">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">tomotopy</span></code> provides <code class="docutils literal notranslate"><span class="pre">save</span></code> and <code class="docutils literal notranslate"><span class="pre">load</span></code> method for each topic model class,
so you can save the model into the file whenever you want, and re-load it from the file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>

<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">HDPModel</span><span class="p">()</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;sample.txt&#39;</span><span class="p">):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="se">\t</span><span class="s1">Log-likelihood: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">ll_per_word</span><span class="p">))</span>

<span class="c1"># save into file</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;sample_hdp_model.bin&#39;</span><span class="p">)</span>

<span class="c1"># load from file</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">HDPModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;sample_hdp_model.bin&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">mdl</span><span class="o">.</span><span class="n">is_live_topic</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="k">continue</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Top 10 words of topic #</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_words</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>

<span class="c1"># the saved model is HDP model, </span>
<span class="c1"># so when you load it by LDA model, it will raise an exception</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;sample_hdp_model.bin&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>When you load the model from a file, a model type in the file should match the class of methods.</p>
</section>
<section id="documents-in-the-model-and-out-of-the-model">
<h2>Documents in the Model and out of the Model<a class="headerlink" href="#documents-in-the-model-and-out-of-the-model" title="Permalink to this headline">#</a></h2>
<p>We can use Topic Model for two major purposes.
The basic one is to discover topics from a set of documents as a result of trained model,
and the more advanced one is to infer topic distributions for unseen documents by using trained model.</p>
<p>We named the document in the former purpose (used for model training) as <strong>document in the model</strong>,
and the document in the later purpose (unseen document during training) as <strong>document out of the model</strong>.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">tomotopy</span></code>, these two different kinds of document are generated differently.
A <strong>document in the model</strong> can be created by <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.add_doc</span></code> method.
<code class="docutils literal notranslate"><span class="pre">add_doc</span></code> can be called before <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.train</span></code> starts.
In other words, after <code class="docutils literal notranslate"><span class="pre">train</span></code> called, <code class="docutils literal notranslate"><span class="pre">add_doc</span></code> cannot add a document into the model because the set of document used for training has become fixed.</p>
<p>To acquire the instance of the created document, you should use <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.docs</span></code> like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">idx</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
<span class="k">if</span> <span class="n">idx</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Failed to add doc&quot;</span><span class="p">)</span>
<span class="n">doc_inst</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
<span class="c1"># doc_inst is an instance of the added document</span>
</pre></div>
</div>
<p>A <strong>document out of the model</strong> is generated by <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.make_doc</span></code> method. <code class="docutils literal notranslate"><span class="pre">make_doc</span></code> can be called only after <code class="docutils literal notranslate"><span class="pre">train</span></code> starts.
If you use <code class="docutils literal notranslate"><span class="pre">make_doc</span></code> before the set of document used for training has become fixed, you may get wrong results.
Since <code class="docutils literal notranslate"><span class="pre">make_doc</span></code> returns the instance directly, you can use its return value for other manipulations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="c1"># add_doc ...</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">doc_inst</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">make_doc</span><span class="p">(</span><span class="n">unseen_doc</span><span class="p">)</span> <span class="c1"># doc_inst is an instance of the unseen document</span>
</pre></div>
</div>
</section>
<section id="inference-for-unseen-documents">
<h2>Inference for Unseen Documents<a class="headerlink" href="#inference-for-unseen-documents" title="Permalink to this headline">#</a></h2>
<p>If a new document is created by <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.make_doc</span></code>, its topic distribution can be inferred by the model.
Inference for unseen document should be performed using <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.infer</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="c1"># add_doc ...</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="n">doc_inst</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">make_doc</span><span class="p">(</span><span class="n">unseen_doc</span><span class="p">)</span>
<span class="n">topic_dist</span><span class="p">,</span> <span class="n">ll</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">doc_inst</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Topic Distribution for Unseen Docs: &quot;</span><span class="p">,</span> <span class="n">topic_dist</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Log-likelihood of inference: &quot;</span><span class="p">,</span> <span class="n">ll</span><span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">infer</span></code> method can infer only one instance of <code class="docutils literal notranslate"><span class="pre">tomotopy.Document</span></code> or a <code class="docutils literal notranslate"><span class="pre">list</span></code> of instances of <code class="docutils literal notranslate"><span class="pre">tomotopy.Document</span></code>.
See more at <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.infer</span></code>.</p>
</section>
<section id="corpus-and-transform">
<h2>Corpus and transform<a class="headerlink" href="#corpus-and-transform" title="Permalink to this headline">#</a></h2>
<p>Every topic model in <code class="docutils literal notranslate"><span class="pre">tomotopy</span></code> has its own internal document type.
A document can be created and added into suitable for each model through each model’s <code class="docutils literal notranslate"><span class="pre">add_doc</span></code> method.
However, trying to add the same list of documents to different models becomes quite inconvenient,
because <code class="docutils literal notranslate"><span class="pre">add_doc</span></code> should be called for the same list of documents to each different model.
Thus, <code class="docutils literal notranslate"><span class="pre">tomotopy</span></code> provides <code class="docutils literal notranslate"><span class="pre">tomotopy.utils.Corpus</span></code> class that holds a list of documents.
<code class="docutils literal notranslate"><span class="pre">tomotopy.utils.Corpus</span></code> can be inserted into any model by passing as argument <code class="docutils literal notranslate"><span class="pre">corpus</span></code> to <code class="docutils literal notranslate"><span class="pre">__init__</span></code> or <code class="docutils literal notranslate"><span class="pre">add_corpus</span></code> method of each model.
So, inserting <code class="docutils literal notranslate"><span class="pre">tomotopy.utils.Corpus</span></code> just has the same effect to inserting documents the corpus holds.</p>
<p>Some topic models requires different data for its documents.
For example, <code class="docutils literal notranslate"><span class="pre">tomotopy.DMRModel</span></code> requires argument <code class="docutils literal notranslate"><span class="pre">metadata</span></code> in <code class="docutils literal notranslate"><span class="pre">str</span></code> type,
but <code class="docutils literal notranslate"><span class="pre">tomotopy.PLDAModel</span></code> requires argument <code class="docutils literal notranslate"><span class="pre">labels</span></code> in <code class="docutils literal notranslate"><span class="pre">List[str]</span></code> type.
Since <code class="docutils literal notranslate"><span class="pre">tomotopy.utils.Corpus</span></code> holds an independent set of documents rather than being tied to a specific topic model,
data types required by a topic model may be inconsistent when a corpus is added into that topic model.
In this case, miscellaneous data can be transformed to be fitted target topic model using argument <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
<p>See more details in the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tomotopy</span> <span class="kn">import</span> <span class="n">DMRModel</span>
<span class="kn">from</span> <span class="nn">tomotopy.utils</span> <span class="kn">import</span> <span class="n">Corpus</span>

<span class="n">corpus</span> <span class="o">=</span> <span class="n">Corpus</span><span class="p">()</span>
<span class="n">corpus</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="s2">&quot;a b c d e&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">a_data</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">corpus</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="s2">&quot;e f g h i&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">a_data</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">corpus</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="s2">&quot;i j k l m&quot;</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">a_data</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DMRModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> 
<span class="c1"># You lose `a_data` field in `corpus`, </span>
<span class="c1"># and `metadata` that `DMRModel` requires is filled with the default value, empty str.</span>

<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span>
<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span>
<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span> <span class="o">==</span> <span class="s1">&#39;&#39;</span>

<span class="k">def</span> <span class="nf">transform_a_data_to_metadata</span><span class="p">(</span><span class="n">misc</span><span class="p">:</span> <span class="nb">dict</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;metadata&#39;</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">misc</span><span class="p">[</span><span class="s1">&#39;a_data&#39;</span><span class="p">])}</span>
<span class="c1"># this function transforms `a_data` to `metadata`</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">DMRModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add_corpus</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform_a_data_to_metadata</span><span class="p">)</span>
<span class="c1"># Now docs in `model` has non-default `metadata`, that generated from `a_data` field.</span>

<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span>
<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span> <span class="o">==</span> <span class="s1">&#39;2&#39;</span>
<span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">docs</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">metadata</span> <span class="o">==</span> <span class="s1">&#39;3&#39;</span>
</pre></div>
</div>
</section>
<section id="pining-topics-using-word-priors">
<h2>Pining Topics using Word Priors<a class="headerlink" href="#pining-topics-using-word-priors" title="Permalink to this headline">#</a></h2>
<p>Since version 0.6.0, a new method <code class="docutils literal notranslate"><span class="pre">tomotopy.LDAModel.set_word_prior</span></code> has been added. It allows you to control word prior for each topic.
For example, we can set the weight of the word ‘church’ to 1.0 in topic 0, and the weight to 0.1 in the rest of the topics by following codes.
This means that the probability that the word ‘church’ is assigned to topic 0 is 10 times higher than the probability of being assigned to another topic.
Therefore, most of ‘church’ is assigned to topic 0, so topic 0 contains many words related to ‘church’.
This allows to manipulate some topics to be placed at a specific topic number.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

<span class="c1"># add documents into `mdl`</span>

<span class="c1"># setting word prior</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;church&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.1</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)])</span>
</pre></div>
</div>
</section>
<section id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">#</a></h2>
<section id="install-or-upgrade-of-ekorpkit">
<h3>Install or upgrade of ekorpkit<a class="headerlink" href="#install-or-upgrade-of-ekorpkit" title="Permalink to this headline">#</a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Install ekorpkit package first.</p>
<p>Set logging level to Warning, if you don’t want to see verbose logging.</p>
<p>If you run this notebook in Colab, set Hardware accelerator to GPU.</p>
</div>
<div class="toggle docutils container">
<p>!pip install -U –pre ekorpkit[topic]</p>
<p>exit()</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ekorpkit</span> <span class="kn">import</span> <span class="n">eKonf</span>

<span class="n">eKonf</span><span class="o">.</span><span class="n">setLogger</span><span class="p">(</span><span class="s2">&quot;WARNING&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;version:&quot;</span><span class="p">,</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;is notebook?&quot;</span><span class="p">,</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">is_notebook</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;is colab?&quot;</span><span class="p">,</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">is_colab</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;environment variables:&quot;</span><span class="p">)</span>
<span class="n">eKonf</span><span class="o">.</span><span class="n">print</span><span class="p">(</span><span class="n">eKonf</span><span class="o">.</span><span class="n">env</span><span class="p">()</span><span class="o">.</span><span class="n">dict</span><span class="p">())</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s2">&quot;../data/topic_models&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>version: 0.1.39.post0.dev7
is notebook? True
is colab? False
environment variables:
{&#39;CUDA_DEVICE_ORDER&#39;: None,
 &#39;CUDA_VISIBLE_DEVICES&#39;: None,
 &#39;EKORPKIT_CONFIG_DIR&#39;: &#39;/workspace/projects/ekorpkit-book/config&#39;,
 &#39;EKORPKIT_DATA_DIR&#39;: None,
 &#39;EKORPKIT_LOG_LEVEL&#39;: &#39;WARNING&#39;,
 &#39;EKORPKIT_PROJECT&#39;: &#39;ekorpkit-book&#39;,
 &#39;EKORPKIT_WORKSPACE_ROOT&#39;: &#39;/workspace&#39;,
 &#39;KMP_DUPLICATE_LIB_OK&#39;: &#39;TRUE&#39;,
 &#39;NUM_WORKERS&#39;: 230}
</pre></div>
</div>
</div>
</div>
</section>
<section id="load-a-dataset">
<h3>Load a dataset<a class="headerlink" href="#load-a-dataset" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cfg</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">compose</span><span class="p">(</span><span class="s1">&#39;path&#39;</span><span class="p">)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">cache</span><span class="o">.</span><span class="n">uri</span> <span class="o">=</span> <span class="s1">&#39;https://github.com/entelecheia/ekorpkit-book/raw/main/assets/data/us_equities_news_sampled.zip&#39;</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="s2">&quot;us_equities_news_sampled.parquet&quot;</span><span class="p">,</span> <span class="n">cfg</span><span class="o">.</span><span class="n">cached_path</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">text</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39;Investing com Asian stock markets were broadly lower for a second day on Thursday as weak U S data on durable goods orders added to concerns over the global growth outlook while concerns over declining corporate profits also weighed During late Asian trade Hong Kong s Hang Seng Index tumbled 1 55 Australia s ASX 200 Index dipped 0 1 while Japan s Nikkei 225 Index shed 0 7 The Nikkei came further off a one year closing high hit earlier in the week as investors cashed in ahead of the Japanese fiscal year end March is the final month of Japan s fiscal year and market participants have expected many funds to lock in profits from a meteoric 19 rally in the January to March period after shedding more than 13 in April to December Exporters which have gained sharply in the first quarter on the back a weakening yen declined Automakers Toyota and Nissan slumped 1 65 and 1 8 respectively while consumer electronics giant Sony retreated 1 5 On the upside Sharp saw shares jump 6 7 extending the previous day s 15 rally following reports that Taiwan s Hon Hai Precision Industry is buying 10 of the Japanese electronics manufacturer for JPY66 91 billion with the two to form a tie up in liquid crystal display production Elsewhere shares in Hong Kong came under pressure amid lingering fears over a hard landing in China and worries over declining corporate profits PICC Property Casualty China s biggest non life insurer saw shares drop 4 after reporting 2011 net income rose to CNY8 03 billion missing expectations for income of CNY8 8 billion China Shipping Container Lines fell 1 55 after the nation s second largest container carrier reported a loss of CNY2 74 billion last year wider than the average estimate of CNY2 63 billion amid rising fuel costs and declining demand Port operator China Merchants Holdings declined 1 7 after saying annual profit dropped 5 2 due to costs from a harbor deal Hong Kong traded Chinese banks were also broadly weaker with Industrial and Commercial Bank of China and Bank of China down 2 4 and 2 3 respectively ahead of their 2011 earnings reports later on Thursday Raw material producers also contributed to losses amid concerns over the global growth outlook Copper mining giant Jiangxi Copper Company dropped 3 4 Aluminum Corporation of China or CHALCO slumped 2 4 while shares in oil majors PetroChina and CNOOC fell 2 1 and 3 8 respectively But shares in Australia outperformed regional equities for a second day remaining close to a four month high The index was weighed by a 7 decline in Leighton Holdings the country s largest construction company after saying its underlying profit in the year ending December 31 will be between AUD400 million and AUD450 million below market expectations citing increased costs due to wet weather and lower than expected productivity Meanwhile European stock markets were mildly lower after the open supported by hopes that euro zone leaders will increase the size of the European debt firewall to combat the fiscal crisis The EURO STOXX 50 shed 0 3 France s CAC 40 dipped 0 1 Germany s DAX fell 0 25 while London s FTSE 100 edged 0 15 lower Later in the day Germany was to publish official data on employment change while the U S was to release official data on initial jobless claims&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="lda-basics">
<h3>LDA Basics<a class="headerlink" href="#lda-basics" title="Permalink to this headline">#</a></h3>
<p>LDA class provides Latent Dirichlet Allocation(LDA) topic model and its implementation is based on following papers:</p>
<ul class="simple">
<li><p>Blei, D.M., Ng, A.Y., &amp;Jordan, M.I. (2003).Latent dirichlet allocation.Journal of machine Learning research, 3(Jan), 993 - 1022.</p></li>
<li><p>Newman, D., Asuncion, A., Smyth, P., &amp;Welling, M. (2009).Distributed algorithms for topic models.Journal of Machine Learning Research, 10(Aug), 1801 - 1828.</p></li>
</ul>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>

<span class="n">save_path</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">join_path</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;lda_basic.mdl&quot;</span><span class="p">)</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">tw</span><span class="o">=</span><span class="n">tp</span><span class="o">.</span><span class="n">TermWeight</span><span class="o">.</span><span class="n">ONE</span><span class="p">,</span> <span class="n">min_cf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">rm_top</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">line</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">][:</span><span class="mi">100</span><span class="p">]):</span>
    <span class="n">ch</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">add_doc</span><span class="p">(</span><span class="n">ch</span><span class="p">)</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">burn_in</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Num docs:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">),</span> <span class="s1">&#39;, Vocab size:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">used_vocabs</span><span class="p">),</span> <span class="s1">&#39;, Num words:&#39;</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">num_words</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Removed top words:&#39;</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">removed_top_words</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="se">\t</span><span class="s1">Log-likelihood: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">ll_per_word</span><span class="p">))</span>

<span class="n">mdl</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_path</span><span class="p">,</span> <span class="n">full</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Num docs: 100 , Vocab size: 972 , Num words: 33695
Removed top words: [&#39;the&#39;, &#39;to&#39;, &#39;of&#39;, &#39;and&#39;, &#39;in&#39;, &#39;a&#39;, &#39;is&#39;, &#39;for&#39;, &#39;s&#39;, &#39;on&#39;]
Iteration: 0	Log-likelihood: -7.3065742522854
Iteration: 10	Log-likelihood: -7.055851222156576
Iteration: 20	Log-likelihood: -6.9786549585511946
Iteration: 30	Log-likelihood: -6.918256985219584
Iteration: 40	Log-likelihood: -6.906922808788813
Iteration: 50	Log-likelihood: -6.875851555821591
Iteration: 60	Log-likelihood: -6.860287052386768
Iteration: 70	Log-likelihood: -6.837860183047866
Iteration: 80	Log-likelihood: -6.833746569962225
Iteration: 90	Log-likelihood: -6.823284888087085
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Basic Info&gt;
| LDAModel (current version: 0.12.3)
| 100 docs, 33695 words
| Total Vocabs: 8855, Used Vocabs: 972
| Entropy of words: 6.35945
| Entropy of term-weighted words: 6.35945
| Removed Vocabs: the to of and in a is for s on
|
&lt;Training Info&gt;
| Iterations: 100, Burn-in steps: 100
| Optimization Interval: 10
| Log-likelihood per word: -6.82328
|
&lt;Initial Parameters&gt;
| tw: TermWeight.ONE
| min_cf: 10 (minimum collection frequency of words)
| min_df: 0 (minimum document frequency of words)
| rm_top: 10 (the number of top words to be removed)
| k: 20 (the number of topics between 1 ~ 32767)
| alpha: [0.1] (hyperparameter of Dirichlet distribution for document-topic, given as a single `float` in case of symmetric prior and as a list with length `k` of `float` in case of asymmetric prior.)
| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)
| seed: 3080440490 (random seed)
| trained in version 0.12.3
|
&lt;Parameters&gt;
| alpha (Dirichlet prior on the per-document topic distributions)
|  [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
|   0.1 0.1]
| eta (Dirichlet prior on the per-topic word distribution)
|  0.01
|
&lt;Topics&gt;
| #0 (4616) : has have be an it
| #1 (979) : trade market that from growth
| #2 (1177) : he He Trump his said
| #3 (1842) : as that The oil from
| #4 (1204) : It that The by some
| #5 (2673) : quarter 1 year 3 company
| #6 (783) : 1 ratio market margin value
| #7 (2400) : with this that from their
| #8 (1257) : its high as this while
| #9 (2030) : percent 1 0 by 2
| #10 (1354) : I gold t you silver
| #11 (1154) : revenue PepsiCo In billion that
| #12 (2895) : The earnings year P S
| #13 (1123) : Goldman by Reuters up last
| #14 (1125) : companies are NYSE they more
| #15 (1115) : with 7 by sales The
| #16 (2150) : said it not that company
| #17 (1204) : S at U said investors
| #18 (1736) : Zacks Rank growth has expected
| #19 (878) : down demand China it level
|
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Topic #</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_words</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">word</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Topic #0
		has	0.043887220323085785
		have	0.041293028742074966
		be	0.040644481778144836
		an	0.03415900468826294
		it	0.03286190703511238
		are	0.03156481310725212
		will	0.031132448464632034
		at	0.02745734713971615
		or	0.027241162955760956
		than	0.023782242089509964
Topic #1
		trade	0.047546323388814926
		market	0.04248927906155586
		that	0.03844364359974861
		from	0.03439800813794136
		growth	0.03439800813794136
		8	0.030352376401424408
		4	0.029340967535972595
		quarter	0.02731814980506897
		25	0.02428392320871353
		results	0.022261105477809906
Topic #2
		he	0.05730922520160675
		He	0.04045604541897774
		Trump	0.037085410207509995
		his	0.03624275326728821
		said	0.03455743566155434
		but	0.031186800450086594
		was	0.028658824041485786
		by	0.026973506435751915
		with	0.026973506435751915
		will	0.025288190692663193
Topic #3
		as	0.05886959284543991
		that	0.05130905658006668
		The	0.046988748013973236
		oil	0.03240770846605301
		from	0.03186766803264618
		two	0.028627438470721245
		out	0.025927245616912842
		last	0.02484716847538948
		production	0.022687014192342758
		over	0.019986823201179504
Topic #4
		It	0.05109086260199547
		that	0.04944303259253502
		The	0.04861912131309509
		by	0.04037998989224434
		some	0.037908248603343964
		also	0.03296476975083351
		global	0.02966911531984806
		stock	0.028845202177762985
		price	0.024725638329982758
		world	0.023077810183167458
Topic #5
		quarter	0.04585271701216698
		1	0.044734448194503784
		year	0.03914311155676842
		3	0.03839759901165962
		company	0.038024842739105225
		2	0.03280625864863396
		million	0.03131523355841637
		from	0.02907869778573513
		billion	0.02460562437772751
		4	0.023860113695263863
Topic #6
		1	0.0706554651260376
		ratio	0.044164396822452545
		market	0.044164396822452545
		margin	0.04037995636463165
		value	0.03659551963210106
		company	0.029026644304394722
		debt	0.02524220570921898
		currency	0.021457767114043236
		13	0.02019628696143627
		total	0.02019628696143627
Topic #7
		with	0.05478229746222496
		this	0.05395232513546944
		that	0.05270737037062645
		from	0.047727540135383606
		their	0.02905316837131977
		just	0.023243363946676254
		see	0.022828377783298492
		as	0.02241339161992073
		investment	0.018678518012166023
		time	0.017433559522032738
Topic #8
		its	0.05605816841125488
		high	0.05132152512669563
		as	0.045795440673828125
		this	0.03553271293640137
		while	0.0292171910405159
		NASDAQ	0.0292171910405159
		week	0.02842774987220764
		day	0.026059428229928017
		new	0.02526998706161976
		markets	0.0244805496186018
Topic #9
		percent	0.08923283219337463
		1	0.05589492991566658
		0	0.05491440370678902
		by	0.04020649939775467
		2	0.0367746576666832
		with	0.024027807638049126
		yen	0.02255701646208763
		after	0.02255701646208763
		expected	0.020595964044332504
		than	0.018634909763932228
Topic #10
		I	0.09166838228702545
		gold	0.06160355731844902
		t	0.040338192135095596
		you	0.03740504011511803
		silver	0.029338866472244263
		Gold	0.027872290462255478
		out	0.02493913657963276
		think	0.020539406687021255
		do	0.019806118682026863
		money	0.019806118682026863
Topic #11
		revenue	0.05758258327841759
		PepsiCo	0.03695906326174736
		In	0.03524043411016464
		billion	0.03524043411016464
		that	0.03352180868387222
		The	0.029225243255496025
		EPS	0.026647305116057396
		are	0.024928677827119827
		growth	0.024928677827119827
		investment	0.02149142511188984
Topic #12
		The	0.057496074587106705
		earnings	0.048889391124248505
		year	0.03615150600671768
		P	0.02582348883152008
		S	0.02444641850888729
		3	0.02375788427889347
		2	0.02169227972626686
		up	0.02134801261126995
		average	0.02100374549627304
		stock	0.01824960671365261
Topic #13
		Goldman	0.03708771616220474
		by	0.03532205522060394
		Reuters	0.030025072395801544
		up	0.029142240062355995
		last	0.025610920041799545
		security	0.023845259100198746
		were	0.022962426766753197
		July	0.022079596295952797
		further	0.020313935354351997
		Inc	0.020313935354351997
Topic #14
		companies	0.08020481467247009
		are	0.06522314250469208
		NYSE	0.05464784428477287
		they	0.04142872244119644
		more	0.03702234849333763
		000	0.03525979816913605
		about	0.029972150921821594
		like	0.02820960246026516
		some	0.0238032303750515
		index	0.022921955212950706
Topic #15
		with	0.05157728120684624
		7	0.05157728120684624
		by	0.05068816989660263
		sales	0.0471317321062088
		The	0.046242620795965195
		year	0.03824062645435333
		Inc	0.024903977289795876
		Amazon	0.024903977289795876
		5	0.02401486597955227
		at	0.022236647084355354
Topic #16
		said	0.051863204687833786
		it	0.04815902188420296
		not	0.03704646974802017
		that	0.03519437834620476
		company	0.0342683307826519
		was	0.032879263162612915
		who	0.030564147979021072
		at	0.0277860090136528
		its	0.02454484812915325
		would	0.024081824347376823
Topic #17
		S	0.08322348445653915
		at	0.0683930441737175
		U	0.06674521416425705
		said	0.03131694346666336
		investors	0.02966911531984806
		dollar	0.027197375893592834
		The	0.023077810183167458
		seen	0.022253897041082382
		rate	0.02060607075691223
		up	0.019782157614827156
Topic #18
		Zacks	0.10655201971530914
		Rank	0.06072566285729408
		growth	0.049841899424791336
		has	0.034375499933958054
		expected	0.025783058255910873
		company	0.025783058255910873
		over	0.022918909788131714
		currently	0.019481932744383812
		Estimate	0.019481932744383812
		you	0.01890910230576992
Topic #19
		down	0.04619699716567993
		demand	0.041691072285175323
		China	0.037185147404670715
		it	0.030426261946558952
		level	0.028173299506306648
		after	0.028173299506306648
		inflation	0.027046818286180496
		consumer	0.025920337066054344
		Google	0.020287929102778435
		from	0.020287929102778435
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="lda-visualization">
<h3>LDA Visualization<a class="headerlink" href="#lda-visualization" title="Permalink to this headline">#</a></h3>
<p>This example shows how to perform a Latent Dirichlet Allocation using tomotopy and visualize the result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tomotopy</span> <span class="k">as</span> <span class="nn">tp</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pyLDAvis</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">porter_stemmer</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">PorterStemmer</span><span class="p">()</span><span class="o">.</span><span class="n">stem</span>
<span class="n">english_stops</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">porter_stemmer</span><span class="p">(</span><span class="n">w</span><span class="p">)</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">))</span>
<span class="n">pat</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s1">&#39;^[a-z]{2,}$&#39;</span><span class="p">)</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">Corpus</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tp</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">SimpleTokenizer</span><span class="p">(</span><span class="n">porter_stemmer</span><span class="p">),</span> 
    <span class="n">stopwords</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">english_stops</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">pat</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">corpus</span><span class="o">.</span><span class="n">process</span><span class="p">(</span><span class="n">d</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">][:</span><span class="mi">100</span><span class="p">])</span>
<span class="c1"># save preprocessed corpus for reuse</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">join_path</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s2">&quot;preprocessed_corpus.cps&quot;</span><span class="p">)</span>
<span class="n">corpus</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">rm_top</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Num docs:</span><span class="si">{}</span><span class="s1">, Num Vocabs:</span><span class="si">{}</span><span class="s1">, Total Words:</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
    <span class="nb">len</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">used_vocabs</span><span class="p">),</span> <span class="n">mdl</span><span class="o">.</span><span class="n">num_words</span>
<span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Removed Top words: &#39;</span><span class="p">,</span> <span class="o">*</span><span class="n">mdl</span><span class="o">.</span><span class="n">removed_top_words</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Num docs:100, Num Vocabs:1074, Total Words:22386
Removed Top words:  year compani stock market earn said zack price percent share quarter expect growth report billion revenu trade investor nyse million
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s train the model</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{:04}</span><span class="s1">, LL per word: </span><span class="si">{:.4}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">ll_per_word</span><span class="p">))</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{:04}</span><span class="s1">, LL per word: </span><span class="si">{:.4}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">ll_per_word</span><span class="p">))</span>

<span class="n">mdl</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration: 0000, LL per word: -12.02
Iteration: 0010, LL per word: -7.564
Iteration: 0020, LL per word: -7.357
Iteration: 0030, LL per word: -7.263
Iteration: 0040, LL per word: -7.193
Iteration: 0050, LL per word: -7.167
Iteration: 0060, LL per word: -7.159
Iteration: 0070, LL per word: -7.144
Iteration: 0080, LL per word: -7.138
Iteration: 0090, LL per word: -7.128
Iteration: 1000, LL per word: -7.122
&lt;Basic Info&gt;
| LDAModel (current version: 0.12.3)
| 100 docs, 22386 words
| Total Vocabs: 5139, Used Vocabs: 1074
| Entropy of words: 6.62188
| Entropy of term-weighted words: 6.62188
| Removed Vocabs: year compani stock market earn said zack price percent share quarter expect growth report billion revenu trade investor nyse million
|
&lt;Training Info&gt;
| Iterations: 100, Burn-in steps: 0
| Optimization Interval: 10
| Log-likelihood per word: -7.12162
|
&lt;Initial Parameters&gt;
| tw: TermWeight.ONE
| min_cf: 0 (minimum collection frequency of words)
| min_df: 5 (minimum document frequency of words)
| rm_top: 20 (the number of top words to be removed)
| k: 30 (the number of topics between 1 ~ 32767)
| alpha: [0.1] (hyperparameter of Dirichlet distribution for document-topic, given as a single `float` in case of symmetric prior and as a list with length `k` of `float` in case of asymmetric prior.)
| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)
| seed: 3743484366 (random seed)
| trained in version 0.12.3
|
&lt;Parameters&gt;
| alpha (Dirichlet prior on the per-document topic distributions)
|  [0.32200417 0.60077    0.21077627 0.06970649 0.4447674  0.5434947
|   0.5469532  0.45518324 0.6338666  0.5719722  0.8117618  0.47851452
|   0.5830207  0.5280389  0.46882564 0.58426094 0.5307975  0.526721
|   0.66027516 0.20483024 0.817219   0.5032047  0.20158361 0.4396458
|   0.43283358 0.6222955  0.43815643 0.29211614 0.32323366 0.4832791 ]
| eta (Dirichlet prior on the per-topic word distribution)
|  0.01
|
&lt;Topics&gt;
| #0 (486) : currenc high forecast chang way
| #1 (1118) : make think would come anoth
| #2 (525) : yen trump japan presid reuter
| #3 (403) : gold silver metal mine see
| #4 (692) : fund yield larg etf countri
| #5 (753) : high manag move new last
| #6 (877) : week rose fall ahead juli
| #7 (765) : rank consensu posit cloud per
| #8 (788) : invest may time import major
| #9 (926) : buy estim current see sell
| #10 (1130) : industri past hold rank term
| #11 (686) : level valu move follow risk
| #12 (817) : increas rate new demand govern
| #13 (890) : dollar bank futur sinc like
| #14 (733) : secur firm accord activist group
| #15 (780) : estim per ep best beat
| #16 (888) : sector goldman invest us season
| #17 (702) : day averag drop show corpor
| #18 (969) : strong increas result continu cent
| #19 (279) : use system organ center network
| #20 (1220) : also busi one last grow
| #21 (566) : month data china gain rise
| #22 (483) : oil product mexico energi unit
| #23 (703) : index higher close nasdaq fell
| #24 (529) : plan car would state media
| #25 (1070) : inc product nasdaq technolog top
| #26 (739) : back could call pay comment
| #27 (623) : oper ratio total margin dividend
| #28 (571) : sale retail store amazon consum
| #29 (675) : peopl financi look equiti seen
|
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">topic_term_dists</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_word_dist</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">)])</span>
<span class="n">doc_topic_dists</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">doc</span><span class="o">.</span><span class="n">get_topic_dist</span><span class="p">()</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">])</span>
<span class="n">doc_topic_dists</span> <span class="o">/=</span> <span class="n">doc_topic_dists</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">doc_lengths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">doc</span><span class="o">.</span><span class="n">words</span><span class="p">)</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">])</span>
<span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">used_vocabs</span><span class="p">)</span>
<span class="n">term_frequency</span> <span class="o">=</span> <span class="n">mdl</span><span class="o">.</span><span class="n">used_vocab_freq</span>

<span class="n">prepared_data</span> <span class="o">=</span> <span class="n">pyLDAvis</span><span class="o">.</span><span class="n">prepare</span><span class="p">(</span>
    <span class="n">topic_term_dists</span><span class="p">,</span> 
    <span class="n">doc_topic_dists</span><span class="p">,</span> 
    <span class="n">doc_lengths</span><span class="p">,</span> 
    <span class="n">vocab</span><span class="p">,</span> 
    <span class="n">term_frequency</span><span class="p">,</span>
    <span class="n">start_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="c1"># tomotopy starts topic ids with 0, pyLDAvis with 1</span>
    <span class="n">sort_topics</span><span class="o">=</span><span class="kc">False</span> <span class="c1"># IMPORTANT: otherwise the topic_ids between pyLDAvis and tomotopy are not matching!</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pyLDAvis</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">prepared_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_dir</span> <span class="o">=</span> <span class="s2">&quot;../../../assets/extra&quot;</span>
<span class="n">filename</span> <span class="o">=</span> <span class="s2">&quot;lda_basic.html&quot;</span>
<span class="n">save_path</span> <span class="o">=</span> <span class="n">eKonf</span><span class="o">.</span><span class="n">join_path</span><span class="p">(</span><span class="n">save_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
<span class="n">pyLDAvis</span><span class="o">.</span><span class="n">save_html</span><span class="p">(</span><span class="n">prepared_data</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>

<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&lt;a href=</span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2"> target=&#39;_blank&#39;&gt;</span><span class="si">{</span><span class="n">filename</span><span class="si">}</span><span class="s2">&lt;/a&gt;&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><a href=../../../assets/extra/lda_basic.html target='_blank'>lda_basic.html</a></div></div>
</div>
</section>
<section id="lda-coherence">
<h3>LDA coherence<a class="headerlink" href="#lda-coherence" title="Permalink to this headline">#</a></h3>
<p>This example shows how to perform a Latent Dirichlet Allocation and calculate coherence of the results.</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate coherence using preset</span>
<span class="k">for</span> <span class="n">preset</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;u_mass&#39;</span><span class="p">,</span> <span class="s1">&#39;c_uci&#39;</span><span class="p">,</span> <span class="s1">&#39;c_npmi&#39;</span><span class="p">,</span> <span class="s1">&#39;c_v&#39;</span><span class="p">):</span>
    <span class="n">coh</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">Coherence</span><span class="p">(</span><span class="n">mdl</span><span class="p">,</span> <span class="n">coherence</span><span class="o">=</span><span class="n">preset</span><span class="p">)</span>
    <span class="n">average_coherence</span> <span class="o">=</span> <span class="n">coh</span><span class="o">.</span><span class="n">get_score</span><span class="p">()</span>
    <span class="n">coherence_per_topic</span> <span class="o">=</span> <span class="p">[</span><span class="n">coh</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">topic_id</span><span class="o">=</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;==== Coherence : </span><span class="si">{}</span><span class="s1"> ====&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">preset</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average:&#39;</span><span class="p">,</span> <span class="n">average_coherence</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Per Topic:&#39;</span><span class="p">,</span> <span class="n">coherence_per_topic</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==== Coherence : u_mass ====
Average: -1.2919665389931534 
Per Topic: [-1.17386418557316, -0.8680202687611864, -1.9011274512865044, -1.047667736559903, -0.8366067935289703, -1.0824157815953828, -1.0848464209397464, -1.042256352533198, -2.040907684969454, -0.9648597265277666, -0.6370809895484615, -1.0602086759498055, -0.9300058656023976, -0.8755223027370869, -3.8756595693460896, -0.9561534903362163, -1.0182683509407169, -1.0452619935102012, -0.8683999688876635, -1.6542543949045063, -0.9976812325252717, -1.3517324017228247, -1.4340397599847348, -1.1336003900525302, -3.3037643601664413, -0.9452589069885053, -1.3000326329631926, -1.1188280272579738, -1.1003419572424118, -1.1103284968522937]

==== Coherence : c_uci ====
Average: -4.878004424663513 
Per Topic: [-1.4440664765834577, -2.9780619010239433, -8.708752137868833, -3.0050339171614286, -3.9756801762639395, -5.2244161333617765, -6.687473406288814, -4.228681125865242, -7.003535776093569, -3.3012711354385487, -0.9000521475110517, -3.7900076427042646, -3.7450666628395886, -3.05733166371, -7.122763804824756, -4.240481845103053, -5.210568908088681, -3.822197030576038, -4.042555006747717, -8.432800473204122, -4.129114331246837, -4.856754672889186, -4.192296480531112, -5.375999981840818, -10.244442932288125, -1.8611091058190008, -7.7178064083191105, -2.0541820205768704, -5.6412571244580745, -9.346372310677454]

==== Coherence : c_npmi ====
Average: -0.1325481235208962 
Per Topic: [0.017405643466831665, -0.06713514820217745, -0.250626658245578, -0.04635542135098983, -0.12268777150029593, -0.1647925543989872, -0.19153348461822214, -0.11479310813952832, -0.20325291559000797, -0.05933672775478992, -0.01312994262040823, -0.10370859429506546, -0.12495710347546096, -0.08055725886583803, -0.18367815044046804, -0.1056187907799229, -0.16950989984821221, -0.1013101627858306, -0.12513122278003186, -0.23018273615527657, -0.13565862607035908, -0.14425460236335147, -0.029011488535021748, -0.16785973124959508, -0.3279976915096982, -0.03667616244336371, -0.25424020821444454, 0.04555992891405496, -0.15709031459299314, -0.32832280118185425]

==== Coherence : c_v ====
Average: 0.5564370689820499 
Per Topic: [0.5011142507195473, 0.5537001609802246, 0.6300975859165192, 0.6528063505887985, 0.5177711397409439, 0.4293242484331131, 0.593023756146431, 0.687737911939621, 0.48875993937253953, 0.6143026351928711, 0.4760036665014923, 0.4910168096423149, 0.4035642951726913, 0.5804461449384689, 0.6122414320707321, 0.5381382368505001, 0.5088414877653122, 0.5503150254487992, 0.49591032415628433, 0.6861237555742263, 0.4793075716122985, 0.5599398672580719, 0.6356056213378907, 0.5512014642357826, 0.6266018450260162, 0.5769483402371407, 0.5394160777330399, 0.6937022149562836, 0.5420901507139206, 0.4770597591996193]
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">itertools</span>
<span class="c1"># calculate coherence using custom combination</span>
<span class="k">for</span> <span class="n">seg</span><span class="p">,</span> <span class="n">cm</span><span class="p">,</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">Segmentation</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">ConfirmMeasure</span><span class="p">,</span> <span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">IndirectMeasure</span><span class="p">):</span>
    <span class="n">coh</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">Coherence</span><span class="p">(</span><span class="n">mdl</span><span class="p">,</span> <span class="n">coherence</span><span class="o">=</span><span class="p">(</span><span class="n">tp</span><span class="o">.</span><span class="n">coherence</span><span class="o">.</span><span class="n">ProbEstimation</span><span class="o">.</span><span class="n">DOCUMENT</span><span class="p">,</span> <span class="n">seg</span><span class="p">,</span> <span class="n">cm</span><span class="p">,</span> <span class="n">im</span><span class="p">))</span>
    <span class="n">average_coherence</span> <span class="o">=</span> <span class="n">coh</span><span class="o">.</span><span class="n">get_score</span><span class="p">()</span>
    <span class="n">coherence_per_topic</span> <span class="o">=</span> <span class="p">[</span><span class="n">coh</span><span class="o">.</span><span class="n">get_score</span><span class="p">(</span><span class="n">topic_id</span><span class="o">=</span><span class="n">k</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">)]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;==== Coherence : </span><span class="si">{}</span><span class="s1">, </span><span class="si">{}</span><span class="s1">, </span><span class="si">{}</span><span class="s1"> =S===&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">repr</span><span class="p">(</span><span class="n">seg</span><span class="p">),</span> <span class="nb">repr</span><span class="p">(</span><span class="n">cm</span><span class="p">),</span> <span class="nb">repr</span><span class="p">(</span><span class="n">im</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Average:&#39;</span><span class="p">,</span> <span class="n">average_coherence</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Per Topic:&#39;</span><span class="p">,</span> <span class="n">coherence_per_topic</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.1351874610643829 
Per Topic: [0.11101613159001103, 0.14175311097344043, 0.16218523657111322, 0.18403090427713625, 0.13375353018989322, 0.11100999661663936, 0.11403467499327492, 0.19470537423940926, 0.09631062974767758, 0.16263582197968346, 0.13661738585142094, 0.11390028382623481, 0.11258613327854435, 0.1902236282755808, 0.1258461538435896, 0.1319174081261988, 0.11790130382631658, 0.101183821270789, 0.13940305217600987, 0.16222103513433575, 0.11832280151689759, 0.09788931234235808, 0.1759731325287265, 0.1419625983771921, 0.12283456255415204, 0.11983944773489327, 0.1397846799755621, 0.17328171317695196, 0.12248752611724914, 0.10001244082020401]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.351438074447317 
Per Topic: [0.33813833362526363, 0.430223838157124, 0.2877488086620967, 0.459748269058764, 0.37483677003118726, 0.3659698486328125, 0.3136667526430554, 0.4313059644566642, 0.3343541645341449, 0.451196633776029, 0.3850690140078465, 0.40851979123221505, 0.29808357678767705, 0.5845632533232371, 0.1891543977169527, 0.32126699541178017, 0.3908944098485841, 0.3035161207119624, 0.34076554398569797, 0.3225314312924941, 0.3825223781996303, 0.29911605285273657, 0.3335316630287303, 0.3914314246426026, 0.2338264191316234, 0.35029977937018786, 0.3607129294011328, 0.31518845558166503, 0.2355661774882012, 0.30939303582741157]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -0.8293424091943761 
Per Topic: [0.007356486366026932, 0.09002556798255278, -19.3119921805544, 0.0981799298690425, 0.041860342708726725, 0.058977754372689456, -0.42121727665782804, -1.2304922645497653, 0.02389199184771213, 0.030123389098379347, 0.04062372690273656, 0.0743200851811303, -0.056963336705747575, 0.18184349636236827, -1.326329428785377, -0.430772896633587, 0.013559697485632367, -0.07364538814872504, -0.016037708872722253, -0.8799245460269352, 0.06188205188243753, -0.0832902544281549, -0.006324527770306708, 0.02566142504931324, -0.44272010181254395, -0.1809079928504717, -0.06870913652399192, -0.8275042325607501, -0.256899498630729, -0.014847449427987967]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.05052750938504081 
Per Topic: [0.028326774704166585, 0.1131498378701508, -0.3143009778112173, 0.11495007860163847, 0.05273476496545805, 0.07745150006893609, -0.19890510874489944, -0.4506096941108505, 0.03240897646173835, 0.05276763825159934, 0.07799616557442479, 0.10300765294167731, 0.029785138120253882, 0.22646935797399945, -0.30842970315780904, -0.21479199138056074, 0.04015165230052339, -0.06290167171715035, 0.03329444641454352, -0.3777039244822744, 0.0837298682696807, -0.048015411863000027, 0.0031752510759462086, 0.06049309560718636, -0.2972231205811517, -0.10548304048522066, -0.04337195058696024, -0.14943984682775205, -0.09097979786909288, 0.016438758864791857]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.7045623505630207 
Per Topic: [1.5266369490971852, 1.5463879113428056, 2.5005275414844204, 2.6211654329045535, 1.615207291260249, 1.4244162026935911, 1.524343961603905, 1.8431163771644157, 1.4003549336881114, 1.482846216572118, 1.3435245777160014, 1.4048138054696506, 1.3353415497716667, 1.7875376955323294, 1.9259544157948747, 1.4914559665787048, 1.5159353629304715, 1.3652218150352202, 1.4493477040020373, 2.7839088670144436, 1.3712513309499346, 1.4650723061795412, 2.5894590816212744, 1.6079433553160218, 1.9996923130945299, 1.4098756572162499, 1.7141295931091425, 2.025746019068962, 1.6136944791990455, 1.451961803479181]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.8551825504170523 
Per Topic: [0.8568254854944017, 0.906697412331899, 0.7271665891011556, 0.8156261616282993, 0.8707838190926446, 0.8924511830012004, 0.8620413064956665, 0.8509526835547553, 0.8582547346750895, 0.9164952185418871, 0.937135538789961, 0.9030599276224772, 0.9020455718040467, 0.9209719644652472, 0.7183065354824066, 0.8972178141276042, 0.8740266468789842, 0.8944442338413663, 0.9104682432280646, 0.6893860750728183, 0.926681931813558, 0.8576761537128025, 0.7724587930573358, 0.8919851157400344, 0.6979990694257948, 0.9129396239916484, 0.8691527287165324, 0.8243044892946879, 0.8304114023844401, 0.8675100591447619]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.3953467755295613 
Per Topic: [0.3952705932988061, 0.4116775261031257, 0.3457771937052409, 0.3738812698258294, 0.3972695622179243, 0.4121724492973752, 0.3927939838833279, 0.39261747068829006, 0.3986912210782369, 0.4234406484497918, 0.4311494575606452, 0.4138374083571964, 0.41399666402075025, 0.4178920825322469, 0.35133889416853586, 0.4098752948972914, 0.4021126025252872, 0.41012402772903445, 0.41826743086179097, 0.3370403753386603, 0.4250685731569926, 0.3981595748000675, 0.35959198474884035, 0.4010718471474118, 0.3426904241243998, 0.41851362850930957, 0.3994131624698639, 0.3785300427012973, 0.3875945382648044, 0.4005433334244622]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.6596688153346381 
Per Topic: [0.6563803288671706, 0.7020963006549411, 0.5323186298211415, 0.6005045566293928, 0.6619628310203552, 0.7054342985153198, 0.6484619776407877, 0.6504347576035394, 0.6657542082998488, 0.736786593331231, 0.759814174969991, 0.7082306557231479, 0.710816662841373, 0.7194733553462558, 0.5525827613141802, 0.6960519154866537, 0.675995961825053, 0.6966831141048008, 0.7229824145634969, 0.5109996477762858, 0.7403956360287136, 0.6643118752373589, 0.5646324700779385, 0.6727087252669864, 0.5272161457273695, 0.720808560318417, 0.6659841272566054, 0.612063941028383, 0.6380366259151035, 0.6701412068472968]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 833248193.1610017 
Per Topic: [2.0082930761066575, 2.0649914529938123, 5.536606056036479, 4074074078.1978583, 2.210945653270672, 1.931628999164661, 2.125470572564088, 2.950515135257185, 1.8025983892937552, 2.373465908815218, 1.8405752408315796, 1.8027322625961777, 1367816093.6748478, 2.8848589893698096, 19555555557.625587, 2.0319740312759507, 1.9730925319655515, 1.6820690483526008, 1.9618860918242997, 4.003495981109249, 1.859194891827816, 1.9271989339005193, 3.968215875053943, 2.4390567261732707, 2.937843376827051, 1.7903929410806272, 2.227756137638969, 2.9174473414104023, 2.1420887517385103, 1.937361064931399]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.7402534365717239 
Per Topic: [0.7901608188947041, 0.843464023537106, 0.4551342276028461, 0.3149481895897124, 0.7948817253112793, 0.8571844696998596, 0.8122045384513007, 0.7541576802730561, 0.8069455133544075, 0.8641168276468912, 0.8905021548271179, 0.8615469124582079, 0.7176932009588028, 0.8644522918595208, 0.27564658059061264, 0.831760479344262, 0.8138297478357951, 0.8520880222320557, 0.8684459182951185, 0.42272013458940716, 0.8856943421893649, 0.8053802145851983, 0.63527436653773, 0.8174244178666009, 0.4379139787207047, 0.8728516340255738, 0.8224291814698114, 0.6472298730578687, 0.7715571337276035, 0.8199644976192051]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.33317976239575325 
Per Topic: [0.3563797414302826, 0.3753472553359138, 0.2330093636364418, 0.1232157862403148, 0.35636063549253677, 0.3826446420616574, 0.3597119006845686, 0.3548059927092658, 0.36521188616752626, 0.394514090485043, 0.40643646253479854, 0.38578488296932645, 0.3188276247833031, 0.3827680640750461, 0.10762037602072624, 0.3783985793590546, 0.3688957737551795, 0.3822804285420312, 0.39233422146903146, 0.18592197238293587, 0.39835565818680657, 0.36646339164839853, 0.29996280868848163, 0.35952309105131364, 0.1976712567250935, 0.3922528200679355, 0.3683128794034322, 0.2780546369890838, 0.3555277672078874, 0.3687988817691803]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.5316045413682643 
Per Topic: [0.5580196784602272, 0.6070075160927243, 0.3320080794477474, 0.19004649233998394, 0.5593037558926477, 0.625640649927987, 0.5640980223814647, 0.5553434246116215, 0.5791655408011542, 0.6549664517243703, 0.6875664088461134, 0.6306196133295695, 0.5326852523605549, 0.6239841527409024, 0.16353459524120556, 0.6113076812691158, 0.5893126898341708, 0.6207689881324768, 0.6512066079510583, 0.2668755257019132, 0.6637576699256897, 0.5820300175084008, 0.4329821487267812, 0.5680274128913879, 0.29369887570285214, 0.6470509966214498, 0.5842362410492368, 0.4285337212423949, 0.557279497385025, 0.5870785329076978]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.5405859769669961 
Per Topic: [0.5826810441083398, 0.6660489351224613, 0.359891652097845, 1.321096407409169, 0.6701883879830325, 0.5319959935158121, 0.5658087696202627, 0.9456190446093845, -0.11162484937707866, 0.7352332243367302, 0.5597643057419147, 0.522965590300311, 0.7758243685876923, 0.8836533972493942, -1.1621559621911957, 0.6014894707978905, 0.5812047616908983, 0.4615187886617018, 0.6076949115341027, 1.0887713264147822, 0.5399529510350565, 0.4875531804415069, 1.1033524638471561, 0.6779175245241125, -1.0429912454491495, 0.5440375487491753, 0.6974779167686911, 0.904638576448713, 0.6177343167893081, 0.5002365076418617]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.11935449063389972 
Per Topic: [0.09104066548170522, 0.06104483656365321, 0.3093050652080112, 0.28175778368280996, 0.08212855363470023, 0.008025267011382514, 0.12080522253006873, 0.1865225060661841, 0.030552612939532587, 0.1300905320340664, 0.059253980701517626, 0.041128822967099646, -0.013953080879420869, 0.09569137090713614, 0.17172210053023365, 0.13141210740238118, 0.09200627624264193, 0.09485439706542012, 0.03239099182925808, 0.3284517904122671, 0.029139023562897312, 0.09320585189982214, 0.20915542462219794, 0.14141440639117112, 0.19086722037431578, 0.07778486348171201, 0.1352714304941603, 0.24153346777929982, 0.08869124026872062, 0.039339987812046374]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 9.764055218641406 
Per Topic: [1.4785268584887186, 8.029365785916646, 0.9702214002609253, 1.8041651871469286, 6.375461806191338, -0.7050536228550806, 1.4947402609719171, 2.4129498998324075, 3.9956230812602573, 5.715696952078077, -3.1508254329363505, -3.0207321961720783, -0.4067401882674959, 1.2127181026670668, 1.1320184853341844, 211.9972156604131, 1.2562444779607984, 1.7112665004200405, -0.5146351165241665, 0.9359890752368503, -4.61125920481152, 5.525151567988925, 39.07899330457052, 1.171814935737186, 0.9255641990237766, 2.0271761390897964, 1.5980050881703696, 1.2008336848682828, 1.1204772697554695, 2.160682597425249]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -20.825088196727965 
Per Topic: [-2.7075881520907084, -2.272716283135944, 3.2274680429034763, 8.821884269184537, -4.040207725101047, -2.5036019414663313, -0.882104041841295, 18.635549034012687, -1.0613703462812636, -3.0882180836465625, -1.289473260111279, -2.3885018050670626, -2.2382670289940303, -2.2146502597464455, -0.25286320050557454, -6.070304331514571, -3.884779371155633, -2.4781847609413994, -2.379622534248564, -604.0762025992076, -1.6511220229996575, -0.15254030227661133, -5.448412187894186, -3.880208917458852, 4.612057495117187, -3.180569440788693, -3.9969701210657758, -0.6741435077455309, 6.395788433154424, -3.6327709509266746]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.2978416590213351 
Per Topic: [0.3780543494180079, 0.41296956919561634, 0.18980654629698537, 0.7691373178155088, 0.43306236075249366, 0.309001147774482, 0.3558471752030721, 0.5755005634088165, -0.2125246165440904, 0.3698390002038444, 0.28614394288966083, 0.3204577164651875, 0.2715209622206862, 0.5262686189508873, -1.423538163168902, 0.3624002845095718, 0.3701383246947222, 0.2877505226455023, 0.3516867899079114, 0.8617703727076176, 0.29600534443070325, 0.3136588599661505, 0.839832037893, 0.4166274363483794, -0.9223808370094703, 0.3299575706066555, 0.48694471889678254, 0.6346445910731934, 0.4248759551503945, 0.31979130793668337]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.17994302767120876 
Per Topic: [0.12805647044959995, 0.11670115184194098, 0.32550658281478617, 0.3205361928480367, 0.1428330622962676, 0.17555796836192408, 0.16637061934840555, 0.2242692696241041, 0.06496669764682236, 0.2734027441797985, 0.23776455167163577, 0.1406386292203226, 0.10335524227573639, 0.2027769971690658, 0.1911078766376401, 0.19030399062256848, 0.15196374676500757, 0.13059370080526506, 0.12559629707700676, 0.3441504937079218, 0.1384310316397912, 0.1333530227472592, 0.21875141391323671, 0.17642224971204995, 0.20602956772264508, 0.14699623237570955, 0.16957532687520144, 0.2709827545409401, 0.10145181030060889, 0.07984513494496544]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 2.7841405712333676 
Per Topic: [1.666050275001261, 0.6319933338297739, 0.9500268008973863, 1.0386896597014532, 2.250735392794013, 0.2756188680003915, 0.17857569058736164, 0.9083827204174466, -2.425627151255806, 0.8707619605792893, -0.2592729784548283, -0.19907247605216172, 0.802290514152911, 0.8496030672556825, 1.077572684817844, 1.2845817714929582, 3.02141981518103, 1.3063109305169847, -0.03761112979716725, 0.9118721087773641, -0.33338644554217656, 1.1887123200628493, 1.0431044512324863, 1.445079586075412, 0.9786576999558343, 61.388298433356816, 1.0510625998179117, 1.1705422348446317, 1.6549388404418197, -1.1656944416877297]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 7.0628127242821375 
Per Topic: [-9.166540891263221, -2.342065739466084, -6.15212869114346, -43.87733449406094, 56.44401636720738, -2.6669036716222765, 1.8036339667108323, 0.8181499573919508, -3.2101934199945794, -3.841389800608158, -1.0703579567372798, -2.519921213326355, -4.007283565733168, -2.817425860464573, -3.0735806226730347, -1.983945485121674, -5.066192412128051, -8.380187131961186, -2.8874885131087566, -4.33076155450609, -1.4770257814062966, -2.8912580755021837, 289.9129321826829, -3.833444407582283, -8.179676280419033, -4.677306281195746, -2.820743430985345, 2.5057655387454565, -4.367011500419014, -3.959949502845605]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.1766937747568545 
Per Topic: [0.14824682586212107, 0.18708438146379341, 0.20281956968249248, 0.24425282842966542, 0.17419189085101458, 0.14265440707643529, 0.14944404510495848, 0.2521999987572534, 0.10834079577106827, 0.2163301201716118, 0.19242175789761948, 0.15242108698649745, 0.15412284717444524, 0.24714972156952805, 0.11141293530537302, 0.17405880215656602, 0.15648258888424169, 0.13498831971804393, 0.1852731795046233, 0.2408658489817811, 0.15769056713778093, 0.12939673533270415, 0.25091810534198355, 0.18260028518696703, 0.12661959749425444, 0.15883896199371866, 0.18870800407669353, 0.2339521853385075, 0.16486529111142129, 0.1324615583424696]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.30799426429340176 
Per Topic: [0.2577278188119332, 0.36455040506811603, 0.27655373497141733, 0.37316074293080925, 0.30523637334505715, 0.31315051799433097, 0.25819794668091667, 0.3904047669635879, 0.226201621008416, 0.4634987852639622, 0.43473703985412915, 0.3618507874508699, 0.286240578111675, 0.5096372005012301, 0.16657824232760404, 0.31665071715186865, 0.29665989984447755, 0.26487721796664926, 0.34197703417804504, 0.3128788981690175, 0.3643739732810193, 0.22974988263514307, 0.2334528881435593, 0.34796334778269133, 0.1884039598180809, 0.3390489612188604, 0.2937325588117043, 0.29894404822132653, 0.18890943971152108, 0.2344785405840311]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -6.696977050953278 
Per Topic: [-0.501081607511474, -0.058775322056478924, -5.950174129340383, -1.0146991021827692, -0.19650192408718997, -0.5972039008306133, 68.61222103497842, -0.5676436835382548, -0.43249382376670836, -0.2505337163909442, 0.004097158461809159, -0.45448160244462393, 2.5815661487686965, 0.10029054445525011, 3.3434767007827757, -12.810671669674209, -0.8501870264609654, -0.34551202019469607, 13.165061561514934, 0.3700122098128001, -0.013202836861213048, 0.8229714737584194, -0.018339197296235295, -0.1298573174048215, -0.5295765637523598, -270.0585608153294, -0.7114471904726491, 5.680398739212089, 0.04282868843939569, -0.14129233918696021]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 2.1071468107418276 
Per Topic: [-0.2321656532999542, -0.009382950059241718, -1.7773478090763093, -0.3373492727159626, -0.12773477082244225, -0.14153379789657064, -0.58121748691968, -0.5889425377361477, -0.20039150988062224, -0.03989723877360423, 0.0805715151131153, -0.027872106507937942, -0.122680844925344, 0.12404205043696695, -1.1835544238487878, -0.5044889359683212, -0.24931146192053955, -0.21346006609706414, -0.1409227941185236, 9.27308953884575, 0.0325390866647164, -0.3664802716837989, -0.6178307306435373, -0.08279434137253297, 63.20406588969959, -0.19907079886438117, -0.30779310458650194, -0.6767237674030993, -0.5674934085458517, -0.2034636748385512]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -1.2272521961226583 
Per Topic: [-1.1493610416512177, -0.9092812064780683, -1.970326895536801, -1.209571909913137, -1.0353222293274311, -0.9238462153413554, -1.1178646906898124, -0.9071476677119651, -1.7523576293806506, -0.7866509199609911, -0.6362178372900401, -0.9782684757568221, -0.8257068116299219, -0.7863431660657688, -3.6965884747288964, -0.9244933878967375, -1.0690041290183774, -0.9893611453220097, -0.795524288275124, -1.504613733026627, -0.7923858074358401, -1.1512319143641574, -1.2850092927096146, -0.9458022725617946, -3.164209136644416, -0.8555574890591362, -1.1133245636868838, -1.171646059376813, -1.200905406979172, -1.1696420858601588]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.4489587392133696 
Per Topic: [0.4172645108567344, 0.3680855777528551, 0.47551360925038655, 0.46617349055078294, 0.42326092951827576, 0.6414405763149261, 0.38452149331569674, 0.4236492501364814, 0.45179317759142984, 0.4734817637337579, 0.513688063621521, 0.4954831686284807, 0.5364161756303575, 0.4674039426777098, 0.3921919425328573, 0.45504247943560283, 0.40978858404689367, 0.34588676674498453, 0.4799913730886247, 0.5026300244861179, 0.48717684911357034, 0.3698685281806522, 0.45938059820069205, 0.48731302552753025, 0.452699175145891, 0.40655995971626707, 0.4119377543528875, 0.42373811536365086, 0.4009397059679031, 0.44544156491756437]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.7170875298093867 
Per Topic: [0.7426078796386719, 0.7015290180842082, 0.7337837298711141, 0.7339953780174255, 0.7182757245169745, 0.7243074602550931, 0.7232087903552585, 0.7609699527422588, 0.7437359650929769, 0.704906948407491, 0.6405402686860826, 0.6788614100880093, 0.7135660039054023, 0.6997373965051439, 0.7442686306105719, 0.7021779139836629, 0.7368649337026808, 0.714368814892239, 0.682016827000512, 0.7392514573203193, 0.7062499708599514, 0.7357237325774298, 0.7286302831437853, 0.7034077525138855, 0.7649813916948106, 0.6894622564315795, 0.6908912089135911, 0.7162305646472507, 0.7261502756012811, 0.7119239542219374]

==== Coherence : &lt;Segmentation.ONE_ONE: 1&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 2.9189544194716004 
Per Topic: [3.515099125438266, 2.5720635890960692, 3.0092657830980087, 3.2807204246521, 2.874766953786214, 3.7289518859651354, 2.8617791864607067, 3.7924955818388195, 3.4049933248096043, 2.7408284081353083, 1.896372185813056, 2.4040002981821695, 3.1123066107432047, 2.618385820918613, 3.2927805900573732, 2.509185202916463, 3.3346821069717407, 2.619035180409749, 2.6232512129677668, 3.124668386247423, 2.6490831957923042, 3.215196074379815, 2.9361532661649914, 2.5999829795625473, 3.845041184955173, 2.3929948170979816, 2.3027957253985933, 2.6045406103134154, 2.966953155729506, 2.740259716245863]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.1259989069056579 
Per Topic: [0.1061245305061154, 0.14334851156873857, 0.16778857356312876, 0.20327777777305223, 0.1617922072094629, 0.08897302425204513, 0.11153553343618199, 0.1664350771921802, 0.06624612605006143, 0.13548263442620365, 0.1378050723416717, 0.10646782095923937, 0.10722655288680988, 0.16845434930938016, 0.10646723646540263, 0.12095094119498716, 0.1218401308467869, 0.09246942280151692, 0.12911488191024367, 0.14767602767328883, 0.09694586040870846, 0.08211303852897013, 0.15206043846975117, 0.11745118766041761, 0.10556810678833571, 0.10622589196313859, 0.11827787994978789, 0.17570182084653996, 0.12563702444193925, 0.11050952574565061]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.351438074447317 
Per Topic: [0.33813833362526363, 0.430223838157124, 0.2877488086620967, 0.459748269058764, 0.37483677003118726, 0.3659698486328125, 0.3136667526430554, 0.4313059644566642, 0.3343541645341449, 0.451196633776029, 0.3850690140078465, 0.40851979123221505, 0.29808357678767705, 0.5845632533232371, 0.1891543977169527, 0.32126699541178017, 0.3908944098485841, 0.3035161207119624, 0.34076554398569797, 0.3225314312924941, 0.3825223781996303, 0.29911605285273657, 0.3335316630287303, 0.3914314246426026, 0.2338264191316234, 0.35029977937018786, 0.3607129294011328, 0.31518845558166503, 0.2355661774882012, 0.30939303582741157]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -0.8293424091943761 
Per Topic: [0.007356486366026932, 0.09002556798255278, -19.3119921805544, 0.0981799298690425, 0.041860342708726725, 0.058977754372689456, -0.42121727665782804, -1.2304922645497653, 0.02389199184771213, 0.030123389098379347, 0.04062372690273656, 0.0743200851811303, -0.056963336705747575, 0.18184349636236827, -1.326329428785377, -0.430772896633587, 0.013559697485632367, -0.07364538814872504, -0.016037708872722253, -0.8799245460269352, 0.06188205188243753, -0.0832902544281549, -0.006324527770306708, 0.02566142504931324, -0.44272010181254395, -0.1809079928504717, -0.06870913652399192, -0.8275042325607501, -0.256899498630729, -0.014847449427987967]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.05052750938504081 
Per Topic: [0.028326774704166585, 0.1131498378701508, -0.3143009778112173, 0.11495007860163847, 0.05273476496545805, 0.07745150006893609, -0.19890510874489944, -0.4506096941108505, 0.03240897646173835, 0.05276763825159934, 0.07799616557442479, 0.10300765294167731, 0.029785138120253882, 0.22646935797399945, -0.30842970315780904, -0.21479199138056074, 0.04015165230052339, -0.06290167171715035, 0.03329444641454352, -0.3777039244822744, 0.0837298682696807, -0.048015411863000027, 0.0031752510759462086, 0.06049309560718636, -0.2972231205811517, -0.10548304048522066, -0.04337195058696024, -0.14943984682775205, -0.09097979786909288, 0.016438758864791857]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.7045623505630207 
Per Topic: [1.5266369490971856, 1.5463879113428052, 2.500527541484421, 2.6211654329045517, 1.6152072912602486, 1.4244162026935918, 1.5243439616039047, 1.8431163771644155, 1.4003549336881116, 1.4828462165721186, 1.3435245777160023, 1.4048138054696502, 1.3353415497716672, 1.7875376955323292, 1.9259544157948747, 1.4914559665787055, 1.5159353629304713, 1.3652218150352202, 1.4493477040020368, 2.7839088670144436, 1.3712513309499348, 1.4650723061795419, 2.5894590816212744, 1.607943355316022, 1.9996923130945297, 1.4098756572162503, 1.7141295931091431, 2.025746019068962, 1.6136944791990455, 1.451961803479182]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.8551825504170523 
Per Topic: [0.8568254854944017, 0.906697412331899, 0.7271665891011556, 0.8156261616282993, 0.8707838190926446, 0.8924511830012004, 0.8620413064956665, 0.8509526835547553, 0.8582547346750895, 0.9164952185418871, 0.937135538789961, 0.9030599276224772, 0.9020455718040467, 0.9209719644652472, 0.7183065354824066, 0.8972178141276042, 0.8740266468789842, 0.8944442338413663, 0.9104682432280646, 0.6893860750728183, 0.926681931813558, 0.8576761537128025, 0.7724587930573358, 0.8919851157400344, 0.6979990694257948, 0.9129396239916484, 0.8691527287165324, 0.8243044892946879, 0.8304114023844401, 0.8675100591447619]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.3953467755295613 
Per Topic: [0.3952705932988061, 0.4116775261031257, 0.3457771937052409, 0.3738812698258294, 0.3972695622179243, 0.4121724492973752, 0.3927939838833279, 0.39261747068829006, 0.3986912210782369, 0.4234406484497918, 0.4311494575606452, 0.4138374083571964, 0.41399666402075025, 0.4178920825322469, 0.35133889416853586, 0.4098752948972914, 0.4021126025252872, 0.41012402772903445, 0.41826743086179097, 0.3370403753386603, 0.4250685731569926, 0.3981595748000675, 0.35959198474884035, 0.4010718471474118, 0.3426904241243998, 0.41851362850930957, 0.3994131624698639, 0.3785300427012973, 0.3875945382648044, 0.4005433334244622]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.6596688153346381 
Per Topic: [0.6563803288671706, 0.7020963006549411, 0.5323186298211415, 0.6005045566293928, 0.6619628310203552, 0.7054342985153198, 0.6484619776407877, 0.6504347576035394, 0.6657542082998488, 0.736786593331231, 0.759814174969991, 0.7082306557231479, 0.710816662841373, 0.7194733553462558, 0.5525827613141802, 0.6960519154866537, 0.675995961825053, 0.6966831141048008, 0.7229824145634969, 0.5109996477762858, 0.7403956360287136, 0.6643118752373589, 0.5646324700779385, 0.6727087252669864, 0.5272161457273695, 0.720808560318417, 0.6659841272566054, 0.612063941028383, 0.6380366259151035, 0.6701412068472968]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1014644532.1307074 
Per Topic: [2.0716905148356126, 2.045420831647486, 6.179741581835933, 8148148151.5435505, 1.96388427810584, 2.1567399942720877, 2.1689504559035084, 3.295981720050152, 2.031448664028519, 2.761785608553607, 1.817477707696492, 1.8154245281843358, 2735632185.589626, 3.2561513797552215, 19555555557.634724, 2.1183098679418264, 1.9320395422644892, 1.742234440291489, 2.0395844394243032, 4.133499290822854, 2.070774345681312, 2.1017326507876506, 4.527260013181598, 2.805270916317296, 3.061376765367417, 1.8785028352814224, 2.348135626366958, 2.8691604139030074, 2.207386240153904, 1.7533559920550403]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.7402534365717239 
Per Topic: [0.7901608188947041, 0.843464023537106, 0.4551342276028461, 0.3149481895897124, 0.7948817253112793, 0.8571844696998596, 0.8122045384513007, 0.7541576802730561, 0.8069455133544075, 0.8641168276468912, 0.8905021548271179, 0.8615469124582079, 0.7176932009588028, 0.8644522918595208, 0.27564658059061264, 0.831760479344262, 0.8138297478357951, 0.8520880222320557, 0.8684459182951185, 0.42272013458940716, 0.8856943421893649, 0.8053802145851983, 0.63527436653773, 0.8174244178666009, 0.4379139787207047, 0.8728516340255738, 0.8224291814698114, 0.6472298730578687, 0.7715571337276035, 0.8199644976192051]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.33317976239575325 
Per Topic: [0.3563797414302826, 0.3753472553359138, 0.2330093636364418, 0.1232157862403148, 0.35636063549253677, 0.3826446420616574, 0.3597119006845686, 0.3548059927092658, 0.36521188616752626, 0.394514090485043, 0.40643646253479854, 0.38578488296932645, 0.31882762478330307, 0.3827680640750461, 0.10762037602072623, 0.3783985793590546, 0.3688957737551795, 0.3822804285420312, 0.39233422146903146, 0.18592197238293587, 0.39835565818680657, 0.36646339164839853, 0.29996280868848163, 0.35952309105131364, 0.19767125672509347, 0.3922528200679355, 0.3683128794034322, 0.2780546369890838, 0.3555277672078874, 0.3687988817691803]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.5316045413682643 
Per Topic: [0.5580196784602272, 0.6070075160927243, 0.3320080794477474, 0.19004649233998394, 0.5593037558926477, 0.625640649927987, 0.5640980223814647, 0.5553434246116215, 0.5791655408011542, 0.6549664517243703, 0.6875664088461134, 0.6306196133295695, 0.532685252360555, 0.6239841527409024, 0.1635345952412056, 0.6113076812691158, 0.5893126898341708, 0.6207689881324768, 0.6512066079510583, 0.26687552570191325, 0.6637576699256897, 0.5820300175084008, 0.4329821487267812, 0.5680274128913879, 0.29369887570285214, 0.6470509966214498, 0.5842362410492368, 0.4285337212423949, 0.557279497385025, 0.5870785329076978]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.5844497149251596 
Per Topic: [0.5936046262814404, 0.6503789352872539, 0.35685782028959667, 1.5368331864793847, 0.5886256409357892, 0.5971336365555293, 0.5579301101135489, 1.0312153663442274, -0.015801263126963696, 0.8471407045467768, 0.5532432510658585, 0.5334630190756529, 1.0494534604589918, 0.9489622076240566, -1.1309658679251207, 0.6300692686554132, 0.5668640611007268, 0.48795462530517447, 0.6444204216480794, 1.1198775447601903, 0.6320095574554566, 0.5382207289094766, 1.1684190336359297, 0.7448662141188256, -1.003586996406117, 0.5806891532275694, 0.74467025670524, 0.9061688786978715, 0.6163566360309041, 0.458417229904026]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.11935449063389972 
Per Topic: [0.09104066548170522, 0.06104483656365321, 0.3093050652080112, 0.28175778368280996, 0.08212855363470023, 0.008025267011382514, 0.12080522253006873, 0.1865225060661841, 0.030552612939532587, 0.1300905320340664, 0.059253980701517626, 0.041128822967099646, -0.013953080879420869, 0.09569137090713614, 0.17172210053023365, 0.13141210740238118, 0.09200627624264193, 0.09485439706542012, 0.03239099182925808, 0.3284517904122671, 0.029139023562897312, 0.09320585189982214, 0.20915542462219794, 0.14141440639117112, 0.19086722037431578, 0.07778486348171201, 0.1352714304941603, 0.24153346777929982, 0.08869124026872062, 0.039339987812046374]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 9.764055218641406 
Per Topic: [1.4785268584887186, 8.029365785916646, 0.9702214002609253, 1.8041651871469286, 6.375461806191338, -0.7050536228550806, 1.4947402609719171, 2.4129498998324075, 3.9956230812602573, 5.715696952078077, -3.1508254329363505, -3.0207321961720783, -0.4067401882674959, 1.2127181026670668, 1.1320184853341844, 211.9972156604131, 1.2562444779607984, 1.7112665004200405, -0.5146351165241665, 0.9359890752368503, -4.61125920481152, 5.525151567988925, 39.07899330457052, 1.171814935737186, 0.9255641990237766, 2.0271761390897964, 1.5980050881703696, 1.2008336848682828, 1.1204772697554695, 2.160682597425249]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -20.825088196727965 
Per Topic: [-2.7075881520907084, -2.272716283135944, 3.2274680429034763, 8.821884269184537, -4.040207725101047, -2.5036019414663313, -0.882104041841295, 18.635549034012687, -1.0613703462812636, -3.0882180836465625, -1.289473260111279, -2.3885018050670626, -2.2382670289940303, -2.2146502597464455, -0.25286320050557454, -6.070304331514571, -3.884779371155633, -2.4781847609413994, -2.379622534248564, -604.0762025992076, -1.6511220229996575, -0.15254030227661133, -5.448412187894186, -3.880208917458852, 4.612057495117187, -3.180569440788693, -3.9969701210657758, -0.6741435077455309, 6.395788433154424, -3.6327709509266746]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.2978416590213352 
Per Topic: [0.3780543494180079, 0.4129695691956162, 0.18980654629698515, 0.7691373178155086, 0.4330623607524941, 0.30900114777448207, 0.355847175203072, 0.5755005634088165, -0.2125246165440904, 0.36983900020384447, 0.28614394288966066, 0.3204577164651876, 0.2715209622206863, 0.5262686189508876, -1.4235381631689017, 0.362400284509572, 0.37013832469472235, 0.28775052264550244, 0.35168678990791136, 0.8617703727076175, 0.2960053444307032, 0.31365885996615045, 0.8398320378929996, 0.4166274363483794, -0.9223808370094702, 0.3299575706066556, 0.48694471889678254, 0.6346445910731939, 0.42487595515039467, 0.3197913079366835]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.17994302767120876 
Per Topic: [0.12805647044959995, 0.11670115184194098, 0.32550658281478617, 0.3205361928480367, 0.1428330622962676, 0.17555796836192408, 0.16637061934840555, 0.2242692696241041, 0.06496669764682236, 0.2734027441797985, 0.23776455167163577, 0.1406386292203226, 0.10335524227573639, 0.2027769971690658, 0.1911078766376401, 0.19030399062256848, 0.15196374676500757, 0.13059370080526506, 0.12559629707700676, 0.3441504937079218, 0.1384310316397912, 0.1333530227472592, 0.21875141391323671, 0.17642224971204995, 0.20602956772264508, 0.14699623237570955, 0.16957532687520144, 0.2709827545409401, 0.10145181030060889, 0.07984513494496544]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 2.7841405712333676 
Per Topic: [1.666050275001261, 0.6319933338297739, 0.9500268008973863, 1.0386896597014532, 2.250735392794013, 0.2756188680003915, 0.17857569058736164, 0.9083827204174466, -2.425627151255806, 0.8707619605792893, -0.2592729784548283, -0.19907247605216172, 0.802290514152911, 0.8496030672556825, 1.077572684817844, 1.2845817714929582, 3.02141981518103, 1.3063109305169847, -0.03761112979716725, 0.9118721087773641, -0.33338644554217656, 1.1887123200628493, 1.0431044512324863, 1.445079586075412, 0.9786576999558343, 61.388298433356816, 1.0510625998179117, 1.1705422348446317, 1.6549388404418197, -1.1656944416877297]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 7.0628127242821375 
Per Topic: [-9.166540891263221, -2.342065739466084, -6.15212869114346, -43.87733449406094, 56.44401636720738, -2.6669036716222765, 1.8036339667108323, 0.8181499573919508, -3.2101934199945794, -3.841389800608158, -1.0703579567372798, -2.519921213326355, -4.007283565733168, -2.817425860464573, -3.0735806226730347, -1.983945485121674, -5.066192412128051, -8.380187131961186, -2.8874885131087566, -4.33076155450609, -1.4770257814062966, -2.8912580755021837, 289.9129321826829, -3.833444407582283, -8.179676280419033, -4.677306281195746, -2.820743430985345, 2.5057655387454565, -4.367011500419014, -3.959949502845605]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.1766937747568545 
Per Topic: [0.14824682586212107, 0.18708438146379353, 0.20281956968249237, 0.2442528284296655, 0.1741918908510146, 0.14265440707643534, 0.14944404510495854, 0.25219999875725335, 0.10834079577106827, 0.2163301201716119, 0.19242175789761945, 0.1524210869864975, 0.15412284717444538, 0.247149721569528, 0.111412935305373, 0.17405880215656605, 0.15648258888424163, 0.1349883197180439, 0.18527317950462321, 0.24086584898178115, 0.15769056713778107, 0.1293967353327041, 0.25091810534198355, 0.18260028518696708, 0.12661959749425447, 0.1588389619937186, 0.1887080040766936, 0.2339521853385075, 0.16486529111142117, 0.13246155834246956]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.30799426429340176 
Per Topic: [0.2577278188119332, 0.36455040506811603, 0.27655373497141733, 0.37316074293080925, 0.30523637334505715, 0.31315051799433097, 0.25819794668091667, 0.3904047669635879, 0.226201621008416, 0.4634987852639622, 0.43473703985412915, 0.3618507874508699, 0.286240578111675, 0.5096372005012301, 0.16657824232760404, 0.31665071715186865, 0.29665989984447755, 0.26487721796664926, 0.34197703417804504, 0.3128788981690175, 0.3643739732810193, 0.22974988263514307, 0.2334528881435593, 0.34796334778269133, 0.1884039598180809, 0.3390489612188604, 0.2937325588117043, 0.29894404822132653, 0.18890943971152108, 0.2344785405840311]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -6.696977050953278 
Per Topic: [-0.501081607511474, -0.058775322056478924, -5.950174129340383, -1.0146991021827692, -0.19650192408718997, -0.5972039008306133, 68.61222103497842, -0.5676436835382548, -0.43249382376670836, -0.2505337163909442, 0.004097158461809159, -0.45448160244462393, 2.5815661487686965, 0.10029054445525011, 3.3434767007827757, -12.810671669674209, -0.8501870264609654, -0.34551202019469607, 13.165061561514934, 0.3700122098128001, -0.013202836861213048, 0.8229714737584194, -0.018339197296235295, -0.1298573174048215, -0.5295765637523598, -270.0585608153294, -0.7114471904726491, 5.680398739212089, 0.04282868843939569, -0.14129233918696021]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 2.1071468107418276 
Per Topic: [-0.2321656532999542, -0.009382950059241718, -1.7773478090763093, -0.3373492727159626, -0.12773477082244225, -0.14153379789657064, -0.58121748691968, -0.5889425377361477, -0.20039150988062224, -0.03989723877360423, 0.0805715151131153, -0.027872106507937942, -0.122680844925344, 0.12404205043696695, -1.1835544238487878, -0.5044889359683212, -0.24931146192053955, -0.21346006609706414, -0.1409227941185236, 9.27308953884575, 0.0325390866647164, -0.3664802716837989, -0.6178307306435373, -0.08279434137253297, 63.20406588969959, -0.19907079886438117, -0.30779310458650194, -0.6767237674030993, -0.5674934085458517, -0.2034636748385512]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -1.2919665389931534 
Per Topic: [-1.17386418557316, -0.8680202687611864, -1.9011274512865044, -1.047667736559903, -0.8366067935289703, -1.0824157815953828, -1.0848464209397464, -1.042256352533198, -2.040907684969454, -0.9648597265277666, -0.6370809895484615, -1.0602086759498055, -0.9300058656023976, -0.8755223027370869, -3.8756595693460896, -0.9561534903362163, -1.0182683509407169, -1.0452619935102012, -0.8683999688876635, -1.6542543949045063, -0.9976812325252717, -1.3517324017228247, -1.4340397599847348, -1.1336003900525302, -3.3037643601664413, -0.9452589069885053, -1.3000326329631926, -1.1188280272579738, -1.1003419572424118, -1.1103284968522937]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.4489587392133696 
Per Topic: [0.4172645108567344, 0.3680855777528551, 0.47551360925038655, 0.46617349055078294, 0.42326092951827576, 0.6414405763149261, 0.38452149331569674, 0.4236492501364814, 0.45179317759142984, 0.4734817637337579, 0.513688063621521, 0.4954831686284807, 0.5364161756303575, 0.4674039426777098, 0.3921919425328573, 0.45504247943560283, 0.40978858404689367, 0.34588676674498453, 0.4799913730886247, 0.5026300244861179, 0.48717684911357034, 0.3698685281806522, 0.45938059820069205, 0.48731302552753025, 0.452699175145891, 0.40655995971626707, 0.4119377543528875, 0.42373811536365086, 0.4009397059679031, 0.44544156491756437]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.7170875298093867 
Per Topic: [0.7426078796386719, 0.7015290180842082, 0.7337837298711141, 0.7339953780174255, 0.7182757245169745, 0.7243074602550931, 0.7232087903552585, 0.7609699527422588, 0.7437359650929769, 0.704906948407491, 0.6405402686860826, 0.6788614100880093, 0.7135660039054023, 0.6997373965051439, 0.7442686306105719, 0.7021779139836629, 0.7368649337026808, 0.714368814892239, 0.682016827000512, 0.7392514573203193, 0.7062499708599514, 0.7357237325774298, 0.7286302831437853, 0.7034077525138855, 0.7649813916948106, 0.6894622564315795, 0.6908912089135911, 0.7162305646472507, 0.7261502756012811, 0.7119239542219374]

==== Coherence : &lt;Segmentation.ONE_PRE: 2&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 2.9189544194716004 
Per Topic: [3.515099125438266, 2.5720635890960692, 3.0092657830980087, 3.2807204246521, 2.874766953786214, 3.7289518859651354, 2.8617791864607067, 3.7924955818388195, 3.4049933248096043, 2.7408284081353083, 1.896372185813056, 2.4040002981821695, 3.1123066107432047, 2.618385820918613, 3.2927805900573732, 2.509185202916463, 3.3346821069717407, 2.619035180409749, 2.6232512129677668, 3.124668386247423, 2.6490831957923042, 3.215196074379815, 2.9361532661649914, 2.5999829795625473, 3.845041184955173, 2.3929948170979816, 2.3027957253985933, 2.6045406103134154, 2.966953155729506, 2.740259716245863]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.041999999999236134 
Per Topic: [0.04666666666620373, 0.12999999999861117, 0.03666666666620372, 0.03999999999930559, 0.028888888887808717, 0.19888888888711426, -0.007777777778395056, 0.13777777777700623, 0.0011111111108024763, 0.1388888888878087, 0.028888888887808717, -0.06666666666689813, 0.014444444443209914, -0.06888888888919752, 0.018888888888503125, 0.15333333333240745, 0.028888888887808717, 0.05999999999930558, 0.10666666666550928, 0.02111111111080248, 0.0755555555547068, -0.013333333333796271, 0.05666666666620372, -0.08222222222229938, 0.0011111111108024763, 0.05555555555401248, 0.016666666666203728, 0.15333333333240745, -0.026666666667592542, -0.0244444444452932]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.15673434886460502 
Per Topic: [0.28987571597099304, 0.320284903049469, 0.15148071944713593, 0.20374327898025513, 0.08384250849485397, 0.34609341621398926, 0.01871933601796627, 0.4937671720981598, 0.026877814903855324, 0.40721428394317627, 0.08384250849485397, -0.19972720742225647, 0.2210555225610733, -0.22205013036727905, 0.008636128157377243, 0.40278589725494385, 0.3336375951766968, 0.23292849957942963, 0.35347050428390503, 0.26747798919677734, 0.3050496578216553, -0.13561280071735382, 0.14727157354354858, -0.10859449952840805, 0.014918585307896137, 0.25913405418395996, 0.05369899049401283, 0.5455716252326965, 0.013203505426645279, -0.21656668186187744]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -0.3440898985369131 
Per Topic: [-0.44132310152053833, -0.1838964819908142, -0.7713922262191772, -0.15017744898796082, -0.13535699248313904, -0.0145052969455719, -0.5916098952293396, -0.9177692532539368, -0.38130316138267517, -0.014815865084528923, -0.13535699248313904, -1.1045511960983276, -0.03331481292843819, -0.3744139075279236, -0.5134019255638123, -0.002610116498544812, -0.0871577113866806, -0.32402369379997253, -0.04791494831442833, -0.4453229010105133, -0.577428936958313, -0.6193571090698242, -0.283419132232666, -0.317392498254776, -0.6215577125549316, -0.00806919950991869, -0.57356196641922, -0.04842308908700943, -0.2178465873003006, -0.38542279601097107]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.22468823567808915 
Per Topic: [-0.3061930537223816, -0.155331552028656, -0.4354722201824188, -0.1305689513683319, -0.11921977251768112, -0.014297901652753353, -0.3717052936553955, -0.47856080532073975, -0.2760459780693054, -0.014599558897316456, -0.11921977251768112, -0.5248393416404724, -0.032240718603134155, -0.2724171280860901, -0.3392370343208313, -0.0026033215690404177, -0.08017025142908096, -0.2447265088558197, -0.04572408273816109, -0.30811312794685364, -0.36605697870254517, -0.3824710249900818, -0.22083134949207306, -0.24092480540275574, -0.383309006690979, -0.008004610426723957, -0.36449912190437317, -0.04618659242987633, -0.178878515958786, -0.2781986892223358]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.1829920572622323 
Per Topic: [1.3888888888567388, 1.351351351341206, 1.2820512820238879, 1.1904761904604435, 1.0802469135719117, 1.4520202020110353, 0.9661835748675581, 1.9841269840876163, 1.0101010100755026, 1.5555555555382716, 1.0802469135719117, 0.5555555555452675, 1.033591731259473, 0.617283950607758, 1.1574074073806158, 1.8518518518232738, 1.0802469135719117, 1.315789473664974, 1.3440860214933326, 1.234567901196464, 1.3285024154428924, 0.9259259259116369, 1.5151515151132535, 0.25252525251887564, 1.0101010100755026, 1.1111111111049383, 1.111111111090535, 1.8518518518232738, 0.9259259259187814, 0.9259259259181319]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.8453894654909769 
Per Topic: [0.8197667598724365, 0.9256532788276672, 0.8035576939582825, 0.8818578124046326, 0.8918190002441406, 0.9353445768356323, 0.8346521258354187, 0.873748779296875, 0.7586309909820557, 0.9246693849563599, 0.8918190002441406, 0.7219855189323425, 0.9121947288513184, 0.7525374889373779, 0.7535561919212341, 0.8993445038795471, 0.9197915196418762, 0.8803811073303223, 0.9235726594924927, 0.7482755780220032, 0.8938221335411072, 0.8005030751228333, 0.8128131628036499, 0.7002859115600586, 0.7354151606559753, 0.9233746528625488, 0.805790901184082, 0.9214084148406982, 0.8755013942718506, 0.8396104574203491]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.38887887398401894 
Per Topic: [0.3785381019115448, 0.42045146226882935, 0.3751106262207031, 0.3976234495639801, 0.4064190685749054, 0.42867404222488403, 0.3846781253814697, 0.3993554711341858, 0.35036173462867737, 0.42043137550354004, 0.4064190685749054, 0.34244710206985474, 0.415459543466568, 0.34844744205474854, 0.36161744594573975, 0.40465158224105835, 0.41982099413871765, 0.39895099401474, 0.4213864803314209, 0.3619428873062134, 0.4089191257953644, 0.37124642729759216, 0.37123751640319824, 0.32440507411956787, 0.3589421510696411, 0.4214225709438324, 0.3721025586128235, 0.41501474380493164, 0.3991887867450714, 0.38110026717185974]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.6396074990431467 
Per Topic: [0.609109103679657, 0.7254809141159058, 0.6002833247184753, 0.6600911617279053, 0.6846902370452881, 0.7503141760826111, 0.6251657009124756, 0.6648780703544617, 0.5393182039260864, 0.7254211902618408, 0.6846902370452881, 0.520790159702301, 0.7107454538345337, 0.5347955226898193, 0.5664587616920471, 0.6796886920928955, 0.7236059308052063, 0.6637577414512634, 0.7282691597938538, 0.5672577619552612, 0.6918159127235413, 0.5904481410980225, 0.5904256105422974, 0.4801769256591797, 0.5599215030670166, 0.7283771634101868, 0.5926167368888855, 0.7094447016716003, 0.6644162535667419, 0.6157705187797546]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.513354111031174 
Per Topic: [1.7777777777432102, 1.6842105263022469, 1.5238095237835223, 1.3333333333185187, 1.1313131313048466, 1.947089947075267, 0.9481481481391936, 4.444444444320989, 1.0158730158556815, 2.2626262625994085, 1.1313131313048466, 0.44444444443950626, 1.053497942380003, 0.5079365079314689, 1.269841269819602, 3.5555555554864204, 1.1313131313048466, 1.5999999999795558, 1.6666666666516203, 1.4222222221898273, 1.6296296296115227, 0.8888888888790125, 2.133333333284741, 0.17777777777550618, 1.0158730158556815, 1.1851851851779427, 1.1851851851687243, 3.5555555554864204, 0.8888888888827162, 0.8888888888823795]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.756882642582059 
Per Topic: [0.7650192379951477, 0.8613271713256836, 0.7436153888702393, 0.8194134831428528, 0.828204870223999, 0.8931920528411865, 0.7570669054985046, 0.84662264585495, 0.6689490675926208, 0.8754242658615112, 0.828204870223999, 0.639968752861023, 0.862912118434906, 0.6384710669517517, 0.05105343088507652, 0.7766585350036621, 0.8765435218811035, 0.8180068135261536, 0.879450798034668, 0.7161286473274231, 0.8418636918067932, 0.7145481109619141, 0.7389515042304993, 0.5211626291275024, 0.689755380153656, 0.8764177560806274, 0.7430278062820435, 0.870980441570282, 0.8075026869773865, 0.7560356259346008]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.3428099542940226 
Per Topic: [0.34372544288635254, 0.38872024416923523, 0.34047603607177734, 0.3650163412094116, 0.37595123052597046, 0.4036736488342285, 0.34979259967803955, 0.3731122314929962, 0.3054954707622528, 0.3928699791431427, 0.37595123052597046, 0.30285680294036865, 0.386983186006546, 0.30006176233291626, 2.5203056308598093e-10, 0.3609868586063385, 0.3934319317340851, 0.3656192421913147, 0.3954794108867645, 0.32332706451416016, 0.3795117437839508, 0.3331964910030365, 0.3284977972507477, 0.24949350953102112, 0.32146450877189636, 0.39533209800720215, 0.33701446652412415, 0.38405901193618774, 0.3673328459262848, 0.34486544132232666]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.535612565287408 
Per Topic: [0.5237525105476379, 0.635912299156189, 0.5162451863288879, 0.57484370470047, 0.6024388074874878, 0.6769340634346008, 0.5379707217216492, 0.5951818227767944, 0.43987542390823364, 0.6470937132835388, 0.6024388074874878, 0.4344255328178406, 0.6312766671180725, 0.4286973774433136, 2.5203056308598093e-10, 0.5649130344390869, 0.6486195921897888, 0.57634037733078, 0.654203474521637, 0.4778187870979309, 0.6116340756416321, 0.4996921420097351, 0.48919835686683655, 0.33243343234062195, 0.47376230359077454, 0.6538003087043762, 0.5083285570144653, 0.6235321164131165, 0.5806098580360413, 0.5264039039611816]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.24354935751654835 
Per Topic: [0.57536414488468, 0.521296923625839, 0.4212134650598962, 0.2876820724414198, 0.1233790211540655, 0.6663359231022626, -0.0532445145272019, 1.4916548767501645, 0.01574835695205985, 0.8165262017090233, 0.1233790211540655, -0.8109302162251897, 0.05211600113348184, -0.677398823599758, 0.23889190826607307, 1.268511325444344, 0.1233790211540655, 0.47000362923358285, 0.5108256237575629, 0.3522205935672775, 0.4883527679034347, -0.1177830356663694, 0.7576857016752074, -1.7272209480976366, 0.01574835695205985, 0.16989903679013044, 0.1698990367823524, 1.268511325444344, -0.11778303566220273, -0.11778303566258155]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.10306088653936361 
Per Topic: [0.04774315282702446, 0.00027956522535532713, 0.1759595423936844, 0.044969458132982254, 0.010081577114760876, -0.02322317101061344, 0.25080054998397827, 0.16333380341529846, 0.155797079205513, 0.02492894046008587, 0.010081577114760876, 0.14169538021087646, 0.031085219234228134, 0.2477717101573944, 0.16646547615528107, 0.28673261404037476, 0.030864188447594643, 0.012386607937514782, -0.016495274379849434, 0.16911812126636505, 0.25782379508018494, 0.22052617371082306, 0.20629671216011047, 0.17674943804740906, 0.002177574671804905, 0.022487830370664597, 0.025386424735188484, 0.2607489824295044, 0.019804658368229866, -0.030551111325621605]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 1.6876316348711649 
Per Topic: [1.1808829307556152, 3.1761984825134277, 1.11403226852417, 1.6925550699234009, 7.197402000427246, -44.1919059753418, 1.2981277704238892, 1.0437235832214355, 1.3059754371643066, 3.1600587368011475, 7.197402000427246, 1.1293100118637085, -6.238952159881592, 1.9343199729919434, 1.3272883892059326, 2.058518886566162, 2.8631575107574463, 1.5730520486831665, -8.661764144897461, 1.0858306884765625, 1.2325001955032349, 1.4062464237213135, 1.4607523679733276, 1.4230997562408447, 1.191633939743042, 6.938048362731934, 1.2817714214324951, 1.389438509941101, 48.58103942871094, 4.479205131530762]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -4.202050316333771 
Per Topic: [-6.528441429138184, -1.4595166444778442, -9.76945686340332, -2.4439284801483154, -1.1613579988479614, -0.9778721332550049, -4.3542680740356445, -23.871009826660156, -4.2682366371154785, -1.4629502296447754, -1.1613579988479614, -8.733351707458496, -0.8618583679199219, -2.0702972412109375, -4.055410385131836, -1.9447168111801147, -1.5367234945297241, -2.7450411319732666, -0.8964992761611938, -12.650808334350586, -5.301071643829346, -3.4615578651428223, -3.170363187789917, -3.3635103702545166, -6.2182841300964355, -1.168405532836914, -4.548975944519043, -3.5677988529205322, -1.0210167169570923, -1.2874221801757812]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.10650250803827695 
Per Topic: [0.3285040669655546, 0.30110509278196973, 0.2484613592937987, 0.17435338714266152, 0.07718963869055703, 0.37295582954090467, -0.03440142671690969, 0.6851790109009271, 0.010050335853248927, 0.44183275227507113, 0.07718963869055703, -0.5877866648873042, 0.033039854077990205, -0.48242614923472477, 0.14618251017493344, 0.6161861394167182, 0.07718963869055703, 0.2744368456982516, 0.2957142441467513, 0.21072103130978853, 0.2840523043982159, -0.07696104113489391, 0.41551544395307993, -1.3762440251916417, 0.010050335853248927, 0.1053605156572708, 0.10536051565597443, 0.6161861394167182, -0.07696104113551105, -0.07696104113545482]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.16347259391720095 
Per Topic: [0.07990583777427673, 0.036092985421419144, 0.2575892210006714, 0.07601101696491241, 0.024034013971686363, 0.03873555362224579, 0.36558184027671814, 0.2416311651468277, 0.21751579642295837, 0.065586157143116, 0.024034013971686363, 0.18903659284114838, 0.1921483874320984, 0.34645339846611023, 0.24603603780269623, 0.4383622705936432, 0.05610727518796921, 0.03076649084687233, -0.01406999584287405, 0.23927003145217896, 0.3885394036769867, 0.318610280752182, 0.3091985285282135, 0.22767148911952972, 0.004244009032845497, 0.05279702693223953, 0.04347703978419304, 0.4040156900882721, 0.07553057372570038, -0.07073431462049484]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 1.2288841644922892 
Per Topic: [1.1499894857406616, 8.694544792175293, 1.0880317687988281, 1.6410962343215942, -7.84513521194458, -1.5090053081512451, 1.2635118961334229, 1.0226049423217773, 1.2583255767822266, 3.92311429977417, -7.84513521194458, 1.1067636013031006, -1.1698986291885376, 1.8490943908691406, 1.211580514907837, 1.8340578079223633, 4.200595378875732, 1.5275579690933228, -1.2552475929260254, 1.0609850883483887, 1.174046516418457, 1.382623314857483, 1.387900710105896, 1.328208327293396, 1.1547659635543823, -7.241245746612549, 1.2499561309814453, 1.2993130683898926, -2.234434127807617, 24.157958984375]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -5.430280049641927 
Per Topic: [-7.667129993438721, -1.1299620866775513, -12.359515190124512, -2.559828281402588, -0.8869431614875793, -0.6014356017112732, -4.794895172119141, -45.238197326660156, -4.871084690093994, -1.3421005010604858, -0.8869431614875793, -10.366501808166504, -0.5391488671302795, -2.177724838256836, -5.726335525512695, -2.1989564895629883, -1.3124418258666992, -2.8955254554748535, -0.556589663028717, -17.397472381591797, -6.74558687210083, -3.6135365962982178, -3.5779788494110107, -4.046844959259033, -7.461368560791016, -0.8786590695381165, -5.00070333480835, -4.340982913970947, -0.6908267736434937, -1.0431815385818481]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.06624470394148856 
Per Topic: [0.11676363675255017, 0.17559212082902823, 0.08831321989894252, 0.07240752719538407, 0.03926002438804054, 0.2537673862402816, -0.013620396947472472, 0.29756946355149305, 0.0031223123848645212, 0.2247240034286678, 0.03926002438804054, -0.16762497072759863, 0.01802913252790635, -0.14987410993346564, 0.048796920694947676, 0.2906177127978444, 0.03926002438804054, 0.11397136410118747, 0.15587535132395897, 0.06546416910010913, 0.12868913731679366, -0.02735506788144294, 0.14769100063500679, -0.2988475929530144, 0.0031223123848645212, 0.06546416910128068, 0.03744939017575551, 0.2906177127978444, -0.03629786572368363, -0.034866993991498695]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.1795986601151526 
Per Topic: [0.2393397092819214, 0.2939641773700714, 0.1676352471113205, 0.23427294194698334, 0.1200600191950798, 0.45229148864746094, 0.08748222142457962, 0.39698004722595215, 0.004797083325684071, 0.4234808087348938, 0.1200600191950798, -0.13449855148792267, 0.2900974750518799, -0.16396880149841309, 0.033560678362846375, 0.5256941318511963, 0.32555586099624634, 0.1784573495388031, 0.3900874853134155, 0.31562480330467224, 0.3369654417037964, -0.0987323746085167, 0.1808038353919983, -0.1088065505027771, 0.01916022039949894, 0.2978954613208771, 0.07305517047643661, 0.5543202757835388, 0.03412267193198204, -0.20179854333400726]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -35.873382854368536 
Per Topic: [-2.413581609725952, -0.19152449071407318, -7.951733589172363, -0.2445598989725113, -0.12968221306800842, 0.028639836236834526, -1.0611329078674316, 3.067133665084839, -0.9410110116004944, -0.00830205250531435, -0.12968221306800842, -1076.655029296875, -0.011695269495248795, -0.49732834100723267, -1.262964129447937, 0.006568645592778921, -0.09923006594181061, -0.47071945667266846, -0.006059555336833, 22.188892364501953, -0.884681761264801, -1.017217755317688, -0.44068923592567444, -0.7247352600097656, -4.022817134857178, -0.005134203936904669, -1.5642764568328857, -0.15523123741149902, -0.20906424522399902, -0.39463675022125244]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.39027324233514565 
Per Topic: [-0.7070525884628296, -0.1607390195131302, -0.8882899284362793, -0.19650308787822723, -0.11479531228542328, 0.029484260827302933, -0.5148299932479858, -1.4837617874145508, -0.48480454087257385, -0.008233696222305298, -0.11479531228542328, -0.999072253704071, -0.011560071259737015, -0.33214378356933594, -0.5581017136573792, 0.006612077821046114, -0.09027235209941864, -0.32006070017814636, -0.006023058667778969, -1.0471946001052856, -0.46940648555755615, -0.5042677521705627, -0.30588778853416443, -0.4202008843421936, -0.8009085059165955, -0.005107979290187359, -0.6100264191627502, -0.13437245786190033, -0.17291411757469177, -0.2829674184322357]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -1.4736030129460684 
Per Topic: [-1.7917594692248326, -0.693147180560723, -1.7917594692248326, -1.3862943611186682, -0.9444616088410577, -0.4480247225281728, -1.5040773967745518, -1.280933845461242, -2.197224577329997, -0.9444616088410577, -0.9444616088410577, -2.484906649778778, -0.8109302162168566, -2.197224577329997, -1.9740810260175872, -1.0986122886678875, -0.9444616088410577, -1.3862943611186682, -0.8754687373542778, -2.197224577329997, -1.1856236656572445, -1.7917594692248326, -1.7917594692248326, -3.5835189384228876, -2.197224577329997, -0.5877866649030966, -1.7917594692248326, -1.0986122886678875, -1.0986122886678875, -1.1856236656572445]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.4051099667946498 
Per Topic: [0.3128114342689514, 0.29022714495658875, 0.456012099981308, 0.27219223976135254, 0.27618899941444397, 0.5187976956367493, 0.5151218771934509, 0.45409396290779114, 0.4310186803340912, 0.2844853401184082, 0.27618899941444397, 0.406873881816864, 0.5763556361198425, 0.5211324095726013, 0.44940024614334106, 0.5777320265769958, 0.25635379552841187, 0.26241374015808105, 0.5060144066810608, 0.4632687270641327, 0.5369794368743896, 0.5030347108840942, 0.4982015788555145, 0.4322194457054138, 0.26809704303741455, 0.2195909172296524, 0.2773457169532776, 0.5402519106864929, 0.5302295088768005, 0.24066539108753204]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.7169607857863108 
Per Topic: [0.8160318732261658, 0.6320065855979919, 0.7978934049606323, 0.7204073071479797, 0.6506289839744568, 0.6404455900192261, 0.7013998627662659, 0.8310660719871521, 0.7743260264396667, 0.6533805131912231, 0.6506289839744568, 0.800041675567627, 0.6519516706466675, 0.7004050612449646, 0.7702807784080505, 0.6710249781608582, 0.6511701941490173, 0.714690089225769, 0.6047012209892273, 0.8539513349533081, 0.680045485496521, 0.7045339941978455, 0.741414487361908, 0.7823833227157593, 0.8255860805511475, 0.7111220359802246, 0.7788773775100708, 0.6950854659080505, 0.6371696591377258, 0.6661734580993652]

==== Coherence : &lt;Segmentation.ONE_SUC: 3&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 2.79475519657135 
Per Topic: [4.435728073120117, 1.7174402475357056, 3.947885513305664, 2.5766310691833496, 1.8622870445251465, 1.7812200784683228, 2.3489603996276855, 4.919475555419922, 3.431169271469116, 1.885008454322815, 1.8622870445251465, 4.001043796539307, 1.8731648921966553, 2.3378403186798096, 3.353139877319336, 2.0397439002990723, 1.866727590560913, 2.5049610137939453, 1.5297322273254395, 5.847029685974121, 2.125443935394287, 2.3844850063323975, 2.8671932220458984, 3.595236301422119, 4.7334885597229, 2.461669683456421, 3.522379159927368, 2.279606819152832, 1.7561087608337402, 1.9955683946609497]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.05055555552748148 
Per Topic: [-0.253, 0.6079999999150001, -0.13799999999999998, 0.7759999999074999, -0.25999999999999995, -0.33999999999999997, -0.24899999999999997, -0.26, -0.26599999999999996, -0.343, 0.4843333332497222, -0.29000000000000004, -0.367, 0.50299999993, -0.14900000000000002, 0.7029999999000001, 0.6749999999074999, -0.296, -0.332, -0.10500000000000002, 0.6379999999500001, 0.7369999999000001, -0.13699999999999998, 0.613999999915, -0.145, 0.5583333332497221, -0.21400000000000002, -0.177, -0.21000000000000002, -0.24900000000000003]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.5415724128422639 
Per Topic: [0.5373274594545364, 0.6175571918487549, 0.4770723730325699, 0.6316824167966842, 0.5644107758998871, 0.5595276564359665, 0.5154653616249562, 0.6185740262269974, 0.5269137233495712, 0.6371875941753388, 0.5716313332319259, 0.5969623416662216, 0.5010495139285922, 0.73782097697258, 0.3656056709587574, 0.5169796407222748, 0.5813835948705673, 0.4918918490409851, 0.5391562134027481, 0.5122612968087197, 0.5736709266901017, 0.4945665955543518, 0.5182306855916977, 0.5902392476797104, 0.42227031141519544, 0.54073486328125, 0.5509150475263596, 0.510292598605156, 0.43703860640525816, 0.508752492070198]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -0.05027374318626243 
Per Topic: [0.03927813754417002, 0.04180443454533815, -0.2468165174126625, 0.027459732769057155, 0.025011882465332747, 0.0523207476362586, -0.15124760381877422, -0.7090898901224136, 0.04631739230826497, -0.04348974861204624, 0.033568563591688874, 0.05140705183148384, 0.07163909580558539, 0.03393064513802528, -0.17329260855913162, -0.15716274566948413, 0.031568868551403284, -0.023677445948123932, 0.03465194166637957, -0.35570975244045255, 0.04182005319744349, 0.024973296327516437, 0.0360838046297431, 0.023332816548645496, -0.1388972859829664, -0.06800140934064984, -0.02806585220969282, -0.09312676191329956, 0.019143888726830482, 0.04605297315865755]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.029941071485324454 
Per Topic: [0.04308585688704625, 0.0446071389131248, -0.1967119961977005, 0.02873232145793736, 0.02626017779111862, 0.056498335860669616, -0.12840020135045052, -0.41183939278125764, 0.04950031088665128, -0.040606487262994054, 0.03527016192674637, 0.05498626958578825, 0.08003168953582644, 0.03558255136013031, -0.14648936986923217, -0.13402051515877247, 0.03433660753071308, -0.02260943448636681, 0.037681630812585354, -0.2607411935925484, 0.04467113250866532, 0.027608619537204504, 0.037783720856532456, 0.026072914712131023, -0.11964958906173706, -0.06285469895228743, -0.02633865411626175, -0.08349631540477276, 0.022510839439928532, 0.05030542407184839]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.3552114872225542 
Per Topic: [0.0, 3.754637752793726, 0.0, 8.385281375197048, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2441218301929142, 0.0, 0.0, 2.9333105725176685, 0.0, 3.8905305203853535, 4.541123934836883, 0.0, 0.0, 0.0, 3.17222144025044, 4.939386063134093, 0.0, 3.8182960730456528, 0.0, 2.9774350543228523, 0.0, 0.0, 0.0, 0.0]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.9146278921763101 
Per Topic: [0.9166006147861481, 0.9460621774196625, 0.8346863150596618, 0.8896758079528808, 0.9241811692714691, 0.937481838464737, 0.9202969610691071, 0.9123888492584229, 0.9169389188289643, 0.9522718071937561, 0.9645551145076752, 0.9446840107440948, 0.9442847371101379, 0.9547281682491302, 0.8270976185798645, 0.9409907221794128, 0.9267397880554199, 0.9392213821411133, 0.9492060959339141, 0.8096889436244965, 0.9583303928375244, 0.9172113299369812, 0.8633925139904022, 0.9372662842273712, 0.8148745715618133, 0.9502478659152984, 0.9243027687072753, 0.8960786700248718, 0.9017829835414887, 0.9235683441162109]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.09997679015000661 
Per Topic: [0.09999999850988388, 0.10000000223517418, 0.09983752146363259, 0.09997299909591675, 0.09999999776482582, 0.09999999850988388, 0.1, 0.09998270869255066, 0.10000000074505806, 0.10000000298023223, 0.09999999701976776, 0.09999999403953552, 0.10000000670552253, 0.1, 0.09982802346348763, 0.10000000149011612, 0.10000000521540642, 0.10000000223517418, 0.10000000223517418, 0.09972630068659782, 0.1000000037252903, 0.09999999627470971, 0.09997882321476936, 0.10000000223517418, 0.09999999850988388, 0.10000000149011612, 0.10000000447034836, 0.09997731372714043, 0.09999999776482582, 0.1]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.1111955966303746 
Per Topic: [0.11120680719614029, 0.11128147840499877, 0.11113375052809715, 0.11124621704220772, 0.1112453892827034, 0.11116116121411324, 0.11123602688312531, 0.1111360877752304, 0.11117456331849099, 0.11113841906189918, 0.11113927066326142, 0.11117525771260262, 0.11122014597058297, 0.11120561137795448, 0.11129894480109215, 0.1112654909491539, 0.11122472137212754, 0.11114718317985535, 0.11117018386721611, 0.11086780652403831, 0.1111651249229908, 0.11118221059441566, 0.11119996532797813, 0.11132487207651139, 0.11122125610709191, 0.11115459278225899, 0.111176498234272, 0.11129455417394638, 0.11122925654053688, 0.1112450510263443]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.4393458787279667 
Per Topic: [0.0, 3.91612019971099, 0.0, 9.500013296804193, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2771944399682726, 0.0, 0.0, 3.023488366399701, 0.0, 4.031166594645543, 4.80990493381229, 0.0, 0.0, 0.0, 3.3473098207303265, 5.222771860531334, 0.0, 3.992185453036204, 0.0, 3.0602213962001406, 0.0, 0.0, 0.0, 0.0]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.703916822627378 
Per Topic: [0.872867226600647, 0.9013971149921417, 0.0466287637129426, 0.11647273153066635, 0.871793395280838, 0.914996188879013, 0.888783973455429, 0.8472237527370453, 0.8838164329528808, 0.92010298371315, 0.9369237124919891, 0.9197418034076691, 0.05875986196674117, 0.9177050948143005, 0.07719137948006391, 0.8989042401313782, 0.8865294039249421, 0.9135325968265533, 0.9234955966472626, 0.10785636231303215, 0.9338362574577331, 0.8839708745479584, 0.7614807307720184, 0.8858444094657898, 0.0600609116256237, 0.9261069238185883, 0.8955683052539826, 0.10792532227933407, 0.8649173259735108, 0.8930710017681122]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.07714912438359542 
Per Topic: [0.10000000596046447, 0.09977788031101227, 3.2780742120763763e-09, 0.01643266061982747, 0.09973965883255005, 0.1, 0.09999999627470971, 0.09973392114043236, 0.09999999776482582, 0.09999999701976776, 0.09999999850988388, 0.09999999776482582, 2.743425109308362e-09, 0.09995957762002945, 1.5768337677246613e-10, 0.09989505112171174, 0.09971871227025986, 0.09999999776482582, 0.09999999925494193, 7.87408849234339e-10, 0.09999999701976776, 0.10000000074505806, 0.09936678409576416, 0.09984949454665185, 2.908799512368887e-09, 0.09999999478459358, 0.09999999701976776, 1.9358580072292853e-09, 0.1, 0.09999999925494193]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.08589823905593837 
Per Topic: [0.11150938868522645, 0.11153265833854675, 3.2780742120763763e-09, 0.01723609397849675, 0.11136268749833107, 0.11126035824418068, 0.11148354113101959, 0.11087922155857086, 0.11130479648709297, 0.11118842512369156, 0.11112882122397423, 0.11124122738838196, 2.743425109308362e-09, 0.11147894263267517, 1.5768337538468736e-10, 0.11138427332043647, 0.11109846010804177, 0.11119341179728508, 0.11115589812397957, 7.87408849234339e-10, 0.11124403774738312, 0.11130044609308243, 0.11093106865882874, 0.1117858462035656, 2.908799512368887e-09, 0.11121246218681335, 0.11125476285815239, 1.9358580072292853e-09, 0.11129547506570817, 0.11148485541343689]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -17.998075495427734 
Per Topic: [-27.631021115928547, 1.2140641365107059, -27.631021115928547, 1.99268501437722, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, 0.7556502297443957, -27.631021115928547, -27.631021115928547, 1.0629795470195091, -27.631021115928547, 1.316640100991759, 1.4100873610433413, -27.631021115928547, -27.631021115928547, -27.631021115928547, 1.1340019846351324, 1.5058705645390194, -27.631021115928547, 1.2574427025423358, -27.631021115928547, 1.0287358143354586, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.2581733147753403 
Per Topic: [0.24508911790326238, 0.17374768014997244, 0.5105727970600128, 0.48035172671079635, 0.2207817789982073, 0.058474055491387844, 0.2861169584095478, 0.377871535718441, 0.1149206195026636, 0.27650429494678974, 0.1526490034069866, 0.12525155174080282, -0.02420790456235409, 0.2585714322398417, 0.34213744625449183, 0.3058826974593103, 0.23692641034722328, 0.2380435297265649, 0.11151184756308793, 0.530694967508316, 0.09301305944100022, 0.23980206837877632, 0.3962100613862276, 0.33828441947698595, 0.38168871533125637, 0.19976201755926012, 0.3081607738509774, 0.43378524780273436, 0.21452752351760865, 0.11807400994002819]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 1.4955023588736858 
Per Topic: [1.2561096668243408, 1.8136528134346008, 0.9747179567813873, 1.2463554620742798, 1.4402464628219604, 1.3493381023406983, 1.1479509949684144, 1.0095133185386658, 1.325226652622223, 1.5603938579559327, 4.509990119934082, 2.0536433339118956, 1.7466441154479981, 2.458484387397766, 0.9938374519348144, 1.266217577457428, 1.2540597200393677, 1.3152145147323608, 1.4414571046829223, 0.9607468128204346, 2.6165847301483156, 1.1989105820655823, 1.0787838399410248, 1.52461838722229, 0.9657190799713135, 1.5096396565437318, 1.245335590839386, 1.0928990066051483, 1.0921587586402892, 1.416620707511902]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -7.092051823536552 
Per Topic: [-6.871484327316284, -2.254611086845398, -49.44212474822998, -7.2994259119033815, -3.3631428241729737, -4.071650528907776, -11.374973249435424, -13.510870265960694, -4.225879836082458, -2.798841881752014, -1.2853970527648926, -1.9529073238372803, -2.342919707298279, -1.6996152639389037, -45.50078015327453, -5.234318804740906, -5.3679927587509155, -4.312158226966858, -3.308485984802246, 1.496824312210083, -1.6213171839714051, -6.712603521347046, -0.5913944244384766, -3.05693256855011, 7.437892961502075, -3.0004308223724365, -5.7403112888336185, -6.814890384674072, -14.517410898208619, -3.423400950431824]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -0.7321758026569418 
Per Topic: [-2.1193269466817144, 1.1836213392910842, 0.0, 1.9093945089752844, -2.05001222868822, 0.0, 0.0, -6.282835324932625, -2.09055873945737, -2.159873457471698, 0.7431858331334158, -2.1821878125947856, -6.468966903707212, 1.035352912605204, 0.0, 1.2868936721207613, 1.3698277353097963, 0.0, -2.272474583729167, 0.0, 1.0883911517599014, 1.4648907739423103, -2.151172319776523, 1.2238002725221477, 0.0, 1.0063391125479737, -2.1716517610327064, -2.163955656922057, -2.163955656922057, 0.0]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.3125091246325367 
Per Topic: [0.2762430664151907, 0.25201512277126314, 0.5245177417993545, 0.5173569798469544, 0.28970395103096963, 0.09718930795788765, 0.34388906210660936, 0.4112602941691875, 0.12733350574271754, 0.4111373096704483, 0.3453836627304554, 0.22875212784856558, 0.017550497874617578, 0.36196450125426055, 0.36375135481357573, 0.37084027417004106, 0.287821763753891, 0.2903820521198213, 0.1693682083627209, 0.5441355347633362, 0.21100983675569296, 0.27975747734308243, 0.4058368131518364, 0.3833363808691502, 0.39377264669165013, 0.29187180995941164, 0.3566843113861978, 0.4650069460272789, 0.2167186163365841, 0.1406825812533498]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 3.8570949314037963 
Per Topic: [1.2249209702014923, 1.882071053981781, 0.9637438952922821, 1.1076842308044434, 1.405919623374939, 1.3376509308815003, 1.1359732747077942, 0.9947576940059661, 1.3089823722839355, 1.5321281790733337, 74.32208251953125, 2.260452628135681, 1.8589930772781371, 2.706422758102417, 0.9735818028450012, 1.2448540449142456, 1.2417418599128722, 1.2851081848144532, 1.444409430027008, 0.944037276506424, 3.541761589050293, 1.1833403348922729, 1.0524930655956268, 1.4987923622131347, 0.9549902737140655, 1.5251638889312744, 1.2416791915893555, 1.0531478464603423, 1.0766732692718506, 1.4092903137207031]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 20.507366928259525 
Per Topic: [7.635204005241394, -2.1603544473648073, 742.0231639385223, -2.4880732536315917, -3.6107279777526857, -4.309712243080139, -49.40712885856628, -30.79481234550476, -4.448127388954163, -2.899846577644348, -1.013667368888855, -1.797537386417389, -2.1667372226715087, -1.601905071735382, 27.565062618255617, -6.282110285758972, -5.812558126449585, -4.776027750968933, -3.317580962181091, -22.963042879104613, -1.3958378553390502, -7.697141504287719, -9.76264271736145, -3.2256082773208616, 44.59204630851745, -2.959061336517334, -6.136319494247436, -0.9429188728332519, -21.148436403274538, -3.476552414894104]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.04916006557067793 
Per Topic: [-0.07670099985772799, 0.2570201081641083, 0.0, 0.41461974952117087, -0.0741924165627901, 0.0, 0.0, -0.22738339269375524, -0.07565984372007947, -0.07816842701577136, 0.16138075318276104, -0.07897601045720357, -0.23411971915790059, 0.22482402838833196, 0.0, 0.27944541030519776, 0.2974543133079955, 0.0, -0.08224359766491388, 0.0, 0.27821696095948567, 0.318096989863972, -0.07785352234183011, 0.26574485265980285, 0.0, 0.21852376175624544, -0.07859469803599864, -0.0783161667403813, -0.0783161667403813, 0.0]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.4864306248476107 
Per Topic: [0.43763422667980195, 0.5497331604361534, 0.47610455825924874, 0.5632155805826187, 0.4909617304801941, 0.46946394741535186, 0.45332501977682116, 0.5710992306470871, 0.38939291536808013, 0.6348734751343728, 0.6118693023920059, 0.541075611114502, 0.45656153485178946, 0.6805806457996368, 0.3075068242847919, 0.5102350264787674, 0.4688612878322601, 0.4481358230113983, 0.5128358319401741, 0.5088331699371338, 0.5522102773189544, 0.40120257437229156, 0.41351083368062974, 0.5533533722162247, 0.35195610448718073, 0.5260767102241516, 0.48553305864334106, 0.48568335771560667, 0.3347507417201996, 0.40634281262755395]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.13213661321516457 
Per Topic: [-0.2333679087460041, -0.07421420821920037, 2.4051308393478394, -0.6659291565418244, -0.1743314877152443, -0.128420652449131, -1.008475089073181, 4.273856472969055, -0.18330565243959426, -0.17203156054019927, 0.0013614120427519083, -0.04500359818339348, -0.015463637164793908, -0.06803527064621448, 2.363974618911743, -0.5117599874734878, -0.26517586410045624, -0.24317131489515303, -0.11499179378151894, 1.4837201237678528, -0.02400804781354964, -0.3645357459783554, -1.1503982663154602, -0.1648890905082226, 1.8324528217315674, -0.242745341360569, -0.40612800121307374, -1.3859741806983947, -0.6302479207515717, -0.12379411570727825]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.5107786150136963 
Per Topic: [-0.18751066848635672, -0.06765787499025464, -1.7275664448738097, -0.3980284184217453, -0.14733463600277902, -0.1131181314587593, -0.49960836470127107, -1.3078935027122498, -0.15389785915613174, -0.146271950006485, 0.0017750745406374334, -0.0421593233011663, -0.012756952526979148, -0.06273228777572512, -1.7361850976943969, -0.3371551722288132, -0.20854200422763824, -0.1951710104942322, -0.10176142491400242, -3.1382298469543457, -0.022615865571424365, -0.26592340022325517, -0.5338767528533935, -0.13852907791733743, -2.2275139331817626, -0.1945817530155182, -0.28789310455322265, -0.580046021938324, -0.3826148182153702, -0.10795782655477523]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -18.455730713128055 
Per Topic: [-27.631021115928547, -0.1386294362007891, -27.631021115928547, -0.06931471814989455, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -0.17917594700983888, -27.631021115928547, -27.631021115928547, -0.2772588723025781, -27.631021115928547, -9.900003040065772e-11, -0.06931471814989455, -27.631021115928547, -27.631021115928547, -27.631021115928547, -4.8999915237636707e-11, -9.900003040065772e-11, -27.631021115928547, -0.13862943620078907, -27.631021115928547, -0.17917594700983888, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.6004041439294816 
Per Topic: [0.578860592842102, 0.5383680820465088, 0.6549134254455566, 0.6475066512823104, 0.5820991456508636, 0.6632340461015701, 0.5645034700632096, 0.6035295695066452, 0.5770901381969452, 0.6192097634077072, 0.630240973830223, 0.6226463794708252, 0.6046907782554627, 0.6189156651496888, 0.5785669237375259, 0.6159706115722656, 0.5710591435432434, 0.5234188318252564, 0.591490375995636, 0.6765992105007171, 0.6013480097055435, 0.5419433057308197, 0.6310879856348037, 0.6410084575414657, 0.6261020600795746, 0.5683780044317246, 0.591088530421257, 0.6096499741077424, 0.5589282512664795, 0.5796759605407715]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.9081074988842013 
Per Topic: [0.9051498711109162, 0.9094338595867157, 0.9018328309059143, 0.9027936637401581, 0.9086619794368744, 0.9168468117713928, 0.9072303771972656, 0.9084529221057892, 0.9122909307479858, 0.9121033608913421, 0.9074244916439056, 0.9111976206302643, 0.9152511358261108, 0.905062073469162, 0.9079863071441651, 0.9058874368667602, 0.9098460018634796, 0.9077514350414276, 0.9143188178539277, 0.9023345887660981, 0.9079844713211059, 0.9084756791591644, 0.903959184885025, 0.9047776937484742, 0.9054386794567109, 0.9087440133094787, 0.9028993308544159, 0.9061625897884369, 0.9105643033981323, 0.9123625040054322]

==== Coherence : &lt;Segmentation.ONE_ALL: 4&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 13.783973473707835 
Per Topic: [16.25237317085266, 12.821036100387573, 12.807693099975586, 14.896856880187988, 13.771287155151366, 18.443945384025575, 13.258090591430664, 17.12075710296631, 16.368441152572633, 13.711332082748413, 10.349943590164184, 12.753678321838379, 15.601322603225707, 13.092324829101562, 13.680219697952271, 12.417581510543823, 15.442327070236207, 12.039814376831055, 13.387025356292725, 13.295765495300293, 13.442171192169189, 14.691886854171752, 12.82756757736206, 12.966483163833619, 16.276408004760743, 12.039440584182739, 11.163235473632813, 11.66354718208313, 13.309474611282349, 13.62717399597168]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.07499999996833334 
Per Topic: [-0.253, 0.7079999999, -0.13799999999999998, 0.8259999998999998, -0.25999999999999995, -0.33999999999999997, -0.24899999999999997, -0.26, -0.26599999999999996, -0.343, 0.6009999999, -0.29000000000000004, -0.367, 0.7029999999000001, -0.14900000000000002, 0.7029999999000001, 0.7249999999, -0.296, -0.332, -0.10500000000000002, 0.6379999999500001, 0.7369999999000001, -0.13699999999999998, 0.7139999999, -0.145, 0.6749999999, -0.21400000000000002, -0.177, -0.21000000000000002, -0.24900000000000003]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.6410729912131234 
Per Topic: [0.6333910822868347, 0.6973669797182083, 0.5970727115869522, 0.7139965176582337, 0.6602881044149399, 0.6524575412273407, 0.6169759377837181, 0.6953143775463104, 0.6318665146827698, 0.7100220680236816, 0.6676555216312409, 0.6833051443099976, 0.6037357442080975, 0.7908996045589447, 0.5168040946125985, 0.6219531387090683, 0.6696984320878983, 0.6087498277425766, 0.6363498419523239, 0.6194979637861252, 0.6657921642065048, 0.6044882446527481, 0.6306056916713715, 0.6719021423435378, 0.5522374004125595, 0.6434971481561661, 0.6501025140285492, 0.6179495543241501, 0.555858987569809, 0.6123547405004501]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: -0.04950055712210693 
Per Topic: [0.03739694920368493, 0.03908383771777153, -0.23679817765951156, 0.026073369197547436, 0.025373382633551954, 0.050565505400300026, -0.1477519493550062, -0.7227683544158936, 0.047584916590858485, -0.04714265819638967, 0.03233479708433151, 0.04880514014512301, 0.0674881803803146, 0.03012196607887745, -0.1613907128572464, -0.15321893766522407, 0.029766265489161014, -0.02233187196252402, 0.031501518096774817, -0.34623068273067475, 0.038427666574716565, 0.029923668410629035, 0.04161144886165857, 0.02365320026874542, -0.13267237772233784, -0.06120393336750567, -0.029163892567157745, -0.09083370342850686, 0.023013164289295673, 0.04376556184142828]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.DIFFERENCE: 1&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.029246959519878154 
Per Topic: [0.040554215712472794, 0.041367638669908044, -0.18859166279435158, 0.027406617300584912, 0.026466488419100643, 0.05443309042602777, -0.12601786963641642, -0.4160135120153427, 0.0507568078530312, -0.0440474362578243, 0.03395622838288546, 0.05208738949149847, 0.07485087784007191, 0.031389358546584846, -0.13628447167575358, -0.13091368600726128, 0.03229295266792178, -0.02133885601942893, 0.03413750594481826, -0.25280910134315493, 0.04088243441656232, 0.0326758299022913, 0.043880258593708275, 0.025354486890137196, -0.11289855823852121, -0.056442486308515075, -0.027269362611696123, -0.08109336085617543, 0.026242190320044757, 0.04757720679044723]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.4820239801682076 
Per Topic: [0.0, 4.143526641437244, 0.0, 8.839826829122668, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.5244248604016497, 0.0, 0.0, 4.073038898727946, 0.0, 3.8905305203853535, 4.957790600982717, 0.0, 0.0, 0.0, 3.17222144025044, 4.939386063134093, 0.0, 4.439508193554606, 0.0, 3.4804653570495008, 0.0, 0.0, 0.0, 0.0]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.9317025850216545 
Per Topic: [0.9332154810428619, 0.9568761706352233, 0.8678891599178314, 0.9118741154670715, 0.939766138792038, 0.9502161026000977, 0.9357312977313995, 0.9302503347396851, 0.9338732779026031, 0.9616746664047241, 0.9712950348854065, 0.9553639352321625, 0.9548657298088074, 0.96359983086586, 0.8633557140827179, 0.9525385618209838, 0.9414067029953003, 0.9512531757354736, 0.9588610708713532, 0.8481564521789551, 0.9664158940315246, 0.933635026216507, 0.8913208246231079, 0.9496804177761078, 0.8528951346874237, 0.9599951684474946, 0.9392126202583313, 0.916973489522934, 0.9204763114452362, 0.9384097099304199]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.09084771491587165 
Per Topic: [0.090857744961977, 0.09081744477152824, 0.09078982919454574, 0.09081626906991005, 0.09083664193749427, 0.09088162183761597, 0.09084171429276466, 0.09088353589177131, 0.09087421372532845, 0.09089420288801194, 0.0908934824168682, 0.090873484313488, 0.0908483773469925, 0.09085730984807014, 0.09069855883717537, 0.09082573726773262, 0.09084807336330414, 0.09088974744081497, 0.09087632820010186, 0.09085912853479386, 0.09087948873639107, 0.09087031185626984, 0.09084642007946968, 0.0907941222190857, 0.0908469520509243, 0.09088497683405876, 0.090873122215271, 0.09079249650239944, 0.09084264189004898, 0.09083746895194053]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.RATIO: 2&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.10000000116725759 
Per Topic: [0.09999999925494193, 0.10000000521540642, 0.09999999329447747, 0.1000000037252903, 0.09999999850988388, 0.1000000074505806, 0.10000000819563866, 0.09999999925494193, 0.09999999329447747, 0.10000000521540642, 0.10000000521540642, 0.10000000670552253, 0.10000001266598701, 0.09999999478459358, 0.09999999403953552, 0.10000000223517418, 0.10000000298023223, 0.1000000037252903, 0.09999999925494193, 0.10000000447034836, 0.10000001266598701, 0.09999999552965164, 0.09999999105930328, 0.09999999478459358, 0.09999998658895493, 0.10000000447034836, 0.10000000447034836, 0.10000000447034836, 0.10000000074505806, 0.10000000074505806]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 1.574614330098895 
Per Topic: [0.0, 4.322135237242685, 0.0, 10.000013296724692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.56441368063523, 0.0, 0.0, 4.235554731218934, 0.0, 4.031166594645543, 5.264450388285885, 0.0, 0.0, 0.0, 3.3473098207303265, 5.222771860531334, 0.0, 4.664599246033868, 0.0, 3.58601504691836, 0.0, 0.0, 0.0, 0.0]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.7202866797702516 
Per Topic: [0.8995069801807404, 0.9238621056079864, 0.03974424544721842, 0.11647273153066635, 0.9006467580795288, 0.9329968214035034, 0.9107627511024475, 0.8805878221988678, 0.9084170997142792, 0.9366410970687866, 0.9493901491165161, 0.9355605125427247, 0.05246623436214254, 0.9351759076118469, 0.07719137948006391, 0.9200849056243896, 0.9109231293201446, 0.9309146285057068, 0.9388108253479004, 0.10785636231303215, 0.94701087474823, 0.9077460765838623, 0.8153495192527771, 0.9106474757194519, 0.0600609116256237, 0.9409192383289338, 0.9164608538150787, 0.09641246907413006, 0.8911628544330596, 0.9148176729679107]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.08373983587039549 
Per Topic: [0.09070029854774475, 0.090534558147192, 0.05000000283627202, 0.068759411375146, 0.09059121534228325, 0.09082677140831948, 0.09071093946695327, 0.09085014089941978, 0.09080255255103112, 0.09086695313453674, 0.09089943617582322, 0.09083719700574874, 0.050000002527070084, 0.09068491533398629, 0.07616382919974851, 0.09069322496652603, 0.09071683958172798, 0.09086524546146393, 0.0908846378326416, 0.06374088437782353, 0.09083639308810235, 0.0908079169690609, 0.09055597260594368, 0.09045128077268601, 0.06621104702854534, 0.09085262939333916, 0.09082993492484093, 0.050000001652027934, 0.0908067338168621, 0.09071410968899726]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LIKELIHOOD: 3&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 0.09999999938123459 
Per Topic: [0.10000000894069672, 0.10000000149011612, 0.10000000283627201, 0.09999999831161985, 0.10000000223517418, 0.09999999403953552, 0.09999999105930328, 0.09999998137354851, 0.09999998882412911, 0.10000000298023223, 0.10000000223517418, 0.10000000596046447, 0.10000000252707009, 0.09999999925494193, 0.09999999635644484, 0.10000000521540642, 0.09999999403953552, 0.09999999180436134, 0.10000000074505806, 0.10000000359045096, 0.09999999701976776, 0.10000000968575477, 0.10000001043081283, 0.09999999403953552, 0.10000000820064922, 0.09999999925494193, 0.09999998435378074, 0.10000000165202796, 0.10000000074505806, 0.10000000223517418]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -17.962483372280577 
Per Topic: [-27.631021115928547, 1.3547240469054427, -27.631021115928547, 2.063014969574606, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, 0.9378823009649313, -27.631021115928547, -27.631021115928547, 1.3442993678090223, -27.631021115928547, 1.316640100991759, 1.4804173162407261, -27.631021115928547, -27.631021115928547, -27.631021115928547, 1.1340019846351324, 1.5058705645390194, -27.631021115928547, 1.3981026129370882, -27.631021115928547, 1.2109678855560513, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.4232210506374636 
Per Topic: [0.40471704192459584, 0.3748432844877243, 0.6054804116487503, 0.577781380712986, 0.39561948031187055, 0.2525869905948639, 0.4440085932612419, 0.49328284449875354, 0.3226379733532667, 0.44289947897195814, 0.3710936218500137, 0.3367249697446823, 0.23194885086268185, 0.4129734568297863, 0.4842275597155094, 0.450000374764204, 0.3989551968872547, 0.4163795210421085, 0.3081002600491047, 0.6187533557415008, 0.3349212914705276, 0.4033030778169632, 0.5193201501853764, 0.4590431611053646, 0.4998456843197346, 0.39013231322169306, 0.4592802584171295, 0.5574072420597076, 0.39356791619211434, 0.33679577708244324]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 1.4709807678063713 
Per Topic: [1.2335412502288818, 1.7493083596229553, 0.9758998453617096, 1.242317545413971, 1.3921151995658874, 1.305328941345215, 1.1145889222621919, 0.9970690608024597, 1.267557430267334, 1.5003574252128602, 4.813571095466614, 2.008640003204346, 1.6858244955539703, 2.4432090878486634, 0.975768095254898, 1.230519461631775, 1.2183526396751403, 1.2709275364875794, 1.3993108928203584, 0.9570511102676391, 2.5273105978965758, 1.1639196932315827, 1.0658064484596252, 1.497915780544281, 0.9561408758163452, 1.4438908696174622, 1.2263261437416078, 1.0679799139499664, 1.0561725080013276, 1.342701804637909]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGLIKELIHOOD: 4&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -8.774326799710591 
Per Topic: [-180.41927905082701, -2.694600486755371, -8.551981115341187, 91.20622534751892, -5.142442607879639, -1.0554541110992433, -2.1000454425811768, -15.980204629898072, -6.960401701927185, -28.277136898040773, -1.3747661471366883, -18.568219244480133, -1.4437849283218385, -1.7968761801719666, -127.09476642608642, -12.824231719970703, 5.664210915565491, -6.707182431221009, -2.5311867952346803, -0.9237553596496582, -1.7390028595924378, -7.049778604507447, -6.394920063018799, -3.4542298316955566, -3.7749561309814452, -22.10694603919983, -6.989784550666809, -18.917453050613403, 144.33578805923463, -9.562641906738282]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.4454398795410999 
Per Topic: [0.0, 1.3222507753641843, 0.0, 1.9787092269858242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9223617800281911, 0.0, 0.0, 1.3126117847152092, 0.0, 1.2868936721207613, 1.439142453324124, 0.0, 0.0, 0.0, 1.0883911517599014, 1.4648907739423103, 0.0, 1.3624297085720154, 0.0, 1.1855150594204762, 0.0, 0.0, 0.0, 0.0]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.44621886669153665 
Per Topic: [0.4124165214598179, 0.41815333664417265, 0.6163956195116043, 0.6051172554492951, 0.4346828691661358, 0.23162247641012074, 0.4828745499253273, 0.5160080606117845, 0.3062569569796324, 0.5360476672649384, 0.47579583078622817, 0.3852004334330559, 0.1935215424746275, 0.4705633774399757, 0.49999310076236725, 0.4825298238545656, 0.4240686010569334, 0.4432110205292702, 0.31062971577048304, 0.629476198554039, 0.38552218191325666, 0.4223848611116409, 0.5205207884311676, 0.4717846617102623, 0.506538450345397, 0.4375795140862465, 0.4865640806034207, 0.580752494931221, 0.37728322446346285, 0.32307078506564724]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 1.0435703825950624 
Per Topic: [1.2180174231529235, 1.8631192445755005, 0.9675707817077637, 1.1141510665416718, 1.378911566734314, 1.3160255074501037, 1.1139546632766724, 0.9873750627040863, 1.2584400296211242, 1.502124309539795, -10.115685820579529, 2.321642255783081, 1.88246488571167, 2.8269158482551573, 0.9587222039699554, 1.229571372270584, 1.2208441019058227, 1.2584603667259215, 1.4352289259433746, 0.9435745537281036, 3.802091729640961, 1.1612120151519776, 1.045456701517105, 1.5008124589920044, 0.946215808391571, 1.4917181432247162, 1.2405412077903748, 1.0362650513648988, 1.0487590491771699, 1.3526109635829926]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.PMI: 5&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -11.746772848367693 
Per Topic: [5.979167127609253, -2.6410277843475343, 26.23333306312561, -1.7838737487792968, -8.457412910461425, -1.4535639047622682, -3.577716016769409, -27.5216344833374, -8.907718539237976, -0.33805098533630373, -1.0935552358627318, 0.4839033007621765, -1.4398733735084535, -1.685006892681122, 49.72143075466156, -0.885801887512207, 0.6011057376861573, -27.695952582359315, -2.4876408100128176, -20.633373832702638, -1.4742779970169066, -9.314956903457642, -11.319663143157959, -3.6779964208602904, 28.433544445037843, -0.4355814456939697, -7.089989948272705, -313.0866086959839, -11.304293155670166, 4.449900817871094]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: 0.09812190169672579 
Per Topic: [0.0, 0.28712310772271554, 0.0, 0.4296712492948265, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2002883156967014, 0.0, 0.0, 0.2850300274976867, 0.0, 0.27944541030519776, 0.3125058130824736, 0.0, 0.0, 0.0, 0.27821696095948567, 0.318096989863972, 0.0, 0.29584785221336524, 0.0, 0.25743132426534937, 0.0, 0.0, 0.0, 0.0]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.6040872625385721 
Per Topic: [0.5692125529050827, 0.65080326795578, 0.5849519714713096, 0.6516749501228333, 0.6060932964086533, 0.5997911095619202, 0.5725445315241814, 0.6604177474975585, 0.5421510398387909, 0.7167915105819702, 0.6984683573246002, 0.6483241111040116, 0.5904821053147316, 0.744459581375122, 0.48266232311725615, 0.6158387660980225, 0.5940763026475906, 0.5786906272172928, 0.6278219133615494, 0.6103616148233414, 0.6522184759378433, 0.5438662767410278, 0.5459191679954529, 0.6375426169484854, 0.5009278669953346, 0.6335693955421448, 0.6010507076978684, 0.6048533856868744, 0.5055979818105698, 0.5514543205499649]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.16895263698810598 
Per Topic: [-0.22467442005872726, -0.0717879543080926, 2.4869715571403503, -0.6741549015045166, -0.16681005880236627, -0.11651808135211468, -1.0089258432388306, 5.113375616073609, -0.16409189701080323, -0.17005307972431183, 0.0017191542850923725, -0.04115924602374434, -0.01008585398667492, -0.07271983586251736, 2.4648455142974854, -0.5109133243560791, -0.25942555218935015, -0.2349082961678505, -0.11019136048853398, 1.4878202319145202, -0.023804608383215964, -0.35086887776851655, -1.1440933644771576, -0.16545448899269105, 1.8452358961105346, -0.234650719165802, -0.4044821739196777, -1.3970118880271911, -0.6600303232669831, -0.11457271110266447]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.NPMI: 6&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: -0.53091334684587 
Per Topic: [-0.18150741010904312, -0.06580013204365968, -1.7469874143600463, -0.4021384835243225, -0.1423875130712986, -0.10274352580308914, -0.49714879393577577, -1.3276653647422791, -0.14003336653113366, -0.14451706111431123, 0.0022407311684219168, -0.03821370052173734, -0.006127732509048656, -0.0674062106758356, -2.0379212737083434, -0.3348137766122818, -0.20347139984369278, -0.19002137333154678, -0.0963026087731123, -3.2521924495697023, -0.022489816357847303, -0.2565449684858322, -0.5277079284191132, -0.14061422869563103, -2.4841044306755067, -0.1890276476740837, -0.28705792129039764, -0.5744902908802032, -0.37045379281044005, -0.09975052047520876]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.NONE: 0&gt; =S===
Average: -18.420680743983702 
Per Topic: [-27.631021115928547, -9.900003040065772e-11, -27.631021115928547, -9.900003040065772e-11, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547, -9.900003040065772e-11, -27.631021115928547, -27.631021115928547, -9.900003040065772e-11, -27.631021115928547, -9.900003040065772e-11, -9.900003040065772e-11, -27.631021115928547, -27.631021115928547, -27.631021115928547, -4.8999915237636707e-11, -9.900003040065772e-11, -27.631021115928547, -9.900003040065772e-11, -27.631021115928547, -9.900003040065772e-11, -27.631021115928547, -27.631021115928547, -27.631021115928547, -27.631021115928547]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.COSINE: 1&gt; =S===
Average: 0.6858331813414893 
Per Topic: [0.6675231665372848, 0.6407616078853607, 0.7199262201786041, 0.7087128102779389, 0.674959808588028, 0.7404359757900238, 0.658565005660057, 0.6793989837169647, 0.6806197047233582, 0.7043274402618408, 0.717370119690895, 0.7084757924079895, 0.6948964387178421, 0.6933852344751358, 0.6634315013885498, 0.6951278984546662, 0.6594241172075271, 0.6288093000650405, 0.6775986671447753, 0.7365705847740174, 0.7033872485160828, 0.634419396519661, 0.706954562664032, 0.7053548276424408, 0.7015772461891174, 0.662407511472702, 0.6772064924240112, 0.6904528617858887, 0.6603913962841034, 0.6825235188007355]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.DICE: 2&gt; =S===
Average: 0.9118037780125937 
Per Topic: [0.9116515040397644, 0.9112907469272613, 0.9106871962547303, 0.9116369605064392, 0.9115502536296844, 0.9159986495971679, 0.9106798052787781, 0.9134948909282684, 0.911925446987152, 0.9125157237052918, 0.9103051900863648, 0.9119442880153656, 0.9142145872116089, 0.9110994279384613, 0.9133953988552094, 0.9107547461986542, 0.9126778662204742, 0.9105921447277069, 0.9141834139823913, 0.9106616199016571, 0.9110627174377441, 0.9120863258838654, 0.91106196641922, 0.9114029586315155, 0.9120813608169556, 0.9111285269260406, 0.9101901948451996, 0.9104019999504089, 0.9119841039180756, 0.9114533245563508]

==== Coherence : &lt;Segmentation.ONE_SET: 5&gt;, &lt;ConfirmMeasure.LOGCOND: 7&gt;, &lt;IndirectMeasure.JACCARD: 3&gt; =S===
Average: 14.449915270805356 
Per Topic: [17.00997748374939, 13.411004638671875, 13.621732091903686, 15.789669513702393, 14.465864181518555, 19.18271050453186, 13.796858215332032, 17.785425448417662, 16.787820911407472, 14.353698372840881, 11.057847213745116, 13.338881254196167, 16.170499539375307, 13.692289924621582, 14.495761942863464, 13.061396408081055, 16.125968885421752, 12.430436897277833, 14.109033560752868, 14.151474952697754, 14.06671895980835, 15.34122953414917, 13.646188926696777, 13.780387353897094, 16.990155601501463, 12.628229808807372, 11.969531393051147, 12.254098796844483, 13.900067400932311, 14.082498407363891]
</pre></div>
</div>
</div>
</details>
</div>
</section>
<section id="id2">
<h3>Pining Topics using Word Priors<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make LDA model and train</span>
<span class="n">mdl</span> <span class="o">=</span> <span class="n">tp</span><span class="o">.</span><span class="n">LDAModel</span><span class="p">(</span><span class="n">k</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">min_cf</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">min_df</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">corpus</span><span class="o">=</span><span class="n">corpus</span><span class="p">)</span>
<span class="c1"># The word &#39;church&#39; is assigned to Topic 0 with a weight of 1.0 and to the remaining topics with a weight of 0.1.</span>
<span class="c1"># Therefore, a topic related to &#39;nasdaq&#39; can be fixed at Topic 0 .</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;nasdaq&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0001</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)])</span>
<span class="c1"># Topic 1 for a topic related to &#39;bank&#39;</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;bank&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mf">0.0001</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)])</span>
<span class="c1"># Topic 2 for a topic related to &#39;car&#39;</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">set_word_prior</span><span class="p">(</span><span class="s1">&#39;oil&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mf">1.0</span> <span class="k">if</span> <span class="n">k</span> <span class="o">==</span> <span class="mi">2</span> <span class="k">else</span> <span class="mf">0.0001</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">)])</span>
<span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Num docs:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">docs</span><span class="p">),</span> <span class="s1">&#39;, Vocab size:&#39;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">used_vocabs</span><span class="p">),</span> <span class="s1">&#39;, Num words:&#39;</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">num_words</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Removed top words:&#39;</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">removed_top_words</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">):</span>
    <span class="n">mdl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration: </span><span class="si">{}</span><span class="se">\t</span><span class="s1">Log-likelihood: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">mdl</span><span class="o">.</span><span class="n">ll_per_word</span><span class="p">))</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Num docs: 100 , Vocab size: 726 , Num words: 23802
Removed top words: []
Iteration: 0	Log-likelihood: -6.9982102600171
Iteration: 10	Log-likelihood: -6.78172128538039
Iteration: 20	Log-likelihood: -6.707927669262908
Iteration: 30	Log-likelihood: -6.669206157186698
Iteration: 40	Log-likelihood: -6.661336047859807
Iteration: 50	Log-likelihood: -6.63225589900849
Iteration: 60	Log-likelihood: -6.619234496642365
Iteration: 70	Log-likelihood: -6.6113331038327985
Iteration: 80	Log-likelihood: -6.589239579596395
Iteration: 90	Log-likelihood: -6.604038265559883
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mdl</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Basic Info&gt;
| LDAModel (current version: 0.12.3)
| 100 docs, 23802 words
| Total Vocabs: 5139, Used Vocabs: 726
| Entropy of words: 6.20784
| Entropy of term-weighted words: 6.20784
| Removed Vocabs: &lt;NA&gt;
|
&lt;Training Info&gt;
| Iterations: 100, Burn-in steps: 0
| Optimization Interval: 10
| Log-likelihood per word: -6.60404
|
&lt;Initial Parameters&gt;
| tw: TermWeight.ONE
| min_cf: 10 (minimum collection frequency of words)
| min_df: 5 (minimum document frequency of words)
| rm_top: 0 (the number of top words to be removed)
| k: 20 (the number of topics between 1 ~ 32767)
| alpha: [0.1] (hyperparameter of Dirichlet distribution for document-topic, given as a single `float` in case of symmetric prior and as a list with length `k` of `float` in case of asymmetric prior.)
| eta: 0.01 (hyperparameter of Dirichlet distribution for topic-word)
| seed: 2936119906 (random seed)
| trained in version 0.12.3
|
&lt;Parameters&gt;
| alpha (Dirichlet prior on the per-document topic distributions)
|  [0.91635215 0.40094903 0.46934685 0.31341073 0.8245844  0.24786447
|   0.41051129 0.42268345 0.59450996 0.26436833 0.7942999  0.9315055
|   0.74502105 0.36342382 0.6116812  0.4277962  0.97071016 0.26491374
|   1.0327024  0.6145224 ]
| eta (Dirichlet prior on the per-topic word distribution)
|  0.01
|
&lt;Topics&gt;
| #0 (1420) : nasdaq inc gain global demand
| #1 (870) : bank financi goldman could increas
| #2 (935) : oil data countri product sinc
| #3 (615) : investor fund cash manag activist
| #4 (2113) : zack stock rank compani buy
| #5 (609) : revenu billion report cloud share
| #6 (835) : market invest valu product also
| #7 (1250) : percent index dollar retail yen
| #8 (929) : year sector risk move amazon
| #9 (930) : gold price silver metal see
| #10 (1461) : compani nyse unit time number
| #11 (1492) : price high market last new
| #12 (1752) : year million sale revenu expect
| #13 (714) : dollar market store today rate
| #14 (1257) : quarter compani growth oper earn
| #15 (1027) : said reuter trump govern billion
| #16 (1967) : earn estim stock expect posit
| #17 (467) : peopl googl say media ask
| #18 (1975) : trade week us still forecast
| #19 (1184) : one secur make would presid
|
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">mdl</span><span class="o">.</span><span class="n">k</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;== Topic #</span><span class="si">{}</span><span class="s2"> ==&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">k</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">prob</span> <span class="ow">in</span> <span class="n">mdl</span><span class="o">.</span><span class="n">get_topic_words</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">top_n</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="n">prob</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>== Topic #0 ==
nasdaq	0.07707776129245758
inc	0.0574597492814064
gain	0.04695010185241699
global	0.04624945670366287
demand	0.04134495183825493
recent	0.039243023842573166
world	0.03223659098148346
develop	0.028032733127474785
industri	0.028032733127474785
system	0.025230159983038902

== Topic #1 ==
bank	0.0991838201880455
financi	0.06384652107954025
goldman	0.047887738794088364
could	0.04332808777689934
increas	0.04218817502260208
invest	0.041048262268304825
fed	0.03876843675971031
firm	0.0364886112511158
rise	0.034208785742521286
interest	0.03306887298822403

== Topic #2 ==
oil	0.07005497813224792
data	0.05201324075460434
countri	0.043523017317056656
product	0.03821662440896034
sinc	0.03821662440896034
low	0.03715534880757332
well	0.03715534880757332
declin	0.029726402834057808
energi	0.027603846043348312
rose	0.02654256857931614

== Topic #3 ==
investor	0.12054447084665298
fund	0.08358242362737656
cash	0.05304856225848198
manag	0.046620383858680725
activist	0.04019220173358917
score	0.03537106513977051
flow	0.03537106513977051
even	0.028942884877324104
valu	0.027335839346051216
hedg	0.027335839346051216

== Topic #4 ==
zack	0.08725816011428833
stock	0.08112683892250061
rank	0.0603746697306633
compani	0.037264298647642136
buy	0.036792658269405365
share	0.03396281599998474
current	0.02641656994819641
technolog	0.02594492956995964
hold	0.02547328919172287
nyse	0.024058369919657707

== Topic #5 ==
revenu	0.14605848491191864
billion	0.13632233440876007
report	0.07952811568975449
cloud	0.05681043490767479
share	0.04869697988033295
top	0.042206212878227234
ep	0.042206212878227234
busi	0.032470062375068665
consensu	0.032470062375068665
bp	0.032470062375068665

== Topic #6 ==
market	0.09380713850259781
invest	0.07362334430217743
valu	0.05343955382704735
product	0.047503143548965454
also	0.034443046897649765
money	0.034443046897649765
consum	0.03206848353147507
cost	0.03088119998574257
measur	0.027319354936480522
move	0.027319354936480522

== Topic #7 ==
percent	0.1447671800851822
index	0.05091230198740959
dollar	0.04534463584423065
retail	0.04136773571372032
yen	0.04136773571372032
yield	0.0381862111389637
rate	0.029437027871608734
share	0.027050886303186417
currenc	0.025460125878453255
consum	0.02227860502898693

== Topic #8 ==
year	0.0726400837302208
sector	0.04059769585728645
risk	0.03952961415052414
move	0.03312114253640175
amazon	0.029916903004050255
come	0.02884882315993309
chang	0.027780745178461075
option	0.025644585490226746
good	0.02457650564610958
take	0.023508427664637566

== Topic #9 ==
gold	0.13657896220684052
price	0.05335765704512596
silver	0.050156839191913605
metal	0.03948744013905525
see	0.03842049837112427
season	0.034152742475271225
come	0.032018862664699554
report	0.029884984716773033
mine	0.028818044811487198
investor	0.026684165000915527

== Topic #10 ==
compani	0.10489286482334137
nyse	0.044276900589466095
unit	0.025206705555319786
time	0.02384454943239689
number	0.02316347137093544
work	0.021120237186551094
grow	0.019077003002166748
back	0.019077003002166748
last	0.0183959249407053
deal	0.01771484687924385

== Topic #11 ==
price	0.07671117782592773
high	0.07337620109319687
market	0.06070328131318092
last	0.054033324122428894
new	0.05336632952094078
term	0.05003134906291962
long	0.03935941681265831
see	0.033356454223394394
top	0.02802048809826374
remain	0.026686497032642365

== Topic #12 ==
year	0.14438456296920776
million	0.0716267079114914
sale	0.04491093009710312
revenu	0.03524777293205261
expect	0.03297409042716026
result	0.030131986364722252
increas	0.028995145112276077
billion	0.02672146074473858
per	0.026153041049838066
share	0.02217409573495388

== Topic #13 ==
dollar	0.06379114091396332
market	0.05131297558546066
store	0.04299420490860939
today	0.04160774126648903
rate	0.03467543050646782
buy	0.03328896686434746
open	0.0319025032222271
higher	0.030516041442751884
close	0.030516041442751884
part	0.029129577800631523

== Topic #14 ==
quarter	0.1036258339881897
compani	0.0972980260848999
growth	0.08622435480356216
oper	0.05537626892328262
earn	0.0545852929353714
margin	0.03560185059905052
total	0.03560185059905052
cent	0.03322892263531685
strong	0.0316469706594944
corpor	0.029274040833115578

== Topic #15 ==
said	0.18564963340759277
reuter	0.0435190349817276
trump	0.0425521619617939
govern	0.0328834131360054
billion	0.024181541055440903
york	0.023214666172862053
offici	0.021280916407704353
comment	0.021280916407704353
need	0.019347166642546654
tax	0.019347166642546654

== Topic #16 ==
earn	0.07902201265096664
estim	0.06129385158419609
stock	0.04913739860057831
expect	0.042552653700113297
posit	0.041033096611499786
averag	0.036980945616960526
report	0.033435314893722534
market	0.027357084676623344
also	0.026850566267967224
per	0.023304933682084084

== Topic #17 ==
peopl	0.0717117115855217
googl	0.0506262369453907
say	0.04219204559922218
media	0.040083497762680054
ask	0.037974949926137924
center	0.037974949926137924
would	0.035866402089595795
court	0.035866402089595795
face	0.035866402089595795
new	0.035866402089595795

== Topic #18 ==
trade	0.07214492559432983
week	0.048939090222120285
us	0.027751151472330093
still	0.025228777900338173
forecast	0.022201931104063988
point	0.022201931104063988
time	0.021697456017136574
china	0.021697456017136574
two	0.02119298093020916
one	0.020184030756354332

== Topic #19 ==
one	0.04198075830936432
secur	0.040301863104104996
make	0.03862296789884567
would	0.034425731748342514
presid	0.033586286008358
help	0.030228495597839355
also	0.028549600392580032
gener	0.021834025159478188
two	0.020155129954218864
inc	0.020155129954218864
</pre></div>
</div>
</div>
</details>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./docs/lectures/nlp_intro"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="topic.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Topic Modeling</p>
      </div>
    </a>
    <a class="right-next"
       href="topic_coherence.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Topic Coherence Measures</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-tomotopy">What is tomotopy?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#getting-started">Getting Started</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model-save-and-load">Model Save and Load</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#documents-in-the-model-and-out-of-the-model">Documents in the Model and out of the Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#inference-for-unseen-documents">Inference for Unseen Documents</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-and-transform">Corpus and transform</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pining-topics-using-word-priors">Pining Topics using Word Priors</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#examples">Examples</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#install-or-upgrade-of-ekorpkit">Install or upgrade of ekorpkit</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#load-a-dataset">Load a dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lda-basics">LDA Basics</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lda-visualization">LDA Visualization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lda-coherence">LDA coherence</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">Pining Topics using Word Priors</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By <a href="https://entelecheia.me">Young Joon Lee</a>
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>