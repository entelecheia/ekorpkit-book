{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Disco Diffusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Diffusion settings\n",
    "---\n",
    "Disco Diffusion is complex, and continually evolving with new features.\n",
    "\n",
    "Setting | Description | Default\n",
    "--- | --- | ---\n",
    "**Your vision:**\n",
    "`text_prompts` | A description of what you'd like the machine to generate. Think of it like writing the caption below your image on a website. | N/A\n",
    "`image_prompts` | Think of these images more as a description of their contents. | N/A\n",
    "**Image quality:**\n",
    "`clip_guidance_scale`  | Controls how much the image should look like the prompt. | 1000\n",
    "`tv_scale` | Controls the smoothness of the final output. | 150\n",
    "`range_scale` | Controls how far out of range RGB values are allowed to be. | 150\n",
    "`sat_scale` | Controls how much saturation is allowed. From nshepperd's JAX notebook. | 0\n",
    "`cutn` | Controls how many crops to take from the image. | 16\n",
    "`cutn_batches` | Accumulate CLIP gradient from multiple batches of cuts. | 2\n",
    "**Init settings:**\n",
    "`init_image` | URL or local path | None\n",
    "`init_scale` | This enhances the effect of the init image, a good value is 1000 | 0\n",
    "`skip_steps` | Controls the starting point along the diffusion timesteps | 0\n",
    "`perlin_init` | Option to start with random perlin noise | False\n",
    "`perlin_mode` | ('gray', 'color') | 'mixed'\n",
    "**Advanced:**\n",
    "`skip_augs` | Controls whether to skip torchvision augmentations | False\n",
    "`randomize_class` | Controls whether the imagenet class is randomly changed each iteration | True\n",
    "`clip_denoised` | Determines whether CLIP discriminates a noisy or denoised image | False\n",
    "`clamp_grad` | Experimental: Using adaptive clip grad in the cond_fn | True\n",
    "`seed`  | Choose a random seed and print it at end of run for reproduction | random_seed\n",
    "`fuzzy_prompt` | Controls whether to add multiple noisy prompts to the prompt losses | False\n",
    "`rand_mag` | Controls the magnitude of the random noise | 0.1\n",
    "`eta` | DDIM hyperparameter | 0.5\n",
    "`use_vertical_symmetry` | Enforce symmetry over x axis of the image on [`tr_st`*`steps` for `tr_st` in `transformation_steps`] steps of the diffusion process | False\n",
    "`use_horizontal_symmetry` | Enforce symmetry over y axis of the image on [`tr_st`*`steps` for `tr_st` in `transformation_steps`] steps of the diffusion process | False\n",
    "`transformation_steps` | Steps (expressed in percentages) in which the symmetry is enforced | [0.01]\n",
    "`video_init_flow_warp` | Flow warp enabled | True\n",
    "`video_init_flow_blend` | 0 - you get raw input, 1 - you get warped diffused previous frame  | 0.999\n",
    "`video_init_check_consistency` | TBD check forward-backward flow consistency (uncheck unless there are too many warping artifacts) | False\n",
    "\n",
    "..\n",
    "\n",
    "**Model settings**\n",
    "---\n",
    "\n",
    "Setting | Description | Default\n",
    "--- | --- | ---\n",
    "**Diffusion:**\n",
    "`timestep_respacing` | Modify this value to decrease the number of timesteps. | ddim100\n",
    "`diffusion_steps` || 1000\n",
    "**Diffusion:**\n",
    "`clip_models` | Models of CLIP to load. Typically the more, the better but they all come at a hefty VRAM cost. | ViT-B/32, ViT-B/16, RN50x4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b6ee4e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
