{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a00149",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "## Via Command Line Interface (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ebbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:48:40,793\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - initialized batcher with <ekorpkit.utils.batch.batcher.Batcher object at 0x7efdc2537a60>\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "name        : ekorpkit\r\n",
      "author      : Young Joon Lee\r\n",
      "description : eKorpkit provides a flexible interface for NLP and ML research pipelines such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "website     : https://entelecheia.github.io/ekorpkit-book/\r\n",
      "version     : 0.1.31+8.gdef1e03.dirty\r\n",
      "\r\n",
      "Execute `ekorpkit --help` to see what eKorpkit provides\r\n",
      "[\u001b[36m2022-06-02 03:48:40,964\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - stopping joblib, if running\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205f4159",
   "metadata": {},
   "source": [
    "### CLI example to build a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "339f2883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:48:50,107\u001b[0m][\u001b[35mHYDRA\u001b[0m] Hydra 1.2.0\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] ===========\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] Installed Hydra Plugins\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] ***********************\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] \tConfigSource:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t-------------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tFileConfigSource\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tImportlibResourcesConfigSource\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,108\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tStructuredConfigSource\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \tCompletionPlugin:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t-----------------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tBashCompletion\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tFishCompletion\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tZshCompletion\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \tLauncher:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t---------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tBasicLauncher\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \tSweeper:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t--------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,109\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tBasicSweeper\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,110\u001b[0m][\u001b[35mHYDRA\u001b[0m] \tSearchPathPlugin:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,110\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t-----------------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,110\u001b[0m][\u001b[35mHYDRA\u001b[0m] \t\tHydraColorlogSearchPathPlugin\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,110\u001b[0m][\u001b[35mHYDRA\u001b[0m] \u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,110\u001b[0m][\u001b[35mHYDRA\u001b[0m] Config search path\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:50,110\u001b[0m][\u001b[35mHYDRA\u001b[0m] ******************\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:48:53,342\u001b[0m][\u001b[35mHYDRA\u001b[0m] | Provider                 | Search path                                       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,342\u001b[0m][\u001b[35mHYDRA\u001b[0m] --------------------------------------------------------------------------------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,342\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra                    | pkg://hydra.conf                                  |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,342\u001b[0m][\u001b[35mHYDRA\u001b[0m] | main                     | pkg://ekorpkit.conf                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,342\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra-colorlog           | pkg://hydra_plugins.hydra_colorlog.conf           |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,343\u001b[0m][\u001b[35mHYDRA\u001b[0m] | command-line             | file:///workspace/projects/ekorpkit-config/config |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,343\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra.searchpath in main | file://./config                                   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,343\u001b[0m][\u001b[35mHYDRA\u001b[0m] | schema                   | structured://                                     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:53,343\u001b[0m][\u001b[35mHYDRA\u001b[0m] --------------------------------------------------------------------------------\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:48:55,074\u001b[0m][\u001b[35mHYDRA\u001b[0m] \u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,074\u001b[0m][\u001b[35mHYDRA\u001b[0m] Defaults Tree\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,074\u001b[0m][\u001b[35mHYDRA\u001b[0m] *************\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,074\u001b[0m][\u001b[35mHYDRA\u001b[0m] <root>:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,074\u001b[0m][\u001b[35mHYDRA\u001b[0m]   hydra/config:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/output: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/launcher: basic\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/sweeper: basic\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/help: help\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/hydra_help: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/hydra_logging: colorlog\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/job_logging: colorlog\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,075\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/callbacks: null\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]     hydra/env: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]     _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]   config:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]     _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]     about: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]       about/app: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]     cmd: fetch_builtin_corpus:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,076\u001b[0m][\u001b[35mHYDRA\u001b[0m]       cmd/default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]     corpus: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]       column_info@corpus.column_info: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]         column_info/_build\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]         corpus/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]       cache@corpus.cache: extract_archive\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]     dataset: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,077\u001b[0m][\u001b[35mHYDRA\u001b[0m]       column_info@dataset.column_info: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]         column_info/_build\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]         dataset/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]     dir: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]     env: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]       env/run\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]     mode: debug:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]       mode/default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,078\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]     model: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]     project: esgml\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]     corpus/builtin: _dummy_fomc_minutes:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]       corpus/builtin/_build:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]         column_info@corpus.builtin.column_info: _build\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]         io@corpus.builtin.io: _build_corpus:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]           io/_default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,079\u001b[0m][\u001b[35mHYDRA\u001b[0m]             cache@corpus.builtin.io.cache: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]             io/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]           io/loader@corpus.builtin.io.loader: dataframe\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]           corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]         info@corpus.builtin.info: _build_corpus:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]           info/_default_build:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]             info/stats@corpus.builtin.info.stats: corpus:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]               info/stats/default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 _func_/len_bytes@corpus.builtin.info.stats._func_.len_bytes: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,080\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 info/stats/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_/len_wospc@corpus.builtin.info.stats._func_.len_wospc: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_/len_words@corpus.builtin.info.stats._func_.len_words: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_/len_segments@corpus.builtin.info.stats._func_.len_segments: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_/len_sents@corpus.builtin.info.stats._func_.len_sents: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]               info/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]             info/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]           corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]         pipeline@corpus.builtin.pipeline: _build_corpus:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,081\u001b[0m][\u001b[35mHYDRA\u001b[0m]           pipeline/_default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/_blank\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/aggregate_columns@corpus.builtin.pipeline.aggregate_columns: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.aggregate_columns._func_: aggregate_columns\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/chunk@corpus.builtin.pipeline.chunk: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.chunk._func_: chunk\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]               preprocessor/segmenter@corpus.builtin.pipeline.chunk.preprocessor.segmenter: chunk:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,082\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/segmenter/default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/separators@corpus.builtin.pipeline.chunk.preprocessor.segmenter.separators: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/merge@corpus.builtin.pipeline.chunk.preprocessor.segmenter.merge: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/split@corpus.builtin.pipeline.chunk.preprocessor.segmenter.split: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/filter_language@corpus.builtin.pipeline.chunk.preprocessor.segmenter.filter_language: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/filter_sentence_length@corpus.builtin.pipeline.chunk.preprocessor.segmenter.filter_sentence_length: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/chunk@corpus.builtin.pipeline.chunk.preprocessor.segmenter.chunk: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     _func_/len_bytes@corpus.builtin.pipeline.chunk.preprocessor.segmenter.chunk._func_.len_bytes: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,083\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     _func_/len_words@corpus.builtin.pipeline.chunk.preprocessor.segmenter.chunk._func_.len_words: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     preprocessor/segmenter/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 pipeline/chunk/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/combine_columns@corpus.builtin.pipeline.combine_columns: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.combine_columns._func_: combine_columns\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/concat_dataframes@corpus.builtin.pipeline.concat_dataframes: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,084\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.concat_dataframes._func_: concat_dataframes\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/drop_duplicates@corpus.builtin.pipeline.drop_duplicates: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.drop_duplicates._func_: drop_duplicates\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/drop@corpus.builtin.pipeline.drop: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.drop._func_: drop\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,085\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/eval_columns@corpus.builtin.pipeline.eval_columns: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.eval_columns._func_: eval_columns\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/explode_splits@corpus.builtin.pipeline.explode_splits: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.explode_splits._func_: explode_splits\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/extract_tokens@corpus.builtin.pipeline.extract_tokens: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]               preprocessor/tokenizer@corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/tokenizer/stopwords@corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.stopwords: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,086\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/tokenizer/tokenize@corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.tokenize: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/tokenizer/tokenize_article@corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.tokenize_article: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/tokenizer/extract@corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.extract: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 pipeline/extract_tokens/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.extract_tokens._func_: extract_tokens\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/fillna@corpus.builtin.pipeline.fillna: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.fillna._func_: fillna\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,087\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/filter_length@corpus.builtin.pipeline.filter_length: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.filter_length._func_: filter_length\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_/len_bytes@corpus.builtin.pipeline.filter_length._func_.len_bytes: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_/len_words@corpus.builtin.pipeline.filter_length._func_.len_words: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/filter_query@corpus.builtin.pipeline.filter_query: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.filter_query._func_: filter_query\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,088\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/load_dataframe@corpus.builtin.pipeline.load_dataframe: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.load_dataframe._func_: load_dataframe\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/melt@corpus.builtin.pipeline.melt: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.melt._func_: melt\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/merge_dataframe@corpus.builtin.pipeline.merge_dataframe: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.merge_dataframe._func_: merge_dataframe\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,089\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/normalize@corpus.builtin.pipeline.normalize: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.normalize._func_: normalize\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]               preprocessor/normalizer@corpus.builtin.pipeline.normalize.preprocessor.normalizer: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/normalizer/ftfy@corpus.builtin.pipeline.normalize.preprocessor.normalizer.ftfy: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/normalizer/spaces@corpus.builtin.pipeline.normalize.preprocessor.normalizer.spaces: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/normalizer/special_characters@corpus.builtin.pipeline.normalize.preprocessor.normalizer.special_characters: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 pipeline/normalize/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,090\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/pivot@corpus.builtin.pipeline.pivot: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.pivot._func_: pivot\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/plot@corpus.builtin.pipeline.plot: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.plot._func_: plot\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/predict@corpus.builtin.pipeline.predict: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,091\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.predict._func_: predict\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/rename_columns@corpus.builtin.pipeline.rename_columns: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.rename_columns._func_: rename_columns\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/replace@corpus.builtin.pipeline.replace: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.replace._func_: general_function\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _method_@corpus.builtin.pipeline.replace._method_: replace\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,092\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/reset_index@corpus.builtin.pipeline.reset_index: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.reset_index._func_: reset_index\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/sampling@corpus.builtin.pipeline.sampling: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.sampling._func_: sampling\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/save_dataframe@corpus.builtin.pipeline.save_dataframe: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.save_dataframe._func_: save_dataframe\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,093\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/save_metadata@corpus.builtin.pipeline.save_metadata: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.save_metadata._func_: save_metadata\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/save_samples@corpus.builtin.pipeline.save_samples: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.save_samples._func_: save_samples\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/segment@corpus.builtin.pipeline.segment: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,094\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.segment._func_: segment\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]               preprocessor/segmenter@corpus.builtin.pipeline.segment.preprocessor.segmenter: pysbd:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/segmenter/default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/separators@corpus.builtin.pipeline.segment.preprocessor.segmenter.separators: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/merge@corpus.builtin.pipeline.segment.preprocessor.segmenter.merge: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/split@corpus.builtin.pipeline.segment.preprocessor.segmenter.split: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/filter_language@corpus.builtin.pipeline.segment.preprocessor.segmenter.filter_language: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/filter_sentence_length@corpus.builtin.pipeline.segment.preprocessor.segmenter.filter_sentence_length: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,095\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/chunk@corpus.builtin.pipeline.segment.preprocessor.segmenter.chunk: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     _func_/len_bytes@corpus.builtin.pipeline.segment.preprocessor.segmenter.chunk._func_.len_bytes: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     _func_/len_words@corpus.builtin.pipeline.segment.preprocessor.segmenter.chunk._func_.len_words: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     preprocessor/segmenter/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/segmenter/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 pipeline/segment/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/split_column@corpus.builtin.pipeline.split_column: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.split_column._func_: split_column\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,096\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/split_dataframe@corpus.builtin.pipeline.split_dataframe: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.split_dataframe._func_: split_dataframe\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/split_sampling@corpus.builtin.pipeline.split_sampling: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.split_sampling._func_: split_sampling\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/stdout_samples@corpus.builtin.pipeline.stdout_samples: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.stdout_samples._func_: stdout_samples\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,097\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/subset@corpus.builtin.pipeline.subset: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.subset._func_: subset\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/summary_stats@corpus.builtin.pipeline.summary_stats: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.summary_stats._func_: summary_stats\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]               info/stats@corpus.builtin.pipeline.summary_stats.info.stats: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 _func_/len_bytes@corpus.builtin.pipeline.summary_stats.info.stats._func_.len_bytes: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,098\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 pipeline/summary_stats/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/tokenize@corpus.builtin.pipeline.tokenize: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]               preprocessor/tokenizer@corpus.builtin.pipeline.tokenize.preprocessor.tokenizer: mecab:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 preprocessor/tokenizer/default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/tokenizer/stopwords@corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.stopwords: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/tokenizer/tokenize@corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.tokenize: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/tokenizer/tokenize_article@corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.tokenize_article: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/tokenizer/extract@corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.extract: mecab:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,099\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     preprocessor/tokenizer/extract/default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]                     preprocessor/tokenizer/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]                   preprocessor/tokenizer/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]                 pipeline/tokenize/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.tokenize._func_: tokenize\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/top_values@corpus.builtin.pipeline.top_values: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]               _func_@corpus.builtin.pipeline.top_values._func_: top_values\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]               pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,100\u001b[0m][\u001b[35mHYDRA\u001b[0m]             pipeline/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]           corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]         corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]       io/fetcher@corpus.builtin.io.fetcher: _dummy:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]         io/fetcher/_default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]         corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]       preprocessor/normalizer@corpus.builtin.preprocessor.normalizer: formal_en:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]         preprocessor/normalizer/default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/normalizer/ftfy@corpus.builtin.preprocessor.normalizer.ftfy: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,101\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/normalizer/spaces@corpus.builtin.preprocessor.normalizer.spaces: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/normalizer/special_characters@corpus.builtin.preprocessor.normalizer.special_characters: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/normalizer/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]         corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]       preprocessor/segmenter@corpus.builtin.preprocessor.segmenter: pysbd:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]         preprocessor/segmenter/default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/separators@corpus.builtin.preprocessor.segmenter.separators: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/merge@corpus.builtin.preprocessor.segmenter.merge: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/split@corpus.builtin.preprocessor.segmenter.split: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,102\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/filter_language@corpus.builtin.preprocessor.segmenter.filter_language: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/filter_sentence_length@corpus.builtin.preprocessor.segmenter.filter_sentence_length: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/chunk@corpus.builtin.preprocessor.segmenter.chunk: default:\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]             _func_/len_bytes@corpus.builtin.preprocessor.segmenter.chunk._func_.len_bytes: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]             _func_/len_words@corpus.builtin.preprocessor.segmenter.chunk._func_.len_words: default\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]             preprocessor/segmenter/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]           preprocessor/segmenter/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]         corpus/builtin/_self_\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:55,103\u001b[0m][\u001b[35mHYDRA\u001b[0m]       _self_\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:48:56,888\u001b[0m][\u001b[35mHYDRA\u001b[0m] \u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,888\u001b[0m][\u001b[35mHYDRA\u001b[0m] Defaults List\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] *************\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | Config path                                           | Package                                                                        | _self_ | Parent                               | \u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/output/default                                  | hydra                                                                          | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/launcher/basic                                  | hydra.launcher                                                                 | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/sweeper/basic                                   | hydra.sweeper                                                                  | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/help/help                                       | hydra.help                                                                     | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/hydra_help/default                              | hydra.hydra_help                                                               | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/hydra_logging/colorlog                          | hydra.hydra_logging                                                            | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/job_logging/colorlog                            | hydra.job_logging                                                              | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,889\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/env/default                                     | hydra.env                                                                      | False  | hydra/config                         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | hydra/config                                          | hydra                                                                          | True   | <root>                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | config                                                |                                                                                | True   | <root>                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | about/app/default                                     | about.app                                                                      | False  | about/default                        |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | about/default                                         | about                                                                          | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | cmd/default                                           |                                                                                | False  | cmd/fetch_builtin_corpus             |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | cmd/fetch_builtin_corpus                              |                                                                                | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | column_info/_build                                    | corpus.column_info                                                             | False  | column_info/default                  |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | column_info/default                                   | corpus.column_info                                                             | True   | corpus/default                       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | cache/extract_archive                                 | corpus.cache                                                                   | False  | corpus/default                       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | corpus/default                                        | corpus                                                                         | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | column_info/_build                                    | dataset.column_info                                                            | False  | column_info/default                  |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,890\u001b[0m][\u001b[35mHYDRA\u001b[0m] | column_info/default                                   | dataset.column_info                                                            | True   | dataset/default                      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | dataset/default                                       | dataset                                                                        | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | dir/default                                           | dir                                                                            | False  | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | env/run                                               | env                                                                            | False  | env/default                          |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | env/default                                           | env                                                                            | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | mode/default                                          |                                                                                | False  | mode/debug                           |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | mode/debug                                            |                                                                                | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | model/default                                         | model                                                                          | False  | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | project/esgml                                         |                                                                                | False  | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | column_info/_build                                    | corpus.builtin.column_info                                                     | False  | corpus/builtin/_build                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | cache/default                                         | corpus.builtin.io.cache                                                        | False  | io/_default                          |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,891\u001b[0m][\u001b[35mHYDRA\u001b[0m] | io/_default                                           | corpus.builtin.io                                                              | True   | io/_build_corpus                     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | io/loader/dataframe                                   | corpus.builtin.io.loader                                                       | False  | io/_build_corpus                     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | io/_build_corpus                                      | corpus.builtin.io                                                              | True   | corpus/builtin/_build                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_bytes/default                              | corpus.builtin.info.stats._func_.len_bytes                                     | False  | info/stats/default                   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | info/stats/default                                    | corpus.builtin.info.stats                                                      | True   | info/stats/corpus                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_wospc/default                              | corpus.builtin.info.stats._func_.len_wospc                                     | False  | info/stats/corpus                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_words/default                              | corpus.builtin.info.stats._func_.len_words                                     | False  | info/stats/corpus                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_segments/default                           | corpus.builtin.info.stats._func_.len_segments                                  | False  | info/stats/corpus                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_sents/default                              | corpus.builtin.info.stats._func_.len_sents                                     | False  | info/stats/corpus                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | info/stats/corpus                                     | corpus.builtin.info.stats                                                      | True   | info/_default_build                  |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | info/_default_build                                   | corpus.builtin.info                                                            | True   | info/_build_corpus                   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | info/_build_corpus                                    | corpus.builtin.info                                                            | True   | corpus/builtin/_build                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,892\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/_blank                                       | corpus.builtin.pipeline                                                        | False  | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/aggregate_columns                              | corpus.builtin.pipeline.aggregate_columns._func_                               | False  | pipeline/aggregate_columns/default   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/aggregate_columns/default                    | corpus.builtin.pipeline.aggregate_columns                                      | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/chunk                                          | corpus.builtin.pipeline.chunk._func_                                           | False  | pipeline/chunk/default               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/separators/default             | corpus.builtin.pipeline.chunk.preprocessor.segmenter.separators                | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/merge/default                  | corpus.builtin.pipeline.chunk.preprocessor.segmenter.merge                     | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/split/default                  | corpus.builtin.pipeline.chunk.preprocessor.segmenter.split                     | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/filter_language/default        | corpus.builtin.pipeline.chunk.preprocessor.segmenter.filter_language           | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/filter_sentence_length/default | corpus.builtin.pipeline.chunk.preprocessor.segmenter.filter_sentence_length    | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_bytes/default                              | corpus.builtin.pipeline.chunk.preprocessor.segmenter.chunk._func_.len_bytes    | False  | preprocessor/segmenter/chunk/default |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_words/default                              | corpus.builtin.pipeline.chunk.preprocessor.segmenter.chunk._func_.len_words    | False  | preprocessor/segmenter/chunk/default |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,893\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/chunk/default                  | corpus.builtin.pipeline.chunk.preprocessor.segmenter.chunk                     | True   | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/default                        | corpus.builtin.pipeline.chunk.preprocessor.segmenter                           | True   | preprocessor/segmenter/chunk         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/chunk                          | corpus.builtin.pipeline.chunk.preprocessor.segmenter                           | True   | pipeline/chunk/default               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/chunk/default                                | corpus.builtin.pipeline.chunk                                                  | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/combine_columns                                | corpus.builtin.pipeline.combine_columns._func_                                 | False  | pipeline/combine_columns/default     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/combine_columns/default                      | corpus.builtin.pipeline.combine_columns                                        | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/concat_dataframes                              | corpus.builtin.pipeline.concat_dataframes._func_                               | False  | pipeline/concat_dataframes/default   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/concat_dataframes/default                    | corpus.builtin.pipeline.concat_dataframes                                      | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/drop_duplicates                                | corpus.builtin.pipeline.drop_duplicates._func_                                 | False  | pipeline/drop_duplicates/default     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/drop_duplicates/default                      | corpus.builtin.pipeline.drop_duplicates                                        | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/drop                                           | corpus.builtin.pipeline.drop._func_                                            | False  | pipeline/drop/default                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/drop/default                                 | corpus.builtin.pipeline.drop                                                   | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,894\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/eval_columns                                   | corpus.builtin.pipeline.eval_columns._func_                                    | False  | pipeline/eval_columns/default        |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/eval_columns/default                         | corpus.builtin.pipeline.eval_columns                                           | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/explode_splits                                 | corpus.builtin.pipeline.explode_splits._func_                                  | False  | pipeline/explode_splits/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/explode_splits/default                       | corpus.builtin.pipeline.explode_splits                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/stopwords/default              | corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.stopwords        | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/tokenize/default               | corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.tokenize         | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/tokenize_article/default       | corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.tokenize_article | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/extract/default                | corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer.extract          | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/default                        | corpus.builtin.pipeline.extract_tokens.preprocessor.tokenizer                  | True   | pipeline/extract_tokens/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/extract_tokens                                 | corpus.builtin.pipeline.extract_tokens._func_                                  | False  | pipeline/extract_tokens/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/extract_tokens/default                       | corpus.builtin.pipeline.extract_tokens                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,895\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/fillna                                         | corpus.builtin.pipeline.fillna._func_                                          | False  | pipeline/fillna/default              |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/fillna/default                               | corpus.builtin.pipeline.fillna                                                 | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/filter_length                                  | corpus.builtin.pipeline.filter_length._func_                                   | False  | pipeline/filter_length/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_bytes/default                              | corpus.builtin.pipeline.filter_length._func_.len_bytes                         | False  | pipeline/filter_length/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_words/default                              | corpus.builtin.pipeline.filter_length._func_.len_words                         | False  | pipeline/filter_length/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/filter_length/default                        | corpus.builtin.pipeline.filter_length                                          | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/filter_query                                   | corpus.builtin.pipeline.filter_query._func_                                    | False  | pipeline/filter_query/default        |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/filter_query/default                         | corpus.builtin.pipeline.filter_query                                           | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/load_dataframe                                 | corpus.builtin.pipeline.load_dataframe._func_                                  | False  | pipeline/load_dataframe/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/load_dataframe/default                       | corpus.builtin.pipeline.load_dataframe                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/melt                                           | corpus.builtin.pipeline.melt._func_                                            | False  | pipeline/melt/default                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/melt/default                                 | corpus.builtin.pipeline.melt                                                   | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,896\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/merge_dataframe                                | corpus.builtin.pipeline.merge_dataframe._func_                                 | False  | pipeline/merge_dataframe/default     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/merge_dataframe/default                      | corpus.builtin.pipeline.merge_dataframe                                        | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/normalize                                      | corpus.builtin.pipeline.normalize._func_                                       | False  | pipeline/normalize/default           |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/ftfy/default                  | corpus.builtin.pipeline.normalize.preprocessor.normalizer.ftfy                 | False  | preprocessor/normalizer/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/spaces/default                | corpus.builtin.pipeline.normalize.preprocessor.normalizer.spaces               | False  | preprocessor/normalizer/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/special_characters/default    | corpus.builtin.pipeline.normalize.preprocessor.normalizer.special_characters   | False  | preprocessor/normalizer/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/default                       | corpus.builtin.pipeline.normalize.preprocessor.normalizer                      | True   | pipeline/normalize/default           |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/normalize/default                            | corpus.builtin.pipeline.normalize                                              | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/pivot                                          | corpus.builtin.pipeline.pivot._func_                                           | False  | pipeline/pivot/default               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/pivot/default                                | corpus.builtin.pipeline.pivot                                                  | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/plot                                           | corpus.builtin.pipeline.plot._func_                                            | False  | pipeline/plot/default                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,897\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/plot/default                                 | corpus.builtin.pipeline.plot                                                   | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/predict                                        | corpus.builtin.pipeline.predict._func_                                         | False  | pipeline/predict/default             |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/predict/default                              | corpus.builtin.pipeline.predict                                                | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/rename_columns                                 | corpus.builtin.pipeline.rename_columns._func_                                  | False  | pipeline/rename_columns/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/rename_columns/default                       | corpus.builtin.pipeline.rename_columns                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/general_function                               | corpus.builtin.pipeline.replace._func_                                         | False  | pipeline/replace/default             |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _method_/replace                                      | corpus.builtin.pipeline.replace._method_                                       | False  | pipeline/replace/default             |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/replace/default                              | corpus.builtin.pipeline.replace                                                | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/reset_index                                    | corpus.builtin.pipeline.reset_index._func_                                     | False  | pipeline/reset_index/default         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/reset_index/default                          | corpus.builtin.pipeline.reset_index                                            | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/sampling                                       | corpus.builtin.pipeline.sampling._func_                                        | False  | pipeline/sampling/default            |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/sampling/default                             | corpus.builtin.pipeline.sampling                                               | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,898\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/save_dataframe                                 | corpus.builtin.pipeline.save_dataframe._func_                                  | False  | pipeline/save_dataframe/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/save_dataframe/default                       | corpus.builtin.pipeline.save_dataframe                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/save_metadata                                  | corpus.builtin.pipeline.save_metadata._func_                                   | False  | pipeline/save_metadata/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/save_metadata/default                        | corpus.builtin.pipeline.save_metadata                                          | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/save_samples                                   | corpus.builtin.pipeline.save_samples._func_                                    | False  | pipeline/save_samples/default        |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/save_samples/default                         | corpus.builtin.pipeline.save_samples                                           | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/segment                                        | corpus.builtin.pipeline.segment._func_                                         | False  | pipeline/segment/default             |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/separators/default             | corpus.builtin.pipeline.segment.preprocessor.segmenter.separators              | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/merge/default                  | corpus.builtin.pipeline.segment.preprocessor.segmenter.merge                   | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/split/default                  | corpus.builtin.pipeline.segment.preprocessor.segmenter.split                   | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/filter_language/default        | corpus.builtin.pipeline.segment.preprocessor.segmenter.filter_language         | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/filter_sentence_length/default | corpus.builtin.pipeline.segment.preprocessor.segmenter.filter_sentence_length  | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,899\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_bytes/default                              | corpus.builtin.pipeline.segment.preprocessor.segmenter.chunk._func_.len_bytes  | False  | preprocessor/segmenter/chunk/default |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_words/default                              | corpus.builtin.pipeline.segment.preprocessor.segmenter.chunk._func_.len_words  | False  | preprocessor/segmenter/chunk/default |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/chunk/default                  | corpus.builtin.pipeline.segment.preprocessor.segmenter.chunk                   | True   | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/default                        | corpus.builtin.pipeline.segment.preprocessor.segmenter                         | True   | preprocessor/segmenter/pysbd         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/pysbd                          | corpus.builtin.pipeline.segment.preprocessor.segmenter                         | True   | pipeline/segment/default             |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/segment/default                              | corpus.builtin.pipeline.segment                                                | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/split_column                                   | corpus.builtin.pipeline.split_column._func_                                    | False  | pipeline/split_column/default        |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/split_column/default                         | corpus.builtin.pipeline.split_column                                           | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/split_dataframe                                | corpus.builtin.pipeline.split_dataframe._func_                                 | False  | pipeline/split_dataframe/default     |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/split_dataframe/default                      | corpus.builtin.pipeline.split_dataframe                                        | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/split_sampling                                 | corpus.builtin.pipeline.split_sampling._func_                                  | False  | pipeline/split_sampling/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,900\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/split_sampling/default                       | corpus.builtin.pipeline.split_sampling                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/stdout_samples                                 | corpus.builtin.pipeline.stdout_samples._func_                                  | False  | pipeline/stdout_samples/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/stdout_samples/default                       | corpus.builtin.pipeline.stdout_samples                                         | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/subset                                         | corpus.builtin.pipeline.subset._func_                                          | False  | pipeline/subset/default              |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/subset/default                               | corpus.builtin.pipeline.subset                                                 | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/summary_stats                                  | corpus.builtin.pipeline.summary_stats._func_                                   | False  | pipeline/summary_stats/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_bytes/default                              | corpus.builtin.pipeline.summary_stats.info.stats._func_.len_bytes              | False  | info/stats/default                   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | info/stats/default                                    | corpus.builtin.pipeline.summary_stats.info.stats                               | True   | pipeline/summary_stats/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/summary_stats/default                        | corpus.builtin.pipeline.summary_stats                                          | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/stopwords/default              | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.stopwords              | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/tokenize/default               | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.tokenize               | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/tokenize_article/default       | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.tokenize_article       | False  | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,901\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/extract/default                | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.extract                | False  | preprocessor/tokenizer/extract/mecab |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/extract/mecab                  | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer.extract                | True   | preprocessor/tokenizer/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/default                        | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer                        | True   | preprocessor/tokenizer/mecab         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/tokenizer/mecab                          | corpus.builtin.pipeline.tokenize.preprocessor.tokenizer                        | True   | pipeline/tokenize/default            |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/tokenize                                       | corpus.builtin.pipeline.tokenize._func_                                        | False  | pipeline/tokenize/default            |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/tokenize/default                             | corpus.builtin.pipeline.tokenize                                               | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/top_values                                     | corpus.builtin.pipeline.top_values._func_                                      | False  | pipeline/top_values/default          |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/top_values/default                           | corpus.builtin.pipeline.top_values                                             | True   | pipeline/_default                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/_default                                     | corpus.builtin.pipeline                                                        | True   | pipeline/_build_corpus               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | pipeline/_build_corpus                                | corpus.builtin.pipeline                                                        | True   | corpus/builtin/_build                |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | corpus/builtin/_build                                 | corpus.builtin                                                                 | True   | corpus/builtin/_dummy_fomc_minutes   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,902\u001b[0m][\u001b[35mHYDRA\u001b[0m] | io/fetcher/_default                                   | corpus.builtin.io.fetcher                                                      | False  | io/fetcher/_dummy                    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | io/fetcher/_dummy                                     | corpus.builtin.io.fetcher                                                      | True   | corpus/builtin/_dummy_fomc_minutes   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/ftfy/default                  | corpus.builtin.preprocessor.normalizer.ftfy                                    | False  | preprocessor/normalizer/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/spaces/default                | corpus.builtin.preprocessor.normalizer.spaces                                  | False  | preprocessor/normalizer/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/special_characters/default    | corpus.builtin.preprocessor.normalizer.special_characters                      | False  | preprocessor/normalizer/default      |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/default                       | corpus.builtin.preprocessor.normalizer                                         | True   | preprocessor/normalizer/formal_en    |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/normalizer/formal_en                     | corpus.builtin.preprocessor.normalizer                                         | True   | corpus/builtin/_dummy_fomc_minutes   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/separators/default             | corpus.builtin.preprocessor.segmenter.separators                               | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/merge/default                  | corpus.builtin.preprocessor.segmenter.merge                                    | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/split/default                  | corpus.builtin.preprocessor.segmenter.split                                    | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/filter_language/default        | corpus.builtin.preprocessor.segmenter.filter_language                          | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/filter_sentence_length/default | corpus.builtin.preprocessor.segmenter.filter_sentence_length                   | False  | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,903\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_bytes/default                              | corpus.builtin.preprocessor.segmenter.chunk._func_.len_bytes                   | False  | preprocessor/segmenter/chunk/default |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,904\u001b[0m][\u001b[35mHYDRA\u001b[0m] | _func_/len_words/default                              | corpus.builtin.preprocessor.segmenter.chunk._func_.len_words                   | False  | preprocessor/segmenter/chunk/default |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,904\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/chunk/default                  | corpus.builtin.preprocessor.segmenter.chunk                                    | True   | preprocessor/segmenter/default       |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,904\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/default                        | corpus.builtin.preprocessor.segmenter                                          | True   | preprocessor/segmenter/pysbd         |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,904\u001b[0m][\u001b[35mHYDRA\u001b[0m] | preprocessor/segmenter/pysbd                          | corpus.builtin.preprocessor.segmenter                                          | True   | corpus/builtin/_dummy_fomc_minutes   |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,904\u001b[0m][\u001b[35mHYDRA\u001b[0m] | corpus/builtin/_dummy_fomc_minutes                    | corpus.builtin                                                                 | True   | config                               |\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:56,904\u001b[0m][\u001b[35mHYDRA\u001b[0m] -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:48:59,960\u001b[0m][\u001b[35mHYDRA\u001b[0m] Config\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:48:59,960\u001b[0m][\u001b[35mHYDRA\u001b[0m] ******\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:00,046\u001b[0m][\u001b[35mHYDRA\u001b[0m] about:\r\n",
      "  app:\r\n",
      "    _target_: ekorpkit.cli.about\r\n",
      "    name: ekorpkit\r\n",
      "    author: Young Joon Lee\r\n",
      "    description: eKorpkit provides a flexible interface for NLP and ML research pipelines\r\n",
      "      such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "    website: https://entelecheia.github.io/ekorpkit-book/\r\n",
      "    version: ${__version__:}\r\n",
      "_target_: ekorpkit.cli.cmd\r\n",
      "_config_: corpus.builtin\r\n",
      "corpus:\r\n",
      "  column_info:\r\n",
      "    keys:\r\n",
      "      id: id\r\n",
      "      text: text\r\n",
      "      timestamp: timestamp\r\n",
      "      split: split\r\n",
      "    columns:\r\n",
      "      id: ${oc.select:..keys.id,id}\r\n",
      "      text: ${oc.select:..keys.text,text}\r\n",
      "      merge_meta_on: ${oc.select:..id}\r\n",
      "      timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "    data:\r\n",
      "      id: int\r\n",
      "      text: str\r\n",
      "    meta: null\r\n",
      "    timestamp:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    datetime:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "    sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    _target_: ekorpkit.info.column.ColumnInfo\r\n",
      "  cache:\r\n",
      "    uri: null\r\n",
      "    extract_archive: true\r\n",
      "    force_extract: false\r\n",
      "    return_parent_dir: true\r\n",
      "    cache_dir: ${dir.cache}\r\n",
      "    verbose: ${oc.select:..verbose, false}\r\n",
      "    path: ${cached_path:${.uri},${.extract_archive},${.force_extract},${.return_parent_dir},${.cache_dir},${.verbose}}\r\n",
      "  _target_: ekorpkit.corpora.corpus.Corpus\r\n",
      "  name: ${oc.select:.builtin.name, null}\r\n",
      "  data_dir: ${oc.select:.builtin.data_dir, ${dir.corpus}}\r\n",
      "  metadata_dir: null\r\n",
      "  filetype: ${oc.select:.builtin.filetype, null}\r\n",
      "  autoload: true\r\n",
      "  automerge: false\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "  use_name_as_subdir: true\r\n",
      "  builtin:\r\n",
      "    column_info:\r\n",
      "      keys:\r\n",
      "        id: id\r\n",
      "        text: text\r\n",
      "        timestamp: timestamp\r\n",
      "        split: split\r\n",
      "      columns:\r\n",
      "        id: id\r\n",
      "        text: text\r\n",
      "        merge_meta_on: ${oc.select:..id}\r\n",
      "        timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "      data:\r\n",
      "        id: int\r\n",
      "        text: str\r\n",
      "      meta:\r\n",
      "        id: int\r\n",
      "        date: str\r\n",
      "        speaker: str\r\n",
      "        title: str\r\n",
      "      timestamp:\r\n",
      "        key: null\r\n",
      "        format: null\r\n",
      "        _parms_: null\r\n",
      "      datetime:\r\n",
      "        key: null\r\n",
      "        format: null\r\n",
      "        _parms_: null\r\n",
      "      segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "      sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    io:\r\n",
      "      cache:\r\n",
      "        uri: null\r\n",
      "        extract_archive: false\r\n",
      "        force_extract: false\r\n",
      "        return_parent_dir: true\r\n",
      "        cache_dir: ${dir.cache}\r\n",
      "        verbose: ${oc.select:..verbose, false}\r\n",
      "        path: ${cached_path:${.uri},${.extract_archive},${.force_extract},${.return_parent_dir},${.cache_dir},${.verbose}}\r\n",
      "      name: ${oc.select:..name,''}\r\n",
      "      data_dir: ${oc.select:..data_dir, .}\r\n",
      "      data_sources:\r\n",
      "        train: ${..fetcher.output_file}\r\n",
      "      num_workers: ${oc.select:num_workers,1}\r\n",
      "      force_download: false\r\n",
      "      overwrite: false\r\n",
      "      calculate_stats: true\r\n",
      "      preprocess_text: true\r\n",
      "      verbose: ${oc.select:verbose, false}\r\n",
      "      loader:\r\n",
      "        _target_: ekorpkit.io.load.data.load_dataframe\r\n",
      "        name: ${oc.select:..name,''}\r\n",
      "        data_dir: ${oc.select:..data_dir, ''}\r\n",
      "        data_souces: ${oc.select:..data_sources, ''}\r\n",
      "      fetcher:\r\n",
      "        name: ${oc.select:..name, null}\r\n",
      "        output_dir: ${oc.select:..data_dir, .}\r\n",
      "        output_file: ${.name}${iif:${.compress},.csv.bz2,.csv}\r\n",
      "        autoload: true\r\n",
      "        force_download: ${oc.select:..force_download, false}\r\n",
      "        num_workers: ${oc.select:task.num_workers, 1}\r\n",
      "        compress: false\r\n",
      "        verbose: ${oc.select:..verbose, false}\r\n",
      "        _target_: ekorpkit.io.fetch.loader.dummy.DummyCorpus\r\n",
      "    info:\r\n",
      "      stats:\r\n",
      "        _func_:\r\n",
      "          len_bytes:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_bytes\r\n",
      "          len_wospc:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_wospc\r\n",
      "          len_words:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_words\r\n",
      "          len_segments:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_segments\r\n",
      "            sep: ${oc.select:corpus.segment_separator, '\\n\\n'}\r\n",
      "          len_sents:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_sents\r\n",
      "            sep: ${oc.select:corpus.sentence_separator, '\\n'}\r\n",
      "        _target_: ekorpkit.info.stat.summary_stats\r\n",
      "        _partial_: true\r\n",
      "        num_workers: ${oc.select:task.num_workers, 1}\r\n",
      "        key_columns: ${oc.select:..key_columns, ''}\r\n",
      "        num_columns:\r\n",
      "          num_bytes: len_bytes\r\n",
      "          num_bytes_wospc: len_wospc\r\n",
      "          num_words: len_words\r\n",
      "          num_sents: len_sents\r\n",
      "          num_segments: len_segments\r\n",
      "        agg_funcs:\r\n",
      "          num_bytes:\r\n",
      "          - count\r\n",
      "          - sum\r\n",
      "          - median\r\n",
      "          - max\r\n",
      "          - min\r\n",
      "          num_bytes_wospc:\r\n",
      "          - sum\r\n",
      "          num_words:\r\n",
      "          - sum\r\n",
      "          - median\r\n",
      "          - max\r\n",
      "          - min\r\n",
      "          num_sents:\r\n",
      "          - sum\r\n",
      "          - median\r\n",
      "          num_segments:\r\n",
      "          - sum\r\n",
      "          - median\r\n",
      "        rename_columns:\r\n",
      "          num_bytes_count: num_docs\r\n",
      "          num_bytes_sum: num_bytes\r\n",
      "          num_words_sum: num_words\r\n",
      "          num_sents_sum: num_sents\r\n",
      "          num_segments_sum: num_segments\r\n",
      "          num_bytes_wospc_sum: num_bytes_wospc\r\n",
      "        convert_to_humanbytes:\r\n",
      "          num_bytes: human_bytes\r\n",
      "          num_bytes_wospc: human_bytes_wospc\r\n",
      "        text_keys: ${oc.select:..key_columns.text, 'text'}\r\n",
      "      _target_: ekorpkit.info.stat.SummaryInfo\r\n",
      "      name: ${oc.select:..name,''}\r\n",
      "      data_dir: ${oc.select:..data_dir, .}\r\n",
      "      info_file: info-${.name}.yaml\r\n",
      "      info_list:\r\n",
      "      - name\r\n",
      "      - fullname\r\n",
      "      - lang\r\n",
      "      - category\r\n",
      "      - short_description\r\n",
      "      - description\r\n",
      "      - license\r\n",
      "      - homepage\r\n",
      "      - version\r\n",
      "      - num_docs\r\n",
      "      - num_docs_before_processing\r\n",
      "      - num_segments\r\n",
      "      - num_sents\r\n",
      "      - num_words\r\n",
      "      - size_in_bytes\r\n",
      "      - num_bytes_before_processing\r\n",
      "      - size_in_human_bytes\r\n",
      "      - data_files_modified\r\n",
      "      - meta_files_modified\r\n",
      "      - info_updated\r\n",
      "      - data_files\r\n",
      "      - meta_files\r\n",
      "      - column_info\r\n",
      "      update_files_info:\r\n",
      "        data_files: data_file\r\n",
      "        meta_files: meta_file\r\n",
      "      update_info:\r\n",
      "      - fullname\r\n",
      "      - lang\r\n",
      "      - category\r\n",
      "      - description\r\n",
      "      - license\r\n",
      "      - homepage\r\n",
      "      - version\r\n",
      "      modified_info:\r\n",
      "        data_files_modified: data_file\r\n",
      "        meta_files_modified: meta_file\r\n",
      "      key_columns: ${oc.select:..column_info.columns:, ''}\r\n",
      "      verbose: ${oc.select:..verbose, false}\r\n",
      "      aggregate_info:\r\n",
      "        num_sents: num_sents\r\n",
      "        num_segments: num_segments\r\n",
      "        num_words: num_words\r\n",
      "        num_docs: num_docs\r\n",
      "        size_in_bytes: num_bytes\r\n",
      "        num_docs_before_processing: num_docs_before_processing\r\n",
      "        num_bytes_before_processing: num_bytes_before_processing\r\n",
      "      stat_before_processing:\r\n",
      "        num_columns:\r\n",
      "          num_bytes: len_bytes\r\n",
      "          num_sents: len_sents\r\n",
      "        agg_funcs:\r\n",
      "          num_bytes:\r\n",
      "          - count\r\n",
      "          - sum\r\n",
      "          num_sents:\r\n",
      "          - sum\r\n",
      "        rename_columns:\r\n",
      "          num_bytes_count: num_docs_before_processing\r\n",
      "          num_bytes_sum: num_bytes_before_processing\r\n",
      "          num_sents_sum: num_sents\r\n",
      "        convert_to_humanbytes: null\r\n",
      "    pipeline:\r\n",
      "      name: ${oc.select:..name, pipeline}\r\n",
      "      apply_to: ${oc.select:..column_info.columns:.text, text}\r\n",
      "      columns: null\r\n",
      "      data_dir: null\r\n",
      "      data_file: ${oc.select:..data_file, null}\r\n",
      "      output_dir: ${oc.select:..output_dir, ${dir.output}/${.name}}\r\n",
      "      output_file: ${oc.select:..output_file, null}\r\n",
      "      num_workers: ${oc.select:..num_workers,1}\r\n",
      "      use_batcher: true\r\n",
      "      verbose: ${oc.select:..verbose, false}\r\n",
      "      _pipeline_: null\r\n",
      "      aggregate_columns:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.aggregate_columns\r\n",
      "        onto: text\r\n",
      "        groupby: null\r\n",
      "        separator: \\n\\n\r\n",
      "        aggregations: null\r\n",
      "        reset_index: false\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      chunk:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.chunk\r\n",
      "        preprocessor:\r\n",
      "          segmenter:\r\n",
      "            separators:\r\n",
      "              in_segment: \\n\\n\r\n",
      "              in_sentence: \\n\r\n",
      "              out_segment: \\n\\n\r\n",
      "              out_sentence: \\n\r\n",
      "            merge:\r\n",
      "              merge_lines: false\r\n",
      "              merge_level: segment\r\n",
      "              empty_lines_threshold: 0.6\r\n",
      "              broken_lines_threshold: 0.4\r\n",
      "            split:\r\n",
      "              keep_segment: ${oc.select:..keep_segment, false}\r\n",
      "              max_recover_step: 0\r\n",
      "              max_recover_length: 30000\r\n",
      "            filter_language:\r\n",
      "              filter: false\r\n",
      "              detection_level: segment\r\n",
      "              languages_to_keep:\r\n",
      "              - en\r\n",
      "              - ko\r\n",
      "              min_language_probability: 0.8\r\n",
      "            filter_sentence_length:\r\n",
      "              filter: false\r\n",
      "              min_num_words: 3\r\n",
      "              min_length: 10\r\n",
      "            chunk:\r\n",
      "              _func_:\r\n",
      "                len_bytes:\r\n",
      "                  _partial_: true\r\n",
      "                  _target_: ekorpkit.utils.func.len_bytes\r\n",
      "                len_words:\r\n",
      "                  _partial_: true\r\n",
      "                  _target_: ekorpkit.utils.func.len_words\r\n",
      "              chunk_size: ${oc.select:..chunk_size, 300}\r\n",
      "              chunk_overlap: ${oc.select:..chunk_overlap, false}\r\n",
      "              len_func: ${oc.select:..len_func, len_bytes}\r\n",
      "            filter_programming_language: false\r\n",
      "            return_as_list: false\r\n",
      "            print_args: false\r\n",
      "            verbose: ${oc.select:..verbose, true}\r\n",
      "            _target_: ekorpkit.preprocessors.segmenter.Segmenter\r\n",
      "            keep_segment: ${oc.select:..keep_segment, false}\r\n",
      "            chunk_size: ${oc.select:..chunk_size, 300}\r\n",
      "            chunk_overlap: ${oc.select:..chunk_overlap, false}\r\n",
      "            len_func: ${oc.select:..len_func, len_bytes}\r\n",
      "          keep_segment: ${oc.select:..keep_segment, false}\r\n",
      "          chunk_size: ${oc.select:..chunk_size, 300}\r\n",
      "          chunk_overlap: ${oc.select:..chunk_overlap, false}\r\n",
      "          len_func: ${oc.select:..len_func, len_bytes}\r\n",
      "          verbose: ${oc.select:..verbose, true}\r\n",
      "        keep_segment: false\r\n",
      "        chunk_size: 300\r\n",
      "        chunk_overlap: false\r\n",
      "        len_func: len_bytes\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "      combine_columns:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.combine_columns\r\n",
      "        into: text\r\n",
      "        columns: null\r\n",
      "        separator: \\n\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      concat_dataframes:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.concat_dataframes\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      drop_duplicates:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.drop_duplicates\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      drop:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.drop\r\n",
      "        labels: null\r\n",
      "        axix: 1\r\n",
      "        columns: null\r\n",
      "        index: null\r\n",
      "        level: null\r\n",
      "        errors: raise\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      eval_columns:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.eval_columns\r\n",
      "        expressions: null\r\n",
      "        engine: python\r\n",
      "        eval_at: dataframe\r\n",
      "        verbose: ${oc.select:..verbose, false}\r\n",
      "      explode_splits:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.explode_splits\r\n",
      "        apply_to: text\r\n",
      "        id_key: id\r\n",
      "        split_key: sent_id\r\n",
      "        separator: \\n\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      extract_tokens:\r\n",
      "        preprocessor:\r\n",
      "          tokenizer:\r\n",
      "            stopwords:\r\n",
      "              _target_: ekorpkit.preprocessors.stopwords.Stopwords\r\n",
      "              name: stopwords\r\n",
      "              lowercase: true\r\n",
      "              stopwords: null\r\n",
      "              stopwords_path: ${oc.select:..stopwords_path, null}\r\n",
      "              nltk_stopwords: null\r\n",
      "              verbose: ${oc.select:..verbose, false}\r\n",
      "            tokenize:\r\n",
      "              lowercase: false\r\n",
      "              flatten: true\r\n",
      "              strip_pos: false\r\n",
      "              postag_delim: /\r\n",
      "              postag_length: null\r\n",
      "              include_whitespace_token: true\r\n",
      "              tokenize_each_word: false\r\n",
      "              punct_postags:\r\n",
      "              - SF\r\n",
      "              - SP\r\n",
      "              - SSO\r\n",
      "              - SSC\r\n",
      "              - SY\r\n",
      "              wordpieces_prefix: '##'\r\n",
      "              userdic_path: ${oc.select:..userdic_path, null}\r\n",
      "            tokenize_article:\r\n",
      "              sentence_separator: \\n\r\n",
      "            extract:\r\n",
      "              postags: null\r\n",
      "              noun_postags:\r\n",
      "              - NNG\r\n",
      "              - NNP\r\n",
      "              - XSN\r\n",
      "              - SL\r\n",
      "              - XR\r\n",
      "              - NNB\r\n",
      "              - NR\r\n",
      "              stop_postags:\r\n",
      "              - SP\r\n",
      "              - SF\r\n",
      "              - SE\r\n",
      "              - SSO\r\n",
      "              - SSC\r\n",
      "              - SC\r\n",
      "              - SY\r\n",
      "              - SH\r\n",
      "              strip_pos: true\r\n",
      "              postag_delim: /\r\n",
      "              postag_length: null\r\n",
      "            _target_: ekorpkit.preprocessors.tokenizer.SimpleTokenizer\r\n",
      "            normalize: null\r\n",
      "            return_as_list: false\r\n",
      "            stopwords_path: ${oc.select:..stopwords_path, null}\r\n",
      "            tagset: null\r\n",
      "            verbose: ${oc.select:..verbose, false}\r\n",
      "          stopwords_path: ${..stopwords_path}\r\n",
      "          verbose: ${oc.select:..verbose, false}\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.extract_tokens\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "        nouns_only: true\r\n",
      "        filter_stopwords_only: false\r\n",
      "        stopwords_path: null\r\n",
      "      fillna:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.fillna\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        fill_with: ''\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      filter_length:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.filter_length\r\n",
      "          len_bytes:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_bytes\r\n",
      "          len_words:\r\n",
      "            _partial_: true\r\n",
      "            _target_: ekorpkit.utils.func.len_words\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        min_length: 3\r\n",
      "        max_length: null\r\n",
      "        len_func: len_bytes\r\n",
      "        len_column: num_bytes\r\n",
      "        add_len_column: true\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "      filter_query:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.filter_query\r\n",
      "        query: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      load_dataframe:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.load_dataframe\r\n",
      "        filepath: null\r\n",
      "        filetype: null\r\n",
      "        data_dir: ${oc.select:..data_dir, ''}\r\n",
      "        data_file: ${oc.select:..data_file, ''}\r\n",
      "        columns: null\r\n",
      "        concatenate: true\r\n",
      "        dtype: null\r\n",
      "        parse_dates: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      melt:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.melt\r\n",
      "        id_vars: null\r\n",
      "        value_vars: null\r\n",
      "        var_name: variable\r\n",
      "        value_name: value\r\n",
      "        col_level: null\r\n",
      "        ignore_index: true\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      merge_dataframe:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.merge_dataframe\r\n",
      "        filepath: null\r\n",
      "        filetype: null\r\n",
      "        data_dir: ${oc.select:task.data_dir, .}\r\n",
      "        data_file: null\r\n",
      "        how: inner\r\n",
      "        merge_on: null\r\n",
      "        left_on: null\r\n",
      "        right_on: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      normalize:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.normalize\r\n",
      "        preprocessor:\r\n",
      "          normalizer: ${oc.select:corpus.builtin.preprocessor.normalizer,null}\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "      pivot:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.pivot\r\n",
      "        index: null\r\n",
      "        columns: null\r\n",
      "        values: null\r\n",
      "        reset_index: true\r\n",
      "        fillna: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      plot:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.plot\r\n",
      "        output_dir: null\r\n",
      "        output_file: null\r\n",
      "        visualize:\r\n",
      "          output_dir: ..output_dir\r\n",
      "          output_file: ..output_file}\r\n",
      "          plot:\r\n",
      "            output_dir: ..output_dir\r\n",
      "            output_file: ..output_file}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      predict:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.predict\r\n",
      "        name: predict\r\n",
      "        model: null\r\n",
      "        columns: null\r\n",
      "        output_dir: ${oc.select:..output_dir, ${dir.output}/${.name}}\r\n",
      "        output_file: ${oc.select:..output_file, null}\r\n",
      "        num_workers: ${oc.select:..num_workers,1}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        to_predict:\r\n",
      "          prefix: null\r\n",
      "          input: ${oc.select:..apply_to, text}\r\n",
      "          predicted: pred_labels\r\n",
      "          model_outputs: raw_preds\r\n",
      "          task_prefix: ${oc.select:..model.model_class, null}\r\n",
      "      rename_columns:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.rename_columns\r\n",
      "        new_names: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      replace:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.general_function\r\n",
      "        _method_:\r\n",
      "          _name_: replace\r\n",
      "          _parms_: ${oc.select:..parameters,null}\r\n",
      "        apply_to: ${oc.select:..apply_to, ''}\r\n",
      "        parameters:\r\n",
      "          to_replace: null\r\n",
      "          value: null\r\n",
      "          limit: null\r\n",
      "          regex: false\r\n",
      "          method: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      reset_index:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.reset_index\r\n",
      "        index_column_name: id\r\n",
      "        drop_index: false\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      sampling:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.sampling\r\n",
      "        sample_size_per_group: 10\r\n",
      "        random_state: 123\r\n",
      "        groupby: null\r\n",
      "        value_var: null\r\n",
      "        columns: null\r\n",
      "        output_dir: null\r\n",
      "        output_file: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      save_dataframe:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.save_dataframe\r\n",
      "        name: ${oc.select:..name, pipeline}\r\n",
      "        columns: null\r\n",
      "        filepath: null\r\n",
      "        filetype: null\r\n",
      "        output_dir: ${oc.select:..output_dir, ${dir.output}/${.name}}\r\n",
      "        output_file: ${oc.select:..output_file, ${.name}.${.filetype}}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      save_metadata:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.save_metadata\r\n",
      "        filepath: null\r\n",
      "        filetype: null\r\n",
      "        column_info: ${oc.select:corpus.column_info, null}\r\n",
      "        split_name: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      save_samples:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.save_samples\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        num_samples_to_save: 1\r\n",
      "        smaple_file_prfix: null\r\n",
      "        sample_length_to_print: 100\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      segment:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.segment\r\n",
      "        preprocessor:\r\n",
      "          segmenter: ${oc.select:corpus.builtin.preprocessor.segmenter,null}\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        num_workers: ${oc.select:..num_workers,1}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "      split_column:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.split_column\r\n",
      "        source: null\r\n",
      "        target: null\r\n",
      "        split:\r\n",
      "          pat: null\r\n",
      "          'n': -1\r\n",
      "          expand: false\r\n",
      "        verbose: ${oc.select:..verbose, false}\r\n",
      "      split_dataframe:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.split_dataframe\r\n",
      "        num_splits: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      split_sampling:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.split_sampling\r\n",
      "        stratify_on: null\r\n",
      "        random_state: 987\r\n",
      "        dev_size: null\r\n",
      "        test_size: 0.1\r\n",
      "        groupby: ${.stratify_on}\r\n",
      "        unique_key: null\r\n",
      "        output_dir: null\r\n",
      "        train_file: null\r\n",
      "        test_file: null\r\n",
      "        dev_file: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      stdout_samples:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.stdout_samples\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        num_samples: 5\r\n",
      "        head: null\r\n",
      "        tail: null\r\n",
      "        output_dir: ${oc.select:..data_dir, .}\r\n",
      "        output_file: stdout_samples.txt\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      subset:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.subset\r\n",
      "        head_n: null\r\n",
      "        tail_n: null\r\n",
      "        sample_n: null\r\n",
      "        sample_frac: null\r\n",
      "        random_state: 123\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      summary_stats:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.summary_stats\r\n",
      "        info:\r\n",
      "          stats:\r\n",
      "            _func_:\r\n",
      "              len_bytes:\r\n",
      "                _partial_: true\r\n",
      "                _target_: ekorpkit.utils.func.len_bytes\r\n",
      "            _target_: ekorpkit.info.stat.summary_stats\r\n",
      "            _partial_: true\r\n",
      "            num_workers: ${oc.select:task.num_workers, 1}\r\n",
      "            key_columns: ${oc.select:..key_columns, ''}\r\n",
      "            num_columns:\r\n",
      "              num_bytes: len_bytes\r\n",
      "            agg_funcs:\r\n",
      "              num_bytes:\r\n",
      "              - count\r\n",
      "              - sum\r\n",
      "              - median\r\n",
      "              - max\r\n",
      "              - min\r\n",
      "            rename_columns:\r\n",
      "              num_bytes_count: num_examples\r\n",
      "              num_bytes_sum: num_bytes\r\n",
      "            convert_to_humanbytes:\r\n",
      "              num_bytes: human_bytes\r\n",
      "            text_keys: ${..text_keys}\r\n",
      "          text_keys: ${..apply_to}\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        output_dir: ${oc.select:..data_dir, .}\r\n",
      "        output_file: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      tokenize:\r\n",
      "        preprocessor:\r\n",
      "          tokenizer:\r\n",
      "            stopwords:\r\n",
      "              _target_: ekorpkit.preprocessors.stopwords.Stopwords\r\n",
      "              name: stopwords\r\n",
      "              lowercase: true\r\n",
      "              stopwords: null\r\n",
      "              stopwords_path: ${oc.select:..stopwords_path, null}\r\n",
      "              nltk_stopwords: null\r\n",
      "              verbose: ${oc.select:..verbose, false}\r\n",
      "            tokenize:\r\n",
      "              lowercase: false\r\n",
      "              flatten: true\r\n",
      "              strip_pos: false\r\n",
      "              postag_delim: /\r\n",
      "              postag_length: null\r\n",
      "              include_whitespace_token: true\r\n",
      "              tokenize_each_word: false\r\n",
      "              punct_postags:\r\n",
      "              - SF\r\n",
      "              - SP\r\n",
      "              - SSO\r\n",
      "              - SSC\r\n",
      "              - SY\r\n",
      "              wordpieces_prefix: '##'\r\n",
      "              userdic_path: ${oc.select:..userdic_path, null}\r\n",
      "            tokenize_article:\r\n",
      "              sentence_separator: \\n\r\n",
      "            extract:\r\n",
      "              postags: null\r\n",
      "              noun_postags:\r\n",
      "              - NNG\r\n",
      "              - NNP\r\n",
      "              - XSN\r\n",
      "              - SL\r\n",
      "              - XR\r\n",
      "              - NNB\r\n",
      "              - NR\r\n",
      "              stop_postags:\r\n",
      "              - SP\r\n",
      "              - SF\r\n",
      "              - SE\r\n",
      "              - SSO\r\n",
      "              - SSC\r\n",
      "              - SC\r\n",
      "              - SY\r\n",
      "              - SH\r\n",
      "              strip_pos: true\r\n",
      "              postag_delim: /\r\n",
      "              postag_length: null\r\n",
      "            _target_: ekorpkit.preprocessors.tokenizer.MecabTokenizer\r\n",
      "            normalize: null\r\n",
      "            return_as_list: false\r\n",
      "            stopwords_path: ${oc.select:..stopwords_path, null}\r\n",
      "            tagset: null\r\n",
      "            verbose: ${oc.select:..verbose, false}\r\n",
      "            mecab:\r\n",
      "              userdic_path: ${..tokenize.userdic_path}\r\n",
      "              backend: mecab-python3\r\n",
      "              verbose: ${oc.select:..verbose, false}\r\n",
      "          userdic_path: ${..userdic_path}\r\n",
      "          verbose: ${oc.select:..verbose, false}\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.tokenize\r\n",
      "        apply_to: ${oc.select:..apply_to, text}\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        num_workers: ${oc.select:..num_workers,1}\r\n",
      "        use_batcher: ${oc.select:..use_batcher, true}\r\n",
      "        userdic_path: null\r\n",
      "      top_values:\r\n",
      "        _func_:\r\n",
      "          _partial_: true\r\n",
      "          _target_: ekorpkit.pipelines.pipe.top_values\r\n",
      "        groupby: null\r\n",
      "        value_var: null\r\n",
      "        value_label: null\r\n",
      "        value_name: null\r\n",
      "        value_separator: ', '\r\n",
      "        top_n: 5\r\n",
      "        columns: null\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "      _transform_:\r\n",
      "      - reset_index\r\n",
      "      _preprocess_:\r\n",
      "      - normalize\r\n",
      "      - segment\r\n",
      "      - drop_duplicates\r\n",
      "    _target_: ekorpkit.corpora.build.DatasetBuilder\r\n",
      "    name: fomc_minutes\r\n",
      "    data_dir: ${dir.corpus}/${.name}\r\n",
      "    filetype: .parquet\r\n",
      "    segment_separator: \\n\\n\r\n",
      "    sentence_separator: \\n\r\n",
      "    verbose: ${oc.select:..verbose, true}\r\n",
      "    autoload: true\r\n",
      "    preprocessor:\r\n",
      "      normalizer:\r\n",
      "        ftfy:\r\n",
      "          unescape_html: auto\r\n",
      "          remove_terminal_escapes: true\r\n",
      "          fix_encoding: true\r\n",
      "          restore_byte_a0: true\r\n",
      "          replace_lossy_sequences: true\r\n",
      "          decode_inconsistent_utf8: true\r\n",
      "          fix_c1_controls: true\r\n",
      "          fix_latin_ligatures: true\r\n",
      "          fix_character_width: true\r\n",
      "          uncurl_quotes: true\r\n",
      "          fix_line_breaks: true\r\n",
      "          fix_surrogates: true\r\n",
      "          remove_control_chars: true\r\n",
      "          normalization: NFKC\r\n",
      "          max_decode_length: 1000000\r\n",
      "        spaces:\r\n",
      "          strip: true\r\n",
      "          fix_whitespaces: true\r\n",
      "          collapse_whitespaces: true\r\n",
      "          replace_tabs: true\r\n",
      "          num_spaces_for_tab: 4\r\n",
      "        special_characters:\r\n",
      "          fix_hyphens: true\r\n",
      "          fix_ellipsis: true\r\n",
      "          fix_slashes: true\r\n",
      "          fix_tildes: true\r\n",
      "          fix_emoticons: false\r\n",
      "          single_quotes_only: false\r\n",
      "          regular_parentheses_only: false\r\n",
      "        _target_: ekorpkit.preprocessors.normalizer.Normalizer\r\n",
      "        hanja2hangle: false\r\n",
      "        num_repeats: 2\r\n",
      "      segmenter:\r\n",
      "        separators:\r\n",
      "          in_segment: \\n\\n\r\n",
      "          in_sentence: \\n\r\n",
      "          out_segment: \\n\\n\r\n",
      "          out_sentence: \\n\r\n",
      "        merge:\r\n",
      "          merge_lines: false\r\n",
      "          merge_level: segment\r\n",
      "          empty_lines_threshold: 0.6\r\n",
      "          broken_lines_threshold: 0.4\r\n",
      "        split:\r\n",
      "          keep_segment: true\r\n",
      "          max_recover_step: 0\r\n",
      "          max_recover_length: 30000\r\n",
      "        filter_language:\r\n",
      "          filter: false\r\n",
      "          detection_level: segment\r\n",
      "          languages_to_keep:\r\n",
      "          - en\r\n",
      "          - ko\r\n",
      "          min_language_probability: 0.8\r\n",
      "        filter_sentence_length:\r\n",
      "          filter: false\r\n",
      "          min_num_words: 3\r\n",
      "          min_length: 10\r\n",
      "        chunk:\r\n",
      "          _func_:\r\n",
      "            len_bytes:\r\n",
      "              _partial_: true\r\n",
      "              _target_: ekorpkit.utils.func.len_bytes\r\n",
      "            len_words:\r\n",
      "              _partial_: true\r\n",
      "              _target_: ekorpkit.utils.func.len_words\r\n",
      "          chunk_size: 300\r\n",
      "          chunk_overlap: false\r\n",
      "          len_func: len_bytes\r\n",
      "        filter_programming_language: false\r\n",
      "        return_as_list: false\r\n",
      "        print_args: false\r\n",
      "        verbose: ${oc.select:..verbose, true}\r\n",
      "        _target_: ekorpkit.preprocessors.segmenter.PySBDSegmenter\r\n",
      "        pysbd:\r\n",
      "          language: en\r\n",
      "          clean: false\r\n",
      "          doc_type: null\r\n",
      "    fullname: Federal Open Market Committee (FOMC) Corpus\r\n",
      "    lang: en\r\n",
      "    category: formal\r\n",
      "    domain: econ\r\n",
      "    description: FOMC\r\n",
      "    license: null\r\n",
      "    homepage: https://www.federalreserve.gov\r\n",
      "    version: 1.0.0\r\n",
      "dataset:\r\n",
      "  column_info:\r\n",
      "    keys:\r\n",
      "      id: id\r\n",
      "      text: text\r\n",
      "      timestamp: timestamp\r\n",
      "      split: split\r\n",
      "    columns:\r\n",
      "      id: ${oc.select:..keys.id,id}\r\n",
      "      text: ${oc.select:..keys.text,text}\r\n",
      "      merge_meta_on: ${oc.select:..id}\r\n",
      "      timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "    data:\r\n",
      "      id: int\r\n",
      "      text: str\r\n",
      "    meta: null\r\n",
      "    timestamp:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    datetime:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "    sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    _target_: ekorpkit.info.column.ColumnInfo\r\n",
      "  _target_: ekorpkit.datasets.dataset.Dataset\r\n",
      "  name: ${oc.select:.builtin.name, null}\r\n",
      "  data_dir: ${dir.dataset}/dataset\r\n",
      "  filetype: ${oc.select:.builtin.filetype, csv}\r\n",
      "  autoload: true\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "  use_name_as_subdir: true\r\n",
      "dir:\r\n",
      "  archive: ${.data}/archive\r\n",
      "  cache: ${.workspace}/.cache\r\n",
      "  corpus: ${.dataset}/corpus/ekorpkit\r\n",
      "  data: ${.workspace}/data/tbts\r\n",
      "  dataset: ${.workspace}/data/datasets\r\n",
      "  ekorpkit: ${__ekorpkit_path__:}\r\n",
      "  home: ${__home_path__:}\r\n",
      "  log: ${.project}/logs\r\n",
      "  model: ${.workspace}/data/tbts/models\r\n",
      "  output: ${.workspace}/data/outputs\r\n",
      "  project: ${.workspace}/data/tbts/${project}\r\n",
      "  resource: ${.ekorpkit}/resources\r\n",
      "  runtime: ${get_original_cwd:}\r\n",
      "  tmp: ${.workspace}/.tmp\r\n",
      "  workspace: /workspace\r\n",
      "env:\r\n",
      "  dotenv_path: ${dir.runtime}/.env\r\n",
      "  dotenv: ${dotenv_values:${.dotenv_path}}\r\n",
      "  os:\r\n",
      "    MODIN_ENGINE: joblib\r\n",
      "    MODIN_CPUS: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "    CACHED_PATH_CACHE_ROOT: ${dir.cache}/cached_path\r\n",
      "    HYDRA_FULL_ERROR: 1\r\n",
      "  distributed_framework:\r\n",
      "    backend: joblib\r\n",
      "    initialize: true\r\n",
      "    num_workers: ${oc.select:num_workers,50}\r\n",
      "  ray:\r\n",
      "    num_cpus: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "  dask:\r\n",
      "    n_workers: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "  batcher:\r\n",
      "    procs: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "    minibatch_size: 1000\r\n",
      "    backend: ${..distributed_framework.backend}\r\n",
      "    task_num_cpus: 1\r\n",
      "    task_num_gpus: 0\r\n",
      "    verbose: 10\r\n",
      "app_name: ${about.app.name}\r\n",
      "debug_mode: true\r\n",
      "print_config: false\r\n",
      "print_resolved_config: true\r\n",
      "num_workers: 1\r\n",
      "verbose: false\r\n",
      "ignore_warnings: false\r\n",
      "model:\r\n",
      "  name: model\r\n",
      "  data_dir: ${oc.select:..data_dir, ${dir.project}/data}\r\n",
      "  output_dir: ${oc.select:..output_dir, ${dir.output}/${.name}}\r\n",
      "  num_workers: ${oc.select:num_workers,1}\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "project: esgml\r\n",
      "\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:00,278\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - initialized batcher with <ekorpkit.utils.batch.batcher.Batcher object at 0x7f157819edf0>\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:01,025\u001b[0m][\u001b[34mekorpkit.io.fetch.loader.dummy\u001b[0m][\u001b[32mINFO\u001b[0m] - /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes.csv already exists. skipping..\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:01,077\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] - /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes-train.parquet already exists\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:01,077\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading data from /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes-train.parquet\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:01,096\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] - \r\n",
      "Processing dataframe with pipeline: ['normalize', 'segment', 'drop_duplicates', 'save_samples', 'save_dataframe']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:01,163\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipeline: OrderedDict([('normalize', 'normalize'), ('segment', 'segment'), ('drop_duplicates', 'drop_duplicates'), ('save_samples', 'save_samples'), ('save_dataframe', 'save_dataframe')])\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:01,164\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function normalize at 0x7f1577c2d160>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:01,168\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - instantiating normalizer\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Normalizing column: text:   0%|                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Normalizing column: text: 100%|███████████████████| 5/5 [00:00<00:00, 97.57it/s]\r\n",
      "[\u001b[36m2022-06-02 03:49:01,803\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to normalize: 0:00:00.053059\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:01,805\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function segment at 0x7f1577c2d310>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:01,810\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - instantiating segmenter\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:   0%|                             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:  40%|████████▍            | 2/5 [00:00<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:  60%|████████████▌        | 3/5 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:  80%|████████████████▊    | 4/5 [00:01<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text: 100%|█████████████████████| 5/5 [00:01<00:00,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text: 100%|█████████████████████| 5/5 [00:01<00:00,  3.13it/s]\r\n",
      "[\u001b[36m2022-06-02 03:49:03,431\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to segment: 0:00:01.598855\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:03,432\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function drop_duplicates at 0x7f1577c2d820>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:03,436\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function save_samples at 0x7f1577c2d8b0>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:03,440\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function save_dataframe at 0x7f1577c2dca0>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:03,442\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving dataframe as /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes-train.parquet\u001b[0m\r\n",
      "\r",
      "apply len_bytes to num_bytes:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_bytes to num_bytes: 100%|████████████| 5/5 [00:00<00:00, 19400.11it/s]\r\n",
      "\r",
      "apply len_wospc to num_bytes_wospc:   0%|                 | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "apply len_wospc to num_bytes_wospc: 100%|████████| 5/5 [00:00<00:00, 727.45it/s]\r\n",
      "\r",
      "apply len_words to num_words:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_words to num_words: 100%|█████████████| 5/5 [00:00<00:00, 2877.15it/s]\r\n",
      "\r",
      "apply len_sents to num_sents:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_sents to num_sents: 100%|██████████████| 5/5 [00:00<00:00, 402.79it/s]\r\n",
      "\r",
      "apply len_segments to num_segments:   0%|                 | 0/5 [00:00<?, ?it/s]\r",
      "apply len_segments to num_segments: 100%|████████| 5/5 [00:00<00:00, 420.58it/s]\r\n",
      "[\u001b[36m2022-06-02 03:49:03,526\u001b[0m][\u001b[34mekorpkit.info.stat\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to calculate statistics: 0:00:00.070639\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-02 03:49:03,539\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] - \r\n",
      "Corpus [fomc_minutes] is built to [/workspace/data/datasets/corpus/ekorpkit/fomc_minutes] from [/workspace/data/datasets/corpus/ekorpkit/fomc_minutes]\u001b[0m\r\n",
      "[\u001b[36m2022-06-02 03:49:03,539\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - stopping joblib, if running\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit --config-dir /workspace/projects/ekorpkit-config/config  \\\n",
    "    project=esgml \\\n",
    "    dir.workspace=/workspace \\\n",
    "    verbose=false \\\n",
    "    print_config=false \\\n",
    "    num_workers=1 \\\n",
    "    cmd=fetch_builtin_corpus \\\n",
    "    +corpus/builtin=_dummy_fomc_minutes \\\n",
    "    corpus.builtin.io.calculate_stats=true \\\n",
    "    corpus.builtin.io.preprocess_text=true \\\n",
    "    corpus.builtin.io.overwrite=false \\\n",
    "    corpus.builtin.io.force_download=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5175082",
   "metadata": {},
   "source": [
    "### CLI Help\n",
    "\n",
    "To see the available configurations for CLI, run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f553230",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== ekorpkit == \r\n",
      "\r\n",
      "author: Young Joon Lee\r\n",
      "description: eKorpkit provides a flexible interface for NLP and ML research pipelines such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "\r\n",
      "ekorpkit Command Line Interface for Hydra\r\n",
      "\r\n",
      "== Configuration groups ==\r\n",
      "\r\n",
      "Compose your configuration from those groups (task=task_name)\r\n",
      "_func_: aggregate_columns, chunk, combine_columns, concat_dataframes, drop, drop_duplicates, eval_columns, evaluate_classification_performance, explode_splits, extract_tokens, fillna, filter_length, filter_query, general_function, load_dataframe, melt, merge_dataframe, normalize, pivot, plot, predict, remove_startswith, rename_columns, reset_index, sampling, save_as_json, save_as_text, save_dataframe, save_metadata, save_samples, segment, split_column, split_dataframe, split_sampling, stdout_samples, subset, summary_stats, tokenize, top_values\r\n",
      "_func_/concat_dataframes: default\r\n",
      "_func_/len_bytes: default\r\n",
      "_func_/len_segments: default\r\n",
      "_func_/len_sents: default\r\n",
      "_func_/len_words: default\r\n",
      "_func_/len_wospc: default\r\n",
      "_func_/load_dataframe: default\r\n",
      "_func_/save_dataframe: default\r\n",
      "_method_: load_and_concatenate, replace, train_and_eval\r\n",
      "about: default, run\r\n",
      "about/app: default, run\r\n",
      "cache: default, extract_archive\r\n",
      "cmd: convert_electra, default, fetch_builtin_corpus, fetch_simple_dataset, fetch_t5_dataset, info, job, listup, pipeline, task, topic_task, transformer_finetune, workflow\r\n",
      "column_info: _build, default\r\n",
      "corpus: corpora, corpus, dataset, default\r\n",
      "corpus/builtin: _build, _dummy_bok_minutes, _dummy_fomc_minutes, aida_paper, aihub_book, aihub_formal1, aihub_formal2, aihub_koen_formal, aihub_koen_sci, aihub_koen_ssci, aihub_law_case, aihub_law_kb, aihub_paper, aihub_patent1, aihub_patent2, bigkinds, bigpatent, bok_minutes, c4_realnewslike, cb_speech, cc_news, courtlistener, earnings_call, edgar, enron_mail, enwiki, esg_report, fomc, gd_review, hacker_news, kaist, kcbert, kcc, kowiki, mc4_ko, namuwiki, nih_exporter, nikl_news, nikl_spoken, nikl_written, oscar_ko, pathobook, philpapers, pmc_comm, pmc_noncomm, pubmed, respec, reuters_financial, sec_report, stackexchange, us_equities_news, verbcl, youtube_subtitles\r\n",
      "corpus/preset: builtins\r\n",
      "data: concat, default\r\n",
      "dataset: dataset, datasets, default, preset, simple, simple_auto, t5\r\n",
      "dataset/preset: builtins\r\n",
      "dataset/simple: _build, analystsent_kr, bc4chemd, bc5cdr, esg_topics, financial_phrasebank, finphrase_kr, mp_tone_kr, ncbi-disease, nsmc, pathner, sst2\r\n",
      "dataset/t5: BC2GM, BC4CHEMD, BC5CDR-chem, BC5CDR-disease, JNLPBA, NCBI-disease, _build, _scifive_finetune, linnaeus, s800\r\n",
      "dir: default\r\n",
      "env: default, run\r\n",
      "info: _build_corpus, _build_dataset, _build_t5, _default_build, corpus, t5\r\n",
      "info/stats: corpus, default\r\n",
      "info/table: corpus_info, listup, t5_info\r\n",
      "io: _build_corpus, _build_simple, _build_t5, _default\r\n",
      "io/fetcher: _default, _dummy, _gcs, _gdrive_untar, _web, bok, dataframe, earnings_call, edgar, edgar_filings, edgar_items, enwiki, esg_report, fomc, glassdoor, hfds, kcbert, kcc, kowiki, namuwiki, nih_exporter, pathobook, pubmed, quandl, respec, sec_report\r\n",
      "io/fetcher/fomc: _base, default\r\n",
      "io/fetcher/fomc/articles: default, statement\r\n",
      "io/loader: class, csv, dataframe, gcs, hfds, parser, tf_textline, the_pile, tsv\r\n",
      "io/loader/decompressor: gzip\r\n",
      "io/loader/parser: email, html_to_json, json, json_to_list, jsonlines, plaintext, plaintext_split, pmc, pubmed, redif, reuters\r\n",
      "job: _job_, build_corpus\r\n",
      "job/example: build_corpus, tokenize_corpus\r\n",
      "meta/chairpersons: fomc\r\n",
      "meta/econ_series: fomc\r\n",
      "meta/recessions: usa\r\n",
      "meta/unconventionals: fomc\r\n",
      "mode: debug, default, run\r\n",
      "model: default\r\n",
      "model/eval: classification\r\n",
      "model/ngram: branching, cohesion, default, npmi\r\n",
      "model/ngram/candidates: default\r\n",
      "model/ngram/postag: default\r\n",
      "model/ngram/score_function: branching_entropy, cohesion_score, npmi, pmi\r\n",
      "model/plm/electra: base, large\r\n",
      "model/plm/electra/discriminator: base, large\r\n",
      "model/plm/electra/generator: base, large\r\n",
      "model/sentiment: _default, hiv4, lm, mpko_lex\r\n",
      "model/sentiment/lexicon: _default, hiv4, kosac_polarity, lm, mpko_lex\r\n",
      "model/tokenizer: bert_wordpiece, train_spm_t5\r\n",
      "model/tokenizer/spm: t5\r\n",
      "model/topic: default\r\n",
      "model/topic/task: topic_subtask\r\n",
      "model/topic/task/infer_topics: default\r\n",
      "model/topic/task/label_topics: default\r\n",
      "model/topic/task/load_corpus: default\r\n",
      "model/topic/task/load_model: default\r\n",
      "model/topic/task/save_labels: default\r\n",
      "model/topic/task/topic_wordclouds: default\r\n",
      "model/topic/task/train_model: dtm, lda\r\n",
      "model/topic/task/tune_params: default\r\n",
      "model/topic/task/visualize: default\r\n",
      "model/transformer: _default, _train, simple_classification, simple_ner, simple_t5, simple_t5_classification\r\n",
      "model/transformer/config: classification, t5\r\n",
      "model/transformer/pretrained: SciFive-base-Pubmed, bert-base-uncased, ekonelectra-base, electra-discriminator, finbert, t5-base\r\n",
      "pipeline: _blank, _build_corpus, _build_dataset, _default, blank, default\r\n",
      "pipeline/aggregate_columns: default\r\n",
      "pipeline/chunk: default\r\n",
      "pipeline/combine_columns: default\r\n",
      "pipeline/concat_dataframes: default\r\n",
      "pipeline/drop: default\r\n",
      "pipeline/drop_duplicates: default\r\n",
      "pipeline/eval_columns: default\r\n",
      "pipeline/explode_splits: default\r\n",
      "pipeline/extract_tokens: default\r\n",
      "pipeline/fillna: default\r\n",
      "pipeline/filter_length: default, words\r\n",
      "pipeline/filter_query: default\r\n",
      "pipeline/load_dataframe: default\r\n",
      "pipeline/melt: default\r\n",
      "pipeline/merge_dataframe: default\r\n",
      "pipeline/normalize: default\r\n",
      "pipeline/pivot: default\r\n",
      "pipeline/plot: default\r\n",
      "pipeline/predict: default\r\n",
      "pipeline/remove_startswith: default\r\n",
      "pipeline/rename_columns: default\r\n",
      "pipeline/replace: default\r\n",
      "pipeline/reset_index: default\r\n",
      "pipeline/sampling: default\r\n",
      "pipeline/save_as_json: default\r\n",
      "pipeline/save_as_text: default\r\n",
      "pipeline/save_dataframe: default\r\n",
      "pipeline/save_metadata: default\r\n",
      "pipeline/save_samples: default\r\n",
      "pipeline/segment: default\r\n",
      "pipeline/split_column: default\r\n",
      "pipeline/split_dataframe: default\r\n",
      "pipeline/split_sampling: default\r\n",
      "pipeline/stdout_samples: default\r\n",
      "pipeline/subset: default\r\n",
      "pipeline/summary_stats: default\r\n",
      "pipeline/tokenize: default\r\n",
      "pipeline/top_values: default\r\n",
      "preprocessor/normalizer: default, formal_en, formal_en_parantheses, formal_ko, informal_ko\r\n",
      "preprocessor/normalizer/ftfy: default\r\n",
      "preprocessor/normalizer/spaces: default\r\n",
      "preprocessor/normalizer/special_characters: default\r\n",
      "preprocessor/segmenter: chunk, default, kss, kss_merge_article, nltk, pysbd, pysbd_filter_pl, pysbd_merge_article, pysbd_merge_article_filter_len, pysbd_merge_enko, pysbd_merge_segment, simple\r\n",
      "preprocessor/segmenter/chunk: default\r\n",
      "preprocessor/segmenter/filter_language: default\r\n",
      "preprocessor/segmenter/filter_sentence_length: default\r\n",
      "preprocessor/segmenter/merge: default\r\n",
      "preprocessor/segmenter/separators: default\r\n",
      "preprocessor/segmenter/split: default\r\n",
      "preprocessor/tokenizer: bwp, default, mecab, mecab_econ, nltk, pynori, simple\r\n",
      "preprocessor/tokenizer/extract: default, mecab\r\n",
      "preprocessor/tokenizer/stopwords: default\r\n",
      "preprocessor/tokenizer/tokenize: default\r\n",
      "preprocessor/tokenizer/tokenize_article: default\r\n",
      "project: default, sample, test\r\n",
      "resource/meta: recessions\r\n",
      "resource/postag: mecab, nltk\r\n",
      "util/lmdata: build_vocab\r\n",
      "util/lmdata/sharding: default\r\n",
      "util/model/convert: convert_electra\r\n",
      "util/vocab/extract_nouns: default\r\n",
      "visualize: default\r\n",
      "visualize/plot: _default, barplot, confusion_matrix, default, histplot, lineplot, scatter, stackplot\r\n",
      "visualize/plot/confusion_matrix: default\r\n",
      "visualize/plot/figure: default\r\n",
      "visualize/plot/figure/annotation: default\r\n",
      "visualize/plot/figure/axvspan: default\r\n",
      "visualize/plot/histplot: default\r\n",
      "visualize/plot/lineplot: default\r\n",
      "visualize/plot/plot: default\r\n",
      "visualize/plot/savefig: default\r\n",
      "visualize/plot/scatter: default\r\n",
      "visualize/plot/series: default\r\n",
      "visualize/plot/stackplot: default\r\n",
      "visualize/plot/subplots: default\r\n",
      "visualize/treemap: default\r\n",
      "visualize/wordcloud: default\r\n",
      "workflow: _flow_\r\n",
      "workflow/example: example\r\n",
      "\r\n",
      "== Config ==\r\n",
      "\r\n",
      "This is the config generated for this run.\r\n",
      "You can override everything, for example:\r\n",
      "ekorpkit task=your_config_name\r\n",
      "--------------------------------------------------\r\n",
      "about:\r\n",
      "  app:\r\n",
      "    _target_: ekorpkit.cli.about\r\n",
      "    name: ekorpkit\r\n",
      "    author: Young Joon Lee\r\n",
      "    description: eKorpkit provides a flexible interface for NLP and ML research pipelines\r\n",
      "      such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "    website: https://entelecheia.github.io/ekorpkit-book/\r\n",
      "    version: ${__version__:}\r\n",
      "_target_: ekorpkit.cli.cmd\r\n",
      "_config_: about.app\r\n",
      "corpus:\r\n",
      "  column_info:\r\n",
      "    keys:\r\n",
      "      id: id\r\n",
      "      text: text\r\n",
      "      timestamp: timestamp\r\n",
      "      split: split\r\n",
      "    columns:\r\n",
      "      id: ${oc.select:..keys.id,id}\r\n",
      "      text: ${oc.select:..keys.text,text}\r\n",
      "      merge_meta_on: ${oc.select:..id}\r\n",
      "      timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "    data:\r\n",
      "      id: int\r\n",
      "      text: str\r\n",
      "    meta: null\r\n",
      "    timestamp:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    datetime:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "    sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    _target_: ekorpkit.info.column.ColumnInfo\r\n",
      "  cache:\r\n",
      "    uri: null\r\n",
      "    extract_archive: true\r\n",
      "    force_extract: false\r\n",
      "    return_parent_dir: true\r\n",
      "    cache_dir: ${dir.cache}\r\n",
      "    verbose: ${oc.select:..verbose, false}\r\n",
      "    path: ${cached_path:${.uri},${.extract_archive},${.force_extract},${.return_parent_dir},${.cache_dir},${.verbose}}\r\n",
      "  _target_: ekorpkit.corpora.corpus.Corpus\r\n",
      "  name: ${oc.select:.builtin.name, null}\r\n",
      "  data_dir: ${oc.select:.builtin.data_dir, ${dir.corpus}}\r\n",
      "  metadata_dir: null\r\n",
      "  filetype: ${oc.select:.builtin.filetype, null}\r\n",
      "  autoload: true\r\n",
      "  automerge: false\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "  use_name_as_subdir: true\r\n",
      "dataset:\r\n",
      "  column_info:\r\n",
      "    keys:\r\n",
      "      id: id\r\n",
      "      text: text\r\n",
      "      timestamp: timestamp\r\n",
      "      split: split\r\n",
      "    columns:\r\n",
      "      id: ${oc.select:..keys.id,id}\r\n",
      "      text: ${oc.select:..keys.text,text}\r\n",
      "      merge_meta_on: ${oc.select:..id}\r\n",
      "      timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "    data:\r\n",
      "      id: int\r\n",
      "      text: str\r\n",
      "    meta: null\r\n",
      "    timestamp:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    datetime:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "    sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    _target_: ekorpkit.info.column.ColumnInfo\r\n",
      "  _target_: ekorpkit.datasets.dataset.Dataset\r\n",
      "  name: ${oc.select:.builtin.name, null}\r\n",
      "  data_dir: ${dir.dataset}/dataset\r\n",
      "  filetype: ${oc.select:.builtin.filetype, csv}\r\n",
      "  autoload: true\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "  use_name_as_subdir: true\r\n",
      "dir:\r\n",
      "  archive: ${.data}/archive\r\n",
      "  cache: ${.workspace}/.cache\r\n",
      "  corpus: ${.dataset}/corpus\r\n",
      "  data: ${.workspace}/data\r\n",
      "  dataset: ${.data}/datasets\r\n",
      "  ekorpkit: ${__ekorpkit_path__:}\r\n",
      "  home: ${__home_path__:}\r\n",
      "  log: ${.project}/logs\r\n",
      "  model: ${.data}/models\r\n",
      "  output: ${.project}/outputs\r\n",
      "  project: ${.workspace}/projects/${project}\r\n",
      "  resource: ${.ekorpkit}/resources\r\n",
      "  runtime: ${get_original_cwd:}\r\n",
      "  tmp: ${.workspace}/.tmp\r\n",
      "  workspace: ${oc.env:EKORPKIT_WORKSPACE_ROOT,${.home}/.ekorpkit}\r\n",
      "env:\r\n",
      "  dotenv_path: ${dir.runtime}/.env\r\n",
      "  dotenv: ${dotenv_values:${.dotenv_path}}\r\n",
      "  os:\r\n",
      "    MODIN_ENGINE: ray\r\n",
      "    MODIN_CPUS: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "    CACHED_PATH_CACHE_ROOT: ${dir.cache}/cached_path\r\n",
      "  distributed_framework:\r\n",
      "    backend: joblib\r\n",
      "    initialize: true\r\n",
      "    num_workers: ${oc.select:num_workers,50}\r\n",
      "  ray:\r\n",
      "    num_cpus: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "  dask:\r\n",
      "    n_workers: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "  batcher:\r\n",
      "    procs: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "    minibatch_size: 1000\r\n",
      "    backend: ${..distributed_framework.backend}\r\n",
      "    task_num_cpus: 1\r\n",
      "    task_num_gpus: 0\r\n",
      "    verbose: 10\r\n",
      "app_name: ${about.app.name}\r\n",
      "debug_mode: false\r\n",
      "print_config: false\r\n",
      "print_resolved_config: true\r\n",
      "num_workers: 1\r\n",
      "verbose: false\r\n",
      "ignore_warnings: true\r\n",
      "model:\r\n",
      "  name: model\r\n",
      "  data_dir: ${oc.select:..data_dir, ${dir.project}/data}\r\n",
      "  output_dir: ${oc.select:..output_dir, ${dir.output}/${.name}}\r\n",
      "  num_workers: ${oc.select:num_workers,1}\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "project: ${oc.env:EKORPKIT_PROJECT,default}\r\n",
      "\r\n",
      "--------------------------------------------------\r\n",
      "Powered by Hydra (https://hydra.cc)\r\n",
      "Use --hydra-help to view Hydra specific help\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6242cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Defaults List\r\n",
      "*************\r\n",
      "| Config path                  | Package             | _self_ | Parent              | \r\n",
      "--------------------------------------------------------------------------------------\r\n",
      "| hydra/output/default         | hydra               | False  | hydra/config        |\r\n",
      "| hydra/launcher/basic         | hydra.launcher      | False  | hydra/config        |\r\n",
      "| hydra/sweeper/basic          | hydra.sweeper       | False  | hydra/config        |\r\n",
      "| hydra/help/help              | hydra.help          | False  | hydra/config        |\r\n",
      "| hydra/hydra_help/default     | hydra.hydra_help    | False  | hydra/config        |\r\n",
      "| hydra/hydra_logging/colorlog | hydra.hydra_logging | False  | hydra/config        |\r\n",
      "| hydra/job_logging/colorlog   | hydra.job_logging   | False  | hydra/config        |\r\n",
      "| hydra/env/default            | hydra.env           | False  | hydra/config        |\r\n",
      "| hydra/config                 | hydra               | True   | <root>              |\r\n",
      "| config                       |                     | True   | <root>              |\r\n",
      "| about/app/default            | about.app           | False  | about/default       |\r\n",
      "| about/default                | about               | True   | config              |\r\n",
      "| cmd/default                  |                     | False  | config              |\r\n",
      "| column_info/_build           | corpus.column_info  | False  | column_info/default |\r\n",
      "| column_info/default          | corpus.column_info  | True   | corpus/default      |\r\n",
      "| cache/extract_archive        | corpus.cache        | False  | corpus/default      |\r\n",
      "| corpus/default               | corpus              | True   | config              |\r\n",
      "| column_info/_build           | dataset.column_info | False  | column_info/default |\r\n",
      "| column_info/default          | dataset.column_info | True   | dataset/default     |\r\n",
      "| dataset/default              | dataset             | True   | config              |\r\n",
      "| dir/default                  | dir                 | False  | config              |\r\n",
      "| env/run                      | env                 | False  | env/default         |\r\n",
      "| env/default                  | env                 | True   | config              |\r\n",
      "| mode/default                 |                     | False  | config              |\r\n",
      "| model/default                | model               | False  | config              |\r\n",
      "| project/default              |                     | False  | config              |\r\n",
      "--------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit --info defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074ed1c3",
   "metadata": {},
   "source": [
    "## Via Python\n",
    "\n",
    "### Compose an ekorpkit config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc85a094",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config type: <class 'omegaconf.dictconfig.DictConfig'>\n",
      "{'_config_': 'about.app',\n",
      " '_target_': 'ekorpkit.cli.cmd',\n",
      " 'about': {'app': {'_target_': 'ekorpkit.cli.about',\n",
      "                   'author': 'Young Joon Lee',\n",
      "                   'description': 'eKorpkit provides a flexible interface for '\n",
      "                                  'NLP and ML research pipelines such as '\n",
      "                                  'extraction, transformation, tokenization, '\n",
      "                                  'training, and visualization.',\n",
      "                   'name': 'ekorpkit',\n",
      "                   'version': '0.1.31+8.gdef1e03.dirty',\n",
      "                   'website': 'https://entelecheia.github.io/ekorpkit-book/'}},\n",
      " 'app_name': 'ekorpkit',\n",
      " 'corpus': {'_target_': 'ekorpkit.corpora.corpus.Corpus',\n",
      "            'autoload': True,\n",
      "            'automerge': False,\n",
      "            'cache': {'cache_dir': '/root/.ekorpkit/.cache',\n",
      "                      'extract_archive': True,\n",
      "                      'force_extract': False,\n",
      "                      'path': None,\n",
      "                      'return_parent_dir': True,\n",
      "                      'uri': None,\n",
      "                      'verbose': False},\n",
      "            'column_info': {'_target_': 'ekorpkit.info.column.ColumnInfo',\n",
      "                            'columns': {'id': 'id',\n",
      "                                        'merge_meta_on': None,\n",
      "                                        'text': 'text',\n",
      "                                        'timestamp': None},\n",
      "                            'data': {'id': 'int', 'text': 'str'},\n",
      "                            'datetime': {'_parms_': None,\n",
      "                                         'format': None,\n",
      "                                         'key': None},\n",
      "                            'keys': {'id': 'id',\n",
      "                                     'split': 'split',\n",
      "                                     'text': 'text',\n",
      "                                     'timestamp': 'timestamp'},\n",
      "                            'meta': None,\n",
      "                            'segment_separator': '\\\\n\\\\n',\n",
      "                            'sentence_separator': '\\\\n',\n",
      "                            'timestamp': {'_parms_': None,\n",
      "                                          'format': None,\n",
      "                                          'key': None}},\n",
      "            'data_dir': '/root/.ekorpkit/data/datasets/corpus',\n",
      "            'filetype': None,\n",
      "            'metadata_dir': None,\n",
      "            'name': None,\n",
      "            'use_name_as_subdir': True,\n",
      "            'verbose': False},\n",
      " 'dataset': {'_target_': 'ekorpkit.datasets.dataset.Dataset',\n",
      "             'autoload': True,\n",
      "             'column_info': {'_target_': 'ekorpkit.info.column.ColumnInfo',\n",
      "                             'columns': {'id': 'id',\n",
      "                                         'merge_meta_on': None,\n",
      "                                         'text': 'text',\n",
      "                                         'timestamp': None},\n",
      "                             'data': {'id': 'int', 'text': 'str'},\n",
      "                             'datetime': {'_parms_': None,\n",
      "                                          'format': None,\n",
      "                                          'key': None},\n",
      "                             'keys': {'id': 'id',\n",
      "                                      'split': 'split',\n",
      "                                      'text': 'text',\n",
      "                                      'timestamp': 'timestamp'},\n",
      "                             'meta': None,\n",
      "                             'segment_separator': '\\\\n\\\\n',\n",
      "                             'sentence_separator': '\\\\n',\n",
      "                             'timestamp': {'_parms_': None,\n",
      "                                           'format': None,\n",
      "                                           'key': None}},\n",
      "             'data_dir': '/root/.ekorpkit/data/datasets/dataset',\n",
      "             'filetype': 'csv',\n",
      "             'name': None,\n",
      "             'use_name_as_subdir': True,\n",
      "             'verbose': False},\n",
      " 'debug_mode': False,\n",
      " 'dir': {'archive': '/root/.ekorpkit/data/archive',\n",
      "         'cache': '/root/.ekorpkit/.cache',\n",
      "         'corpus': '/root/.ekorpkit/data/datasets/corpus',\n",
      "         'data': '/root/.ekorpkit/data',\n",
      "         'dataset': '/root/.ekorpkit/data/datasets',\n",
      "         'ekorpkit': '/workspace/projects/ekorpkit/ekorpkit',\n",
      "         'home': '/root',\n",
      "         'log': '/root/.ekorpkit/projects/default/logs',\n",
      "         'model': '/root/.ekorpkit/data/models',\n",
      "         'output': '/root/.ekorpkit/projects/default/outputs',\n",
      "         'project': '/root/.ekorpkit/projects/default',\n",
      "         'resource': '/workspace/projects/ekorpkit/ekorpkit/resources',\n",
      "         'runtime': '/workspace/projects/ekorpkit-book/ekorpkit-book/docs/basics',\n",
      "         'tmp': '/root/.ekorpkit/.tmp',\n",
      "         'workspace': '/root/.ekorpkit'},\n",
      " 'env': {'batcher': {'backend': 'joblib',\n",
      "                     'minibatch_size': 1000,\n",
      "                     'procs': 1,\n",
      "                     'task_num_cpus': 1,\n",
      "                     'task_num_gpus': 0,\n",
      "                     'verbose': 10},\n",
      "         'dask': {'n_workers': 1},\n",
      "         'distributed_framework': {'backend': 'joblib',\n",
      "                                   'initialize': True,\n",
      "                                   'num_workers': 1},\n",
      "         'dotenv': {},\n",
      "         'dotenv_path': '/workspace/projects/ekorpkit-book/ekorpkit-book/docs/basics/.env',\n",
      "         'os': {'CACHED_PATH_CACHE_ROOT': '/root/.ekorpkit/.cache/cached_path',\n",
      "                'MODIN_CPUS': 1,\n",
      "                'MODIN_ENGINE': 'ray'},\n",
      "         'ray': {'num_cpus': 1}},\n",
      " 'ignore_warnings': True,\n",
      " 'model': {'data_dir': '/root/.ekorpkit/projects/default/data',\n",
      "           'name': 'model',\n",
      "           'num_workers': 1,\n",
      "           'output_dir': '/root/.ekorpkit/projects/default/outputs/model',\n",
      "           'verbose': False},\n",
      " 'num_workers': 1,\n",
      " 'preprocessor': {'normalizer': {'_target_': 'ekorpkit.preprocessors.normalizer.Normalizer',\n",
      "                                 'ftfy': {'decode_inconsistent_utf8': True,\n",
      "                                          'fix_c1_controls': True,\n",
      "                                          'fix_character_width': True,\n",
      "                                          'fix_encoding': True,\n",
      "                                          'fix_latin_ligatures': True,\n",
      "                                          'fix_line_breaks': True,\n",
      "                                          'fix_surrogates': True,\n",
      "                                          'max_decode_length': 1000000,\n",
      "                                          'normalization': 'NFKC',\n",
      "                                          'remove_control_chars': True,\n",
      "                                          'remove_terminal_escapes': True,\n",
      "                                          'replace_lossy_sequences': True,\n",
      "                                          'restore_byte_a0': True,\n",
      "                                          'uncurl_quotes': True,\n",
      "                                          'unescape_html': True},\n",
      "                                 'hanja2hangle': False,\n",
      "                                 'num_repeats': 2,\n",
      "                                 'spaces': {'collapse_whitespaces': True,\n",
      "                                            'fix_whitespaces': True,\n",
      "                                            'num_spaces_for_tab': 4,\n",
      "                                            'replace_tabs': True,\n",
      "                                            'strip': True},\n",
      "                                 'special_characters': {'fix_ellipsis': True,\n",
      "                                                        'fix_emoticons': False,\n",
      "                                                        'fix_hyphens': True,\n",
      "                                                        'fix_slashes': True,\n",
      "                                                        'fix_tildes': True,\n",
      "                                                        'regular_parentheses_only': False,\n",
      "                                                        'single_quotes_only': False}},\n",
      "                  'segmenter': {'chunk': {'_func_': {'len_bytes': {'_partial_': True,\n",
      "                                                                   '_target_': 'ekorpkit.utils.func.len_bytes'},\n",
      "                                                     'len_words': {'_partial_': True,\n",
      "                                                                   '_target_': 'ekorpkit.utils.func.len_words'}},\n",
      "                                          'chunk_overlap': False,\n",
      "                                          'chunk_size': 300,\n",
      "                                          'len_func': 'len_bytes'},\n",
      "                                'filter_language': {'detection_level': 'segment',\n",
      "                                                    'filter': False,\n",
      "                                                    'languages_to_keep': ['en',\n",
      "                                                                          'ko'],\n",
      "                                                    'min_language_probability': 0.8},\n",
      "                                'filter_programming_language': False,\n",
      "                                'filter_sentence_length': {'filter': False,\n",
      "                                                           'min_length': 10,\n",
      "                                                           'min_num_words': 3},\n",
      "                                'merge': {'broken_lines_threshold': 0.4,\n",
      "                                          'empty_lines_threshold': 0.6,\n",
      "                                          'merge_level': 'segment',\n",
      "                                          'merge_lines': False},\n",
      "                                'print_args': False,\n",
      "                                'return_as_list': False,\n",
      "                                'separators': {'in_segment': '\\\\n\\\\n',\n",
      "                                               'in_sentence': '\\\\n',\n",
      "                                               'out_segment': '\\\\n\\\\n',\n",
      "                                               'out_sentence': '\\\\n'},\n",
      "                                'split': {'keep_segment': True,\n",
      "                                          'max_recover_length': 30000,\n",
      "                                          'max_recover_step': 0},\n",
      "                                'verbose': True},\n",
      "                  'tokenizer': {'_target_': 'ekorpkit.preprocessors.tokenizer.SimpleTokenizer',\n",
      "                                'extract': {'noun_postags': ['NNG',\n",
      "                                                             'NNP',\n",
      "                                                             'XSN',\n",
      "                                                             'SL',\n",
      "                                                             'XR',\n",
      "                                                             'NNB',\n",
      "                                                             'NR'],\n",
      "                                            'postag_delim': '/',\n",
      "                                            'postag_length': None,\n",
      "                                            'postags': None,\n",
      "                                            'stop_postags': ['SP',\n",
      "                                                             'SF',\n",
      "                                                             'SE',\n",
      "                                                             'SSO',\n",
      "                                                             'SSC',\n",
      "                                                             'SC',\n",
      "                                                             'SY',\n",
      "                                                             'SH'],\n",
      "                                            'strip_pos': True},\n",
      "                                'normalize': None,\n",
      "                                'return_as_list': False,\n",
      "                                'stopwords': {'_target_': 'ekorpkit.preprocessors.stopwords.Stopwords',\n",
      "                                              'lowercase': True,\n",
      "                                              'name': 'stopwords',\n",
      "                                              'nltk_stopwords': None,\n",
      "                                              'stopwords': "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None,\n",
      "                                              'stopwords_path': None,\n",
      "                                              'verbose': False},\n",
      "                                'stopwords_path': None,\n",
      "                                'tagset': None,\n",
      "                                'tokenize': {'flatten': True,\n",
      "                                             'include_whitespace_token': True,\n",
      "                                             'lowercase': False,\n",
      "                                             'postag_delim': '/',\n",
      "                                             'postag_length': None,\n",
      "                                             'punct_postags': ['SF',\n",
      "                                                               'SP',\n",
      "                                                               'SSO',\n",
      "                                                               'SSC',\n",
      "                                                               'SY'],\n",
      "                                             'strip_pos': False,\n",
      "                                             'tokenize_each_word': False,\n",
      "                                             'userdic_path': None,\n",
      "                                             'wordpieces_prefix': '##'},\n",
      "                                'tokenize_article': {'sentence_separator': '\\\\n'},\n",
      "                                'verbose': False}},\n",
      " 'print_config': False,\n",
      " 'print_resolved_config': True,\n",
      " 'project': 'default',\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from ekorpkit import eKonf\n",
    "cfg = eKonf.compose()\n",
    "print('Config type:', type(cfg))\n",
    "eKonf.pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc072284",
   "metadata": {},
   "source": [
    "### Instantiating objects with an ekorpkit config\n",
    "\n",
    "#### compose a config for the nltk class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f71b9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'ekorpkit.preprocessors.tokenizer.NLTKTokenizer',\n",
      " 'extract': {'noun_postags': ['NN', 'NNP', 'NNS', 'NNPS'],\n",
      "             'postag_delim': '/',\n",
      "             'postag_length': None,\n",
      "             'postags': None,\n",
      "             'stop_postags': ['.'],\n",
      "             'strip_pos': True},\n",
      " 'nltk': {'lemmatize': False,\n",
      "          'lemmatizer': {'_target_': 'nltk.stem.WordNetLemmatizer'},\n",
      "          'stem': True,\n",
      "          'stemmer': {'_target_': 'nltk.stem.PorterStemmer'}},\n",
      " 'normalize': None,\n",
      " 'return_as_list': False,\n",
      " 'stopwords': {'_target_': 'ekorpkit.preprocessors.stopwords.Stopwords',\n",
      "               'lowercase': True,\n",
      "               'name': 'stopwords',\n",
      "               'nltk_stopwords': None,\n",
      "               'stopwords': None,\n",
      "               'stopwords_path': None,\n",
      "               'verbose': False},\n",
      " 'stopwords_path': None,\n",
      " 'tagset': None,\n",
      " 'tokenize': {'flatten': True,\n",
      "              'include_whitespace_token': True,\n",
      "              'lowercase': False,\n",
      "              'postag_delim': '/',\n",
      "              'postag_length': None,\n",
      "              'punct_postags': ['SF', 'SP', 'SSO', 'SSC', 'SY'],\n",
      "              'strip_pos': False,\n",
      "              'tokenize_each_word': False,\n",
      "              'userdic_path': None,\n",
      "              'wordpieces_prefix': '##'},\n",
      " 'tokenize_article': {'sentence_separator': '\\\\n'},\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from ekorpkit import eKonf\n",
    "config_group='preprocessor/tokenizer=nltk'\n",
    "cfg = eKonf.compose(config_group=config_group)\n",
    "eKonf.pprint(cfg)\n",
    "nltk = eKonf.instantiate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a54d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i/PRP',\n",
       " 'shall/MD',\n",
       " 'reemphas/VB',\n",
       " 'some/DT',\n",
       " 'of/IN',\n",
       " 'those/DT',\n",
       " 'thought/NNS',\n",
       " 'today/NN',\n",
       " 'in/IN',\n",
       " 'the/DT',\n",
       " 'context/NN',\n",
       " 'of/IN',\n",
       " 'legisl/JJ',\n",
       " 'propos/NNS',\n",
       " 'that/WDT',\n",
       " 'are/VBP',\n",
       " 'now/RB',\n",
       " 'befor/IN',\n",
       " 'the/DT',\n",
       " 'current/JJ',\n",
       " 'congress/NNP',\n",
       " './.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I shall reemphasize some of those thoughts today in the context of legislative proposals that are now before the current Congress.\"\n",
    "nltk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04ccd441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thought', 'today', 'context', 'propos', 'congress']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.nouns(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad6483a",
   "metadata": {},
   "source": [
    "#### compose a config for the mecab class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89b3ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'ekorpkit.preprocessors.tokenizer.MecabTokenizer',\n",
      " 'extract': {'noun_postags': ['NNG', 'NNP', 'XSN', 'SL', 'XR', 'NNB', 'NR'],\n",
      "             'postag_delim': '/',\n",
      "             'postag_length': None,\n",
      "             'postags': None,\n",
      "             'stop_postags': ['SP', 'SF', 'SE', 'SSO', 'SSC', 'SC', 'SY', 'SH'],\n",
      "             'strip_pos': True},\n",
      " 'mecab': {'backend': 'mecab-python3', 'userdic_path': None, 'verbose': False},\n",
      " 'normalize': None,\n",
      " 'return_as_list': False,\n",
      " 'stopwords': {'_target_': 'ekorpkit.preprocessors.stopwords.Stopwords',\n",
      "               'lowercase': True,\n",
      "               'name': 'stopwords',\n",
      "               'nltk_stopwords': None,\n",
      "               'stopwords': None,\n",
      "               'stopwords_path': None,\n",
      "               'verbose': False},\n",
      " 'stopwords_path': None,\n",
      " 'tagset': None,\n",
      " 'tokenize': {'flatten': True,\n",
      "              'include_whitespace_token': True,\n",
      "              'lowercase': False,\n",
      "              'postag_delim': '/',\n",
      "              'postag_length': None,\n",
      "              'punct_postags': ['SF', 'SP', 'SSO', 'SSC', 'SY'],\n",
      "              'strip_pos': False,\n",
      "              'tokenize_each_word': False,\n",
      "              'userdic_path': None,\n",
      "              'wordpieces_prefix': '##'},\n",
      " 'tokenize_article': {'sentence_separator': '\\\\n'},\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "config_group='preprocessor/tokenizer=mecab'\n",
    "cfg = eKonf.compose(config_group=config_group)\n",
    "eKonf.pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c79e0",
   "metadata": {},
   "source": [
    "#### intantiate a mecab config and tokenize a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "132786a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMF/SL',\n",
       " '가/JKS',\n",
       " '/SP',\n",
       " '推定/NNG',\n",
       " '한/XSA+ETM',\n",
       " '/SP',\n",
       " '우리나라/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " 'GDP/SL',\n",
       " '갭/NNG',\n",
       " '률/XSN',\n",
       " '은/JX',\n",
       " '/SP',\n",
       " '今年/NNG',\n",
       " '에/JKB',\n",
       " '도/JX',\n",
       " '/SP',\n",
       " '소폭/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " '마이너스/NNG',\n",
       " '(/SSO',\n",
       " '−)/SY',\n",
       " '를/JKO',\n",
       " '/SP',\n",
       " '持續/NNG',\n",
       " '하/XSV',\n",
       " '고/EC',\n",
       " '/SP',\n",
       " '있/VX',\n",
       " '다/EF',\n",
       " './SF']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab = eKonf.instantiate(cfg)\n",
    "text = 'IMF가 推定한 우리나라의 GDP갭률은 今年에도 소폭의 마이너스(−)를 持續하고 있다.'\n",
    "mecab.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e49ab1",
   "metadata": {},
   "source": [
    "#### compose and instantiate a `formal_ko` config for the normalizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27504b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMF가 추정한 우리나라의 GDP갭률은 금년에도 소폭의 마이너스(-)를 지속하고 있다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_group='preprocessor/normalizer=formal_ko'\n",
    "cfg_norm = eKonf.compose(config_group=config_group)\n",
    "norm = eKonf.instantiate(cfg_norm)\n",
    "norm(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99727573",
   "metadata": {},
   "source": [
    "#### instantiate a mecab config with the above normalizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd6f6d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMF/SL',\n",
       " '가/JKS',\n",
       " '/SP',\n",
       " '추정/NNG',\n",
       " '한/XSA+ETM',\n",
       " '/SP',\n",
       " '우리나라/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " 'GDP/SL',\n",
       " '갭/NNG',\n",
       " '률/XSN',\n",
       " '은/JX',\n",
       " '/SP',\n",
       " '금년/NNG',\n",
       " '에/JKB',\n",
       " '도/JX',\n",
       " '/SP',\n",
       " '소폭/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " '마이너스/NNG',\n",
       " '(/SSO',\n",
       " '-)/SY',\n",
       " '를/JKO',\n",
       " '/SP',\n",
       " '지속/NNG',\n",
       " '하/XSV',\n",
       " '고/EC',\n",
       " '/SP',\n",
       " '있/VX',\n",
       " '다/EF',\n",
       " './SF']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_group='preprocessor/tokenizer=mecab'\n",
    "cfg = eKonf.compose(config_group=config_group)\n",
    "cfg.normalize = cfg_norm\n",
    "mecab = eKonf.instantiate(cfg)\n",
    "mecab.tokenize(text)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "source_map": [
   11,
   17,
   19,
   23,
   36,
   42,
   47,
   49,
   55,
   61,
   67,
   75,
   80,
   82,
   86,
   90,
   94,
   98,
   102,
   107,
   111
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}