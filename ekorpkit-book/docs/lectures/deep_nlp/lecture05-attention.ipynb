{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {},
   "source": [
    "# Attention is All You Need\n",
    "\n",
    "\"Attention Is All You Need\" {cite}`vaswani2017attention` introduced the Transformer model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {},
   "source": [
    "## The Basic Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930976a",
   "metadata": {},
   "source": [
    "![](../figs/deep_nlp/attention/transformer-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69856d2d",
   "metadata": {},
   "source": [
    "- The Transformer model is based on an encoder-decoder architecture. \n",
    "- The encoder is the grey rectangle on the left-hand side, the decoder the one on the right-hand side.\n",
    "- Both the encoder and decoder consist of two and three sub-layers, respectively: multi-head self-attention, a fully-connected feed forward network and — in the case of the decoder — encoder-decoder self-attention.\n",
    "- Transformer actually stacks multiple encoders and decoders on top of each other N times.\n",
    "- This means that the output of one encoder is used as the input for the next encoder, and the output of one decoder is used as the input for the next decoder.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc953b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
