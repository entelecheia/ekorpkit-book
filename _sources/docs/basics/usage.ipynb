{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75853d5",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "## Via Command Line Interface (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1734733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "name        : ekorpkit\r\n",
      "author      : Young Joon Lee\r\n",
      "description : eKorpkit provides a flexible interface for NLP and ML research pipelines such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "website     : https://entelecheia.github.io/ekorpkit-book/\r\n",
      "version     : 0.1.32+4.gfd15d82.dirty\r\n",
      "\r\n",
      "Execute `ekorpkit --help` to see what eKorpkit provides\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169a472",
   "metadata": {},
   "source": [
    "### CLI example to build a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db697cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-10 07:49:34,649\u001b[0m][\u001b[34mekorpkit.io.fetch.loader.dummy\u001b[0m][\u001b[32mINFO\u001b[0m] - /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes.csv already exists. skipping..\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-10 07:49:34,807\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Processing [1] files from ['fomc_minutes.csv']\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,807\u001b[0m][\u001b[34mekorpkit.io.load.data\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading [train] documents from 1 csv files\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,807\u001b[0m][\u001b[34mekorpkit.io.load.data\u001b[0m][\u001b[32mINFO\u001b[0m] - ==> processing /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes.csv\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,808\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Processing [1] files from ['/workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes.csv']\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,808\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading 1 dataframes from ['/workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes.csv']\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,808\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading data from /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes.csv\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,813\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to load and parse data: 0:00:00.041798\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,814\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] - \r\n",
      "Transforming dataframe with pipeline: ['reset_index', 'save_metadata']\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-10 07:49:34,823\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipeline: OrderedDict([('reset_index', 'reset_index'), ('save_metadata', 'save_metadata')])\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,825\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function reset_index at 0x7f0eb6ca0c10>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,827\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function save_metadata at 0x7f0eb6fc3820>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,833\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving dataframe to /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/meta-fomc_minutes-train.parquet\u001b[0m\r\n",
      "\r",
      "apply len_bytes to num_bytes:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_bytes to num_bytes: 100%|████████████| 5/5 [00:00<00:00, 14103.24it/s]\r\n",
      "\r",
      "apply len_sents to num_sents:   0%|                       | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "apply len_sents to num_sents: 100%|██████████████| 5/5 [00:00<00:00, 385.02it/s]\r\n",
      "[\u001b[36m2022-06-10 07:49:34,880\u001b[0m][\u001b[34mekorpkit.info.stat\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to calculate statistics before processing: 0:00:00.034106\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,880\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] - \r\n",
      "Processing dataframe with pipeline: ['normalize', 'segment', 'drop_duplicates', 'save_samples', 'save_dataframe']\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,889\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipeline: OrderedDict([('normalize', 'normalize'), ('segment', 'segment'), ('drop_duplicates', 'drop_duplicates'), ('save_samples', 'save_samples'), ('save_dataframe', 'save_dataframe')])\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,891\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function normalize at 0x7f0eb6ca0d30>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:34,895\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - instantiating normalizer\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Normalizing column: text:   0%|                           | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Normalizing column: text: 100%|██████████████████| 5/5 [00:00<00:00, 148.42it/s]\r\n",
      "[\u001b[36m2022-06-10 07:49:35,428\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to normalize: 0:00:00.034739\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:35,430\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function segment at 0x7f0eb6ca0ee0>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:35,436\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] - instantiating segmenter\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:35,436\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - instantiating ekorpkit.preprocessors.segmenter.PySBDSegmenter...\u001b[0m\r\n",
      "\r",
      "Splitting column: text:   0%|                             | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:  40%|████████▍            | 2/5 [00:00<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:  60%|████████████▌        | 3/5 [00:00<00:00,  3.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text:  80%|████████████████▊    | 4/5 [00:01<00:00,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text: 100%|█████████████████████| 5/5 [00:01<00:00,  3.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Splitting column: text: 100%|█████████████████████| 5/5 [00:01<00:00,  2.91it/s]\r\n",
      "[\u001b[36m2022-06-10 07:49:37,174\u001b[0m][\u001b[34mekorpkit.pipelines.pipe\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to segment: 0:00:01.717029\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:37,176\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function drop_duplicates at 0x7f0eb6fc3430>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:37,180\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function save_samples at 0x7f0eb6fc34c0>)\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-10 07:49:37,185\u001b[0m][\u001b[34mekorpkit.ekonf\u001b[0m][\u001b[32mINFO\u001b[0m] - Applying pipe: functools.partial(<function save_dataframe at 0x7f0eb6fc38b0>)\u001b[0m\r\n",
      "[\u001b[36m2022-06-10 07:49:37,188\u001b[0m][\u001b[34mekorpkit.io.file\u001b[0m][\u001b[32mINFO\u001b[0m] - Saving dataframe to /workspace/data/datasets/corpus/ekorpkit/fomc_minutes/fomc_minutes-train.parquet\u001b[0m\r\n",
      "\r",
      "apply len_bytes to num_bytes:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_bytes to num_bytes: 100%|█████████████| 5/5 [00:00<00:00, 4977.81it/s]\r\n",
      "\r",
      "apply len_wospc to num_bytes_wospc:   0%|                 | 0/5 [00:00<?, ?it/s]\r",
      "apply len_wospc to num_bytes_wospc: 100%|████████| 5/5 [00:00<00:00, 748.15it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "apply len_words to num_words:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_words to num_words: 100%|█████████████| 5/5 [00:00<00:00, 2950.41it/s]\r\n",
      "\r",
      "apply len_sents to num_sents:   0%|                       | 0/5 [00:00<?, ?it/s]\r",
      "apply len_sents to num_sents: 100%|██████████████| 5/5 [00:00<00:00, 364.72it/s]\r\n",
      "\r",
      "apply len_segments to num_segments:   0%|                 | 0/5 [00:00<?, ?it/s]\r",
      "apply len_segments to num_segments: 100%|████████| 5/5 [00:00<00:00, 394.68it/s]\r\n",
      "[\u001b[36m2022-06-10 07:49:37,274\u001b[0m][\u001b[34mekorpkit.info.stat\u001b[0m][\u001b[32mINFO\u001b[0m] -  >> elapsed time to calculate statistics: 0:00:00.072036\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[36m2022-06-10 07:49:37,287\u001b[0m][\u001b[34mekorpkit.corpora.build\u001b[0m][\u001b[32mINFO\u001b[0m] - \r\n",
      "Corpus [fomc_minutes] is built to [/workspace/data/datasets/corpus/ekorpkit/fomc_minutes] from [/workspace/data/datasets/corpus/ekorpkit/fomc_minutes]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit --config-dir /workspace/projects/ekorpkit-config/config  \\\n",
    "    project=esgml \\\n",
    "    dir.workspace=/workspace \\\n",
    "    verbose=false \\\n",
    "    print_config=false \\\n",
    "    num_workers=1 \\\n",
    "    cmd=fetch_builtin_corpus \\\n",
    "    +corpus/builtin=_dummy_fomc_minutes \\\n",
    "    corpus.builtin.io.calculate_stats=true \\\n",
    "    corpus.builtin.io.preprocess_text=true \\\n",
    "    corpus.builtin.io.overwrite=false \\\n",
    "    corpus.builtin.io.force_download=false"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca3155",
   "metadata": {},
   "source": [
    "### CLI Help\n",
    "\n",
    "To see the available configurations for CLI, run the command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eac86bc2",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== ekorpkit == \r\n",
      "\r\n",
      "author: Young Joon Lee\r\n",
      "description: eKorpkit provides a flexible interface for NLP and ML research pipelines such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "\r\n",
      "ekorpkit Command Line Interface for Hydra\r\n",
      "\r\n",
      "== Configuration groups ==\r\n",
      "\r\n",
      "Compose your configuration from those groups (task=task_name)\r\n",
      "_func_: aggregate_columns, chunk, combine_columns, concat_dataframes, drop, drop_duplicates, eval_columns, evaluate_classification_performance, explode_splits, extract_tokens, fillna, filter_length, filter_query, general_function, load_dataframe, melt, merge_dataframe, normalize, pivot, plot, predict, remove_startswith, rename_columns, reset_index, sampling, save_as_json, save_as_text, save_dataframe, save_metadata, save_samples, segment, split_column, split_dataframe, split_sampling, stdout_samples, subset, summary_stats, tokenize, top_values\r\n",
      "_func_/concat_dataframes: default\r\n",
      "_func_/len_bytes: default\r\n",
      "_func_/len_segments: default\r\n",
      "_func_/len_sents: default\r\n",
      "_func_/len_words: default\r\n",
      "_func_/len_wospc: default\r\n",
      "_func_/load_dataframe: cache, default\r\n",
      "_func_/save_dataframe: default\r\n",
      "_method_: fit_transform_show, fittransform_show, load_and_concatenate, replace, train_and_eval\r\n",
      "about: default, run\r\n",
      "about/app: default, run\r\n",
      "auto: load\r\n",
      "cache: archive, file\r\n",
      "cmd: convert_electra, default, fetch_builtin_corpus, fetch_simple_dataset, fetch_t5_dataset, info, job, listup, pipeline, task, topic_task, transformer_finetune, workflow\r\n",
      "column_info: _build, default, feature\r\n",
      "corpus: corpora, corpus, dataset, default\r\n",
      "corpus/builtin: _build, _dummy_bok_minutes, _dummy_fomc_minutes, aida_paper, aihub_book, aihub_formal1, aihub_formal2, aihub_koen_formal, aihub_koen_sci, aihub_koen_ssci, aihub_law_case, aihub_law_kb, aihub_paper, aihub_patent1, aihub_patent2, bigkinds, bigpatent, bok_minutes, c4_realnewslike, cb_speech, cc_news, courtlistener, earnings_call, edgar, enron_mail, enwiki, esg_report, fomc, gd_review, hacker_news, kaist, kcbert, kcc, kowiki, mc4_ko, namuwiki, nih_exporter, nikl_news, nikl_spoken, nikl_written, oscar_ko, pathobook, philpapers, pmc_comm, pmc_noncomm, pubmed, respec, reuters_financial, sec_report, stackexchange, us_equities_news, verbcl, youtube_subtitles\r\n",
      "corpus/preset: builtins\r\n",
      "data: _na, concat, default\r\n",
      "dataset: dataset, datasets, default, feature, feature_build, preset, simple, simple_auto, t5\r\n",
      "dataset/preset: builtins\r\n",
      "dataset/simple: _build, analystsent_kr, bc4chemd, bc5cdr, esg_topics, financial_phrasebank, finphrase_kr, mp_tone_kr, ncbi-disease, nsmc, pathner, sst2\r\n",
      "dataset/t5: BC2GM, BC4CHEMD, BC5CDR-chem, BC5CDR-disease, JNLPBA, NCBI-disease, _build, _scifive_finetune, linnaeus, s800\r\n",
      "dir: default\r\n",
      "env: default, run\r\n",
      "info: _build_corpus, _build_dataset, _build_feature, _build_t5, _default_build, corpus, default, t5\r\n",
      "info/stats: corpus, default, feature\r\n",
      "info/table: corpus_info, listup, t5_info\r\n",
      "io: _build_corpus, _build_simple, _build_t5, _default\r\n",
      "io/data: default\r\n",
      "io/fetcher: _default, _dummy, _gcs, _gdrive_untar, _web, bok, dataframe, earnings_call, edgar, edgar_filings, edgar_items, enwiki, esg_report, fomc, glassdoor, hfds, kcbert, kcc, kowiki, namuwiki, nih_exporter, pathobook, pubmed, quandl, respec, sec_report\r\n",
      "io/fetcher/fomc: _base, default\r\n",
      "io/fetcher/fomc/articles: default, statement\r\n",
      "io/loader: class, csv, dataframe, gcs, hfds, parser, tf_textline, the_pile, tsv\r\n",
      "io/loader/decompressor: gzip\r\n",
      "io/loader/parser: email, html_to_json, json, json_to_list, jsonlines, plaintext, plaintext_split, pmc, pubmed, redif, reuters\r\n",
      "io/meta: default\r\n",
      "io/sample: default\r\n",
      "job: _job_, build_corpus\r\n",
      "job/example: build_corpus, tokenize_corpus\r\n",
      "meta/chairpersons: fomc\r\n",
      "meta/econ_series: fomc\r\n",
      "meta/recessions: usa\r\n",
      "meta/unconventionals: fomc\r\n",
      "mode: debug, default, run\r\n",
      "model: default\r\n",
      "model/automl: _default, classification\r\n",
      "model/automl/config: classification\r\n",
      "model/embedding: default\r\n",
      "model/eval: classification\r\n",
      "model/ngram: branching, cohesion, default, hiv4, lexicon, lm, mpko_lex, npmi, pmi\r\n",
      "model/ngram/candidates: default\r\n",
      "model/ngram/ngram: default\r\n",
      "model/ngram/ngramize: default\r\n",
      "model/ngram/postag: default\r\n",
      "model/ngram/score_function: _na, branching_entropy, cohesion_score, npmi, pmi\r\n",
      "model/ngram/scores: branching_entropy, cohesion_score, default, pmi\r\n",
      "model/plm/electra: base, large\r\n",
      "model/plm/electra/discriminator: base, large\r\n",
      "model/plm/electra/generator: base, large\r\n",
      "model/sentiment: _default, hiv4, lm, mpko_lex\r\n",
      "model/sklearn: cross_validate\r\n",
      "model/sklearn/AdaBoost: default\r\n",
      "model/sklearn/DecisionTree: default\r\n",
      "model/sklearn/GaussianNB: default\r\n",
      "model/sklearn/LogisticRegression: default\r\n",
      "model/sklearn/RandomForest: default\r\n",
      "model/sklearn/SVC: default\r\n",
      "model/tokenizer: bert_wordpiece, train_spm_t5\r\n",
      "model/tokenizer/spm: t5\r\n",
      "model/topic: default\r\n",
      "model/topic/task: topic_subtask\r\n",
      "model/topic/task/infer_topics: default\r\n",
      "model/topic/task/label_topics: default\r\n",
      "model/topic/task/load_corpus: default\r\n",
      "model/topic/task/load_model: default\r\n",
      "model/topic/task/save_labels: default\r\n",
      "model/topic/task/topic_wordclouds: default\r\n",
      "model/topic/task/train_model: dtm, lda\r\n",
      "model/topic/task/tune_params: default\r\n",
      "model/topic/task/visualize: default\r\n",
      "model/transformer: _default, _train, simple_classification, simple_ner, simple_t5, simple_t5_classification\r\n",
      "model/transformer/config: classification, t5\r\n",
      "model/transformer/pretrained: SciFive-base-Pubmed, bert-base-uncased, ekonelectra-base, electra-discriminator, finbert, t5-base\r\n",
      "path: _default, data, default, model, output, output-txt, train_dev_test, train_dev_test-meta, train_dev_test-sample\r\n",
      "path/data: default\r\n",
      "path/dev: default\r\n",
      "path/model: default\r\n",
      "path/output: default, text\r\n",
      "path/test: default\r\n",
      "path/train: default\r\n",
      "pipeline: _blank, _build_corpus, _build_dataset, _build_feature, _default, blank, default\r\n",
      "pipeline/aggregate_columns: default\r\n",
      "pipeline/chunk: default\r\n",
      "pipeline/combine_columns: default\r\n",
      "pipeline/concat_dataframes: default\r\n",
      "pipeline/drop: default\r\n",
      "pipeline/drop_duplicates: default\r\n",
      "pipeline/eval_columns: default\r\n",
      "pipeline/explode_splits: default\r\n",
      "pipeline/extract_tokens: default\r\n",
      "pipeline/fillna: default\r\n",
      "pipeline/filter_length: default, words\r\n",
      "pipeline/filter_query: default\r\n",
      "pipeline/load_dataframe: default\r\n",
      "pipeline/melt: default\r\n",
      "pipeline/merge_dataframe: default\r\n",
      "pipeline/normalize: default\r\n",
      "pipeline/pivot: default\r\n",
      "pipeline/plot: default\r\n",
      "pipeline/predict: default\r\n",
      "pipeline/remove_startswith: default\r\n",
      "pipeline/rename_columns: default\r\n",
      "pipeline/replace: default\r\n",
      "pipeline/reset_index: default\r\n",
      "pipeline/sampling: default\r\n",
      "pipeline/save_as_json: default\r\n",
      "pipeline/save_as_text: default\r\n",
      "pipeline/save_dataframe: default\r\n",
      "pipeline/save_metadata: default\r\n",
      "pipeline/save_samples: default\r\n",
      "pipeline/segment: default\r\n",
      "pipeline/split_column: default\r\n",
      "pipeline/split_dataframe: default\r\n",
      "pipeline/split_sampling: default\r\n",
      "pipeline/stdout_samples: default\r\n",
      "pipeline/subset: default\r\n",
      "pipeline/summary_stats: default\r\n",
      "pipeline/tokenize: default\r\n",
      "pipeline/top_values: default\r\n",
      "preprocessor/normalizer: default, formal_en, formal_en_parantheses, formal_ko, informal_ko\r\n",
      "preprocessor/normalizer/ftfy: default\r\n",
      "preprocessor/normalizer/spaces: default\r\n",
      "preprocessor/normalizer/special_characters: default\r\n",
      "preprocessor/segmenter: chunk, default, kss, kss_merge_article, nltk, pysbd, pysbd_filter_pl, pysbd_merge_article, pysbd_merge_article_filter_len, pysbd_merge_enko, pysbd_merge_segment, simple\r\n",
      "preprocessor/segmenter/chunk: default\r\n",
      "preprocessor/segmenter/filter_language: default\r\n",
      "preprocessor/segmenter/filter_sentence_length: default\r\n",
      "preprocessor/segmenter/merge: default\r\n",
      "preprocessor/segmenter/separators: default\r\n",
      "preprocessor/segmenter/split: default\r\n",
      "preprocessor/tokenizer: bwp, default, mecab, mecab_econ, nltk, pynori, simple\r\n",
      "preprocessor/tokenizer/extract: default, mecab\r\n",
      "preprocessor/tokenizer/stopwords: default\r\n",
      "preprocessor/tokenizer/tokenize: default\r\n",
      "preprocessor/tokenizer/tokenize_article: default\r\n",
      "project: default, sample, test\r\n",
      "resource/meta: recessions\r\n",
      "resource/postag: mecab, nltk\r\n",
      "util/lmdata: build_vocab\r\n",
      "util/lmdata/sharding: default\r\n",
      "util/model/convert: convert_electra\r\n",
      "util/vocab/extract_nouns: default\r\n",
      "visualize: default\r\n",
      "visualize/plot: _default, _grid, barplot, confusion_matrix, countplot, default, facetgrid, heatmap, histplot, jointplot, kdeplot, lineplot, manifold, pca, pcoords, radviz, rank1d, rank2d, scatter, stackplot\r\n",
      "visualize/plot/ax: default\r\n",
      "visualize/plot/ax/annotation: default\r\n",
      "visualize/plot/ax/axvspan: default\r\n",
      "visualize/plot/barplot: default\r\n",
      "visualize/plot/confusion_matrix: default\r\n",
      "visualize/plot/countplot: default\r\n",
      "visualize/plot/facetgrid: default\r\n",
      "visualize/plot/figure: default\r\n",
      "visualize/plot/gridspec: default\r\n",
      "visualize/plot/heatmap: default\r\n",
      "visualize/plot/histplot: default\r\n",
      "visualize/plot/jointplot: default\r\n",
      "visualize/plot/kdeplot: default\r\n",
      "visualize/plot/lineplot: default\r\n",
      "visualize/plot/manifold: default\r\n",
      "visualize/plot/pca: default\r\n",
      "visualize/plot/pcoords: default\r\n",
      "visualize/plot/radviz: default\r\n",
      "visualize/plot/rank1d: default\r\n",
      "visualize/plot/rank2d: default\r\n",
      "visualize/plot/savefig: default\r\n",
      "visualize/plot/scatter: default\r\n",
      "visualize/plot/series: default\r\n",
      "visualize/plot/stackplot: default\r\n",
      "visualize/plot/subplots: default\r\n",
      "visualize/plot/theme: seaborn\r\n",
      "visualize/treemap: default\r\n",
      "visualize/wordcloud: default\r\n",
      "workflow: _flow_\r\n",
      "workflow/example: example\r\n",
      "\r\n",
      "== Config ==\r\n",
      "\r\n",
      "This is the config generated for this run.\r\n",
      "You can override everything, for example:\r\n",
      "ekorpkit task=your_config_name\r\n",
      "--------------------------------------------------\r\n",
      "about:\r\n",
      "  app:\r\n",
      "    _target_: ekorpkit.cli.about\r\n",
      "    name: ekorpkit\r\n",
      "    author: Young Joon Lee\r\n",
      "    description: eKorpkit provides a flexible interface for NLP and ML research pipelines\r\n",
      "      such as extraction, transformation, tokenization, training, and visualization.\r\n",
      "    website: https://entelecheia.github.io/ekorpkit-book/\r\n",
      "    version: ${__version__:}\r\n",
      "_target_: ekorpkit.cli.cmd\r\n",
      "_config_: about.app\r\n",
      "corpus:\r\n",
      "  column_info:\r\n",
      "    keys:\r\n",
      "      id: id\r\n",
      "      text: text\r\n",
      "      timestamp: timestamp\r\n",
      "      split: split\r\n",
      "    columns:\r\n",
      "      id: ${oc.select:..keys.id,id}\r\n",
      "      text: ${oc.select:..keys.text,text}\r\n",
      "      merge_meta_on: ${oc.select:..id}\r\n",
      "      timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "    data:\r\n",
      "      id: int\r\n",
      "      text: str\r\n",
      "    meta: null\r\n",
      "    timestamp:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    datetime:\r\n",
      "      columns: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "    sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    _target_: ekorpkit.info.column.ColumnInfo\r\n",
      "  cache:\r\n",
      "    uri: null\r\n",
      "    extract_archive: true\r\n",
      "    force_extract: false\r\n",
      "    return_parent_dir: true\r\n",
      "    cache_dir: ${dir.cache}\r\n",
      "    verbose: ${oc.select:..verbose, false}\r\n",
      "    path: ${cached_path:${.uri},${.extract_archive},${.force_extract},${.return_parent_dir},${.cache_dir},${.verbose}}\r\n",
      "  _target_: ekorpkit.corpora.corpus.Corpus\r\n",
      "  name: ${oc.select:.builtin.name, null}\r\n",
      "  data_dir: ${oc.select:.builtin.data_dir, ${dir.corpus}}\r\n",
      "  metadata_dir: null\r\n",
      "  filetype: ${oc.select:.builtin.filetype, null}\r\n",
      "  autoload: true\r\n",
      "  automerge: false\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "  use_name_as_subdir: true\r\n",
      "dataset:\r\n",
      "  column_info:\r\n",
      "    keys:\r\n",
      "      id: id\r\n",
      "      text: text\r\n",
      "      timestamp: timestamp\r\n",
      "      split: split\r\n",
      "    columns:\r\n",
      "      id: ${oc.select:..keys.id,id}\r\n",
      "      text: ${oc.select:..keys.text,text}\r\n",
      "      merge_meta_on: ${oc.select:..id}\r\n",
      "      timestamp: ${oc.select:..timestamp.key,timestamp}\r\n",
      "    data:\r\n",
      "      id: int\r\n",
      "      text: str\r\n",
      "    meta: null\r\n",
      "    timestamp:\r\n",
      "      key: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    datetime:\r\n",
      "      columns: null\r\n",
      "      format: null\r\n",
      "      _parms_: null\r\n",
      "    segment_separator: ${oc.select:..segment_separator, '\\n\\n'}\r\n",
      "    sentence_separator: ${oc.select:..sentence_separator, '\\n'}\r\n",
      "    _target_: ekorpkit.info.column.ColumnInfo\r\n",
      "  path:\r\n",
      "    root: ${dir.data}/${.name}\r\n",
      "    name: ${oc.select:..name, ${name}}\r\n",
      "    cached_path: ${oc.select:.cache.path,null}\r\n",
      "    filetype: ${oc.select:..filetype,''}\r\n",
      "    verbose: ${oc.select:..verbose,false}\r\n",
      "    data_dir: ${oc.select:..data_dir, ${.root}}\r\n",
      "    data_file: ${oc.select:..data_file, null}\r\n",
      "    concat_data: ${oc.select:..concat_data, false}\r\n",
      "    columns: ${oc.select:..columns, null}\r\n",
      "    output_dir: ${oc.select:..output_dir, null}\r\n",
      "    output_file: ${oc.select:..output_file, null}\r\n",
      "    suffix: ${oc.select:..suffix, null}\r\n",
      "    data:\r\n",
      "      file: ${..data_file}\r\n",
      "      filename: ${.file}\r\n",
      "      base_dir: ${..data_dir}\r\n",
      "      filetype: ${..filetype}\r\n",
      "      concatenate: ${..concat_data}\r\n",
      "      dype: null\r\n",
      "      parse_dates: null\r\n",
      "      columns: ${..columns}\r\n",
      "    cache:\r\n",
      "      uri: null\r\n",
      "      extract_archive: true\r\n",
      "      force_extract: false\r\n",
      "      return_parent_dir: true\r\n",
      "      cache_dir: ${dir.cache}\r\n",
      "      verbose: ${oc.select:..verbose, false}\r\n",
      "      path: ${cached_path:${.uri},${.extract_archive},${.force_extract},${.return_parent_dir},${.cache_dir},${.verbose}}\r\n",
      "  _target_: ekorpkit.datasets.dataset.Dataset\r\n",
      "  name: ${oc.select:.builtin.name, null}\r\n",
      "  data_dir: ${dir.dataset}/dataset\r\n",
      "  filetype: ${oc.select:.builtin.filetype, .parquet}\r\n",
      "  autoload: true\r\n",
      "  use_name_as_subdir: true\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "dir:\r\n",
      "  archive: ${.data}/archive\r\n",
      "  cache: ${.workspace}/.cache\r\n",
      "  corpus: ${.dataset}/corpus\r\n",
      "  data: ${.workspace}/data\r\n",
      "  dataset: ${.data}/datasets\r\n",
      "  ekorpkit: ${__ekorpkit_path__:}\r\n",
      "  home: ${__home_path__:}\r\n",
      "  log: ${.project}/logs\r\n",
      "  model: ${.data}/models\r\n",
      "  output: ${.project}/outputs\r\n",
      "  project: ${.workspace}/projects/${project}\r\n",
      "  resource: ${.ekorpkit}/resources\r\n",
      "  runtime: ${get_original_cwd:}\r\n",
      "  tmp: ${.workspace}/.tmp\r\n",
      "  workspace: ${oc.env:EKORPKIT_WORKSPACE_ROOT,${.home}/.ekorpkit}\r\n",
      "env:\r\n",
      "  dotenv_path: ${dir.runtime}/.env\r\n",
      "  dotenv: ${dotenv_values:${.dotenv_path}}\r\n",
      "  os:\r\n",
      "    MODIN_ENGINE: ray\r\n",
      "    MODIN_CPUS: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "    CACHED_PATH_CACHE_ROOT: ${dir.cache}/cached_path\r\n",
      "  distributed_framework:\r\n",
      "    backend: joblib\r\n",
      "    initialize: true\r\n",
      "    num_workers: ${oc.select:num_workers,50}\r\n",
      "  ray:\r\n",
      "    num_cpus: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "  dask:\r\n",
      "    n_workers: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "  batcher:\r\n",
      "    procs: ${oc.select:..distributed_framework.num_workers,50}\r\n",
      "    minibatch_size: 1000\r\n",
      "    backend: ${..distributed_framework.backend}\r\n",
      "    task_num_cpus: 1\r\n",
      "    task_num_gpus: 0\r\n",
      "    verbose: 10\r\n",
      "app_name: ${about.app.name}\r\n",
      "name: ${.project}\r\n",
      "debug_mode: false\r\n",
      "print_config: false\r\n",
      "print_resolved_config: true\r\n",
      "num_workers: 1\r\n",
      "verbose: false\r\n",
      "ignore_warnings: true\r\n",
      "model:\r\n",
      "  name: model\r\n",
      "  data_dir: ${oc.select:..data_dir, ${dir.project}/data}\r\n",
      "  output_dir: ${oc.select:..output_dir, ${dir.output}/${.name}}\r\n",
      "  num_workers: ${oc.select:num_workers,1}\r\n",
      "  verbose: ${oc.select:..verbose, true}\r\n",
      "project: ${oc.env:EKORPKIT_PROJECT,${about.app.name}}\r\n",
      "\r\n",
      "--------------------------------------------------\r\n",
      "Powered by Hydra (https://hydra.cc)\r\n",
      "Use --hydra-help to view Hydra specific help\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81842f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Defaults List\r\n",
      "*************\r\n",
      "| Config path                  | Package             | _self_ | Parent              | \r\n",
      "--------------------------------------------------------------------------------------\r\n",
      "| hydra/output/default         | hydra               | False  | hydra/config        |\r\n",
      "| hydra/launcher/basic         | hydra.launcher      | False  | hydra/config        |\r\n",
      "| hydra/sweeper/basic          | hydra.sweeper       | False  | hydra/config        |\r\n",
      "| hydra/help/help              | hydra.help          | False  | hydra/config        |\r\n",
      "| hydra/hydra_help/default     | hydra.hydra_help    | False  | hydra/config        |\r\n",
      "| hydra/hydra_logging/colorlog | hydra.hydra_logging | False  | hydra/config        |\r\n",
      "| hydra/job_logging/colorlog   | hydra.job_logging   | False  | hydra/config        |\r\n",
      "| hydra/env/default            | hydra.env           | False  | hydra/config        |\r\n",
      "| hydra/config                 | hydra               | True   | <root>              |\r\n",
      "| config                       |                     | True   | <root>              |\r\n",
      "| about/app/default            | about.app           | False  | about/default       |\r\n",
      "| about/default                | about               | True   | config              |\r\n",
      "| cmd/default                  |                     | False  | config              |\r\n",
      "| column_info/_build           | corpus.column_info  | False  | column_info/default |\r\n",
      "| column_info/default          | corpus.column_info  | True   | corpus/default      |\r\n",
      "| cache/archive                | corpus.cache        | False  | corpus/default      |\r\n",
      "| corpus/default               | corpus              | True   | config              |\r\n",
      "| column_info/_build           | dataset.column_info | False  | column_info/default |\r\n",
      "| column_info/default          | dataset.column_info | True   | dataset/default     |\r\n",
      "| path/_default                | dataset.path        | False  | path/data           |\r\n",
      "| path/data/default            | dataset.path.data   | False  | path/data           |\r\n",
      "| cache/archive                | dataset.path.cache  | False  | path/data           |\r\n",
      "| path/data                    | dataset.path        | True   | dataset/default     |\r\n",
      "| dataset/default              | dataset             | True   | config              |\r\n",
      "| dir/default                  | dir                 | False  | config              |\r\n",
      "| env/run                      | env                 | False  | env/default         |\r\n",
      "| env/default                  | env                 | True   | config              |\r\n",
      "| mode/default                 |                     | False  | config              |\r\n",
      "| model/default                | model               | False  | config              |\r\n",
      "| project/default              |                     | False  | config              |\r\n",
      "--------------------------------------------------------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!ekorpkit --info defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d516a70",
   "metadata": {},
   "source": [
    "## Via Python\n",
    "\n",
    "### Compose an ekorpkit config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77fa19f1",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config type: <class 'omegaconf.dictconfig.DictConfig'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_config_': 'about.app',\n",
      " '_target_': 'ekorpkit.cli.cmd',\n",
      " 'about': {'app': {'_target_': 'ekorpkit.cli.about',\n",
      "                   'author': 'Young Joon Lee',\n",
      "                   'description': 'eKorpkit provides a flexible interface for '\n",
      "                                  'NLP and ML research pipelines such as '\n",
      "                                  'extraction, transformation, tokenization, '\n",
      "                                  'training, and visualization.',\n",
      "                   'name': 'ekorpkit',\n",
      "                   'version': '0.1.32+4.gfd15d82.dirty',\n",
      "                   'website': 'https://entelecheia.github.io/ekorpkit-book/'}},\n",
      " 'app_name': 'ekorpkit',\n",
      " 'corpus': {'_target_': 'ekorpkit.corpora.corpus.Corpus',\n",
      "            'autoload': True,\n",
      "            'automerge': False,\n",
      "            'cache': {'cache_dir': '/root/.ekorpkit/.cache',\n",
      "                      'extract_archive': True,\n",
      "                      'force_extract': False,\n",
      "                      'path': None,\n",
      "                      'return_parent_dir': True,\n",
      "                      'uri': None,\n",
      "                      'verbose': False},\n",
      "            'column_info': {'_target_': 'ekorpkit.info.column.ColumnInfo',\n",
      "                            'columns': {'id': 'id',\n",
      "                                        'merge_meta_on': None,\n",
      "                                        'text': 'text',\n",
      "                                        'timestamp': None},\n",
      "                            'data': {'id': 'int', 'text': 'str'},\n",
      "                            'datetime': {'_parms_': None,\n",
      "                                         'columns': None,\n",
      "                                         'format': None},\n",
      "                            'keys': {'id': 'id',\n",
      "                                     'split': 'split',\n",
      "                                     'text': 'text',\n",
      "                                     'timestamp': 'timestamp'},\n",
      "                            'meta': None,\n",
      "                            'segment_separator': '\\\\n\\\\n',\n",
      "                            'sentence_separator': '\\\\n',\n",
      "                            'timestamp': {'_parms_': None,\n",
      "                                          'format': None,\n",
      "                                          'key': None}},\n",
      "            'data_dir': '/root/.ekorpkit/data/datasets/corpus',\n",
      "            'filetype': None,\n",
      "            'metadata_dir': None,\n",
      "            'name': None,\n",
      "            'use_name_as_subdir': True,\n",
      "            'verbose': False},\n",
      " 'dataset': {'_target_': 'ekorpkit.datasets.dataset.Dataset',\n",
      "             'autoload': True,\n",
      "             'column_info': {'_target_': 'ekorpkit.info.column.ColumnInfo',\n",
      "                             'columns': {'id': 'id',\n",
      "                                         'merge_meta_on': None,\n",
      "                                         'text': 'text',\n",
      "                                         'timestamp': None},\n",
      "                             'data': {'id': 'int', 'text': 'str'},\n",
      "                             'datetime': {'_parms_': None,\n",
      "                                          'columns': None,\n",
      "                                          'format': None},\n",
      "                             'keys': {'id': 'id',\n",
      "                                      'split': 'split',\n",
      "                                      'text': 'text',\n",
      "                                      'timestamp': 'timestamp'},\n",
      "                             'meta': None,\n",
      "                             'segment_separator': '\\\\n\\\\n',\n",
      "                             'sentence_separator': '\\\\n',\n",
      "                             'timestamp': {'_parms_': None,\n",
      "                                           'format': None,\n",
      "                                           'key': None}},\n",
      "             'data_dir': '/root/.ekorpkit/data/datasets/dataset',\n",
      "             'filetype': '.parquet',\n",
      "             'name': None,\n",
      "             'path': {'cache': {'cache_dir': '/root/.ekorpkit/.cache',\n",
      "                                'extract_archive': True,\n",
      "                                'force_extract': False,\n",
      "                                'path': None,\n",
      "                                'return_parent_dir': True,\n",
      "                                'uri': None,\n",
      "                                'verbose': False},\n",
      "                      'cached_path': None,\n",
      "                      'columns': None,\n",
      "                      'concat_data': False,\n",
      "                      'data': {'base_dir': '/root/.ekorpkit/data/datasets/dataset',\n",
      "                               'columns': None,\n",
      "                               'concatenate': False,\n",
      "                               'dype': None,\n",
      "                               'file': None,\n",
      "                               'filename': None,\n",
      "                               'filetype': '.parquet',\n",
      "                               'parse_dates': None},\n",
      "                      'data_dir': '/root/.ekorpkit/data/datasets/dataset',\n",
      "                      'data_file': None,\n",
      "                      'filetype': '.parquet',\n",
      "                      'name': None,\n",
      "                      'output_dir': None,\n",
      "                      'output_file': None,\n",
      "                      'root': '/root/.ekorpkit/data/None',\n",
      "                      'suffix': None,\n",
      "                      'verbose': False},\n",
      "             'use_name_as_subdir': True,\n",
      "             'verbose': False},\n",
      " 'debug_mode': False,\n",
      " 'dir': {'archive': '/root/.ekorpkit/data/archive',\n",
      "         'cache': '/root/.ekorpkit/.cache',\n",
      "         'corpus': '/root/.ekorpkit/data/datasets/corpus',\n",
      "         'data': '/root/.ekorpkit/data',\n",
      "         'dataset': '/root/.ekorpkit/data/datasets',\n",
      "         'ekorpkit': '/workspace/projects/ekorpkit/ekorpkit',\n",
      "         'home': '/root',\n",
      "         'log': '/root/.ekorpkit/projects/ekorpkit/logs',\n",
      "         'model': '/root/.ekorpkit/data/models',\n",
      "         'output': '/root/.ekorpkit/projects/ekorpkit/outputs',\n",
      "         'project': '/root/.ekorpkit/projects/ekorpkit',\n",
      "         'resource': '/workspace/projects/ekorpkit/ekorpkit/resources',\n",
      "         'runtime': '/workspace/projects/ekorpkit-book/ekorpkit-book/docs/basics',\n",
      "         'tmp': '/root/.ekorpkit/.tmp',\n",
      "         'workspace': '/root/.ekorpkit'},\n",
      " 'env': {'batcher': {'backend': 'joblib',\n",
      "                     'minibatch_size': 1000,\n",
      "                     'procs': 1,\n",
      "                     'task_num_cpus': 1,\n",
      "                     'task_num_gpus': 0,\n",
      "                     'verbose': 10},\n",
      "         'dask': {'n_workers': 1},\n",
      "         'distributed_framework': {'backend': 'joblib',\n",
      "                                   'initialize': True,\n",
      "                                   'num_workers': 1},\n",
      "         'dotenv': {},\n",
      "         'dotenv_path': '/workspace/projects/ekorpkit-book/ekorpkit-book/docs/basics/.env',\n",
      "         'os': {'CACHED_PATH_CACHE_ROOT': '/root/.ekorpkit/.cache/cached_path',\n",
      "                'MODIN_CPUS': 1,\n",
      "                'MODIN_ENGINE': 'ray'},\n",
      "         'ray': {'num_cpus': 1}},\n",
      " 'ignore_warnings': True,\n",
      " 'model': {'data_dir': '/root/.ekorpkit/projects/ekorpkit/data',\n",
      "           'name': 'model',\n",
      "           'num_workers': 1,\n",
      "           'output_dir': '/root/.ekorpkit/projects/ekorpkit/outputs/model',\n",
      "           'verbose': False},\n",
      " 'name': 'ekorpkit',\n",
      " 'num_workers': 1,\n",
      " 'preprocessor': {'normalizer': {'_target_': 'ekorpkit.preprocessors.normalizer.Normalizer',\n",
      "                                 'ftfy': {'decode_inconsistent_utf8': True,\n",
      "                                          'fix_c1_controls': True,\n",
      "                                          'fix_character_width': True,\n",
      "                                          'fix_encoding': True,\n",
      "                                          'fix_latin_ligatures': True,\n",
      "                                          'fix_line_breaks': True,\n",
      "                                          'fix_surrogates': True,\n",
      "                                          'max_decode_length': 1000000,\n",
      "                                          'normalization': 'NFKC',\n",
      "                                          'remove_control_chars': True,\n",
      "                                          'remove_terminal_escapes': True,\n",
      "                                          'replace_lossy_sequences': True,\n",
      "                                          'restore_byte_a0': True,\n",
      "                                          'uncurl_quotes': True,\n",
      "                                          'unescape_html': True},\n",
      "                                 'hanja2hangle': False,\n",
      "                                 'num_repeats': 2,\n",
      "                                 'spaces': {'collapse_whitespaces': True,\n",
      "                                            'fix_whitespaces': True,\n",
      "                                            'num_spaces_for_tab': 4,\n",
      "                                            'replace_tabs': True,\n",
      "                                            'strip': True},\n",
      "                                 'special_characters': {'fix_ellipsis': True,\n",
      "                                                        'fix_emoticons': False,\n",
      "                                                        'fix_hyphens': True,\n",
      "                                                        'fix_slashes': True,\n",
      "                                                        'fix_tildes': True,\n",
      "                                                        'regular_parentheses_only': False,\n",
      "                                                        'single_quotes_only': False}},\n",
      "                  'segmenter': {'chunk': {'_func_': {'len_bytes': {'_partial_': True,\n",
      "                                                                   '_target_': 'ekorpkit.utils.func.len_bytes'},\n",
      "                                                     'len_words': {'_partial_': True,\n",
      "                                                                   '_target_': 'ekorpkit.utils.func.len_words'}},\n",
      "                                          'chunk_overlap': False,\n",
      "                                          'chunk_size': 300,\n",
      "                                          'len_func': 'len_bytes'},\n",
      "                                'filter_language': {'detection_level': 'segment',\n",
      "                                                    'filter': False,\n",
      "                                                    'languages_to_keep': ['en',\n",
      "                                                                          'ko'],\n",
      "                                                    'min_language_probability': 0.8},\n",
      "                                'filter_programming_language': False,\n",
      "                                'filter_sentence_length': {'filter': False,\n",
      "                                                           'min_length': 10,\n",
      "                                                           'min_num_words': 3},\n",
      "                                'merge': {'broken_lines_threshold': 0.4,\n",
      "                                          'empty_lines_threshold': 0.6,\n",
      "                                          'merge_level': 'segment',\n",
      "                                          'merge_lines': False},\n",
      "                                'print_args': False,\n",
      "                                'return_as_list': False,\n",
      "                                'separators': {'in_segment': '\\\\n\\\\n',\n",
      "                                               'in_sentence': '\\\\n',\n",
      "                                               'out_segment': '\\\\n\\\\n',\n",
      "                                               'out_sentence': '\\\\n'},\n",
      "                                'split': {'keep_segment': True,\n",
      "                                          'max_recover_length': 30000,\n",
      "                                          'max_recover_step': 0},\n",
      "                                'verbose': True},\n",
      "                  'tokenizer': {'_target_': 'ekorpkit.preprocessors.tokenizer.SimpleTokenizer',\n",
      "                                'extract': {'noun_postags': ['NNG',\n",
      "                                                             'NNP',\n",
      "                                                             'XSN',\n",
      "                                                             'SL',\n",
      "                                                             'XR',\n",
      "                                                             'NNB',\n",
      "                                                             'NR'],\n",
      "                                            'postag_delim': '/',\n",
      "                                            'postag_length': None,\n",
      "                                            'postags': None,\n",
      "                                            'stop_postags': ['SP',\n",
      "                                                             'SF',\n",
      "                                                             'SE',\n",
      "                                                             'SSO',\n",
      "                                                             'SSC',\n",
      "                                                             'SC',\n",
      "                                                             'SY',\n",
      "                                                             'SH'],\n",
      "                                            'strip_pos': True},\n",
      "                                'normalize': None,\n",
      "                                'return_as_list': False,\n",
      "                                'stopwords': {'_target_': 'ekorpkit.preprocessors.stopwords.Stopwords',\n",
      "                                              'lowercase': True,\n",
      "                                              'name': 'stopwords',\n",
      "                                              'nltk_stopwords': None,\n",
      "                                              'stopwords': None,\n",
      "                                              'stopwords_path': None,\n",
      "                                              'verbose': False},\n",
      "                                'stopwords_path': None,\n",
      "                                'tagset': None,\n",
      "                                'tokenize': {'flatten': True,\n",
      "                                             'include_whitespace_token': True,\n",
      "                                             'lowercase': False,\n",
      "                                             'postag_delim': '/',\n",
      "                                             'postag_length': None,\n",
      "                                             'punct_postags': ['SF',\n",
      "                                                               'SP',\n",
      "                                                               'SSO',\n",
      "                                                               'SSC',\n",
      "                                                               'SY'],\n",
      "                                             'strip_pos': False,\n",
      "                                             'tokenize_each_word': False,\n",
      "                                             'userdic_path': None,\n",
      "                                             'wordpieces_prefix': '##'},\n",
      "                                'tokenize_article': {'sentence_separator': '\\\\n'},\n",
      "                                'verbose': False}},\n",
      " 'print_config': False,\n",
      " 'print_resolved_config': True,\n",
      " 'project': 'ekorpkit',\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from ekorpkit import eKonf\n",
    "cfg = eKonf.compose()\n",
    "print('Config type:', type(cfg))\n",
    "eKonf.pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0b6ef",
   "metadata": {},
   "source": [
    "### Instantiating objects with an ekorpkit config\n",
    "\n",
    "#### compose a config for the nltk class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e418b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'ekorpkit.preprocessors.tokenizer.NLTKTokenizer',\n",
      " 'extract': {'noun_postags': ['NN', 'NNP', 'NNS', 'NNPS'],\n",
      "             'postag_delim': '/',\n",
      "             'postag_length': None,\n",
      "             'postags': None,\n",
      "             'stop_postags': ['.'],\n",
      "             'strip_pos': True},\n",
      " 'nltk': {'lemmatize': False,\n",
      "          'lemmatizer': {'_target_': 'nltk.stem.WordNetLemmatizer'},\n",
      "          'stem': True,\n",
      "          'stemmer': {'_target_': 'nltk.stem.PorterStemmer'}},\n",
      " 'normalize': None,\n",
      " 'return_as_list': False,\n",
      " 'stopwords': {'_target_': 'ekorpkit.preprocessors.stopwords.Stopwords',\n",
      "               'lowercase': True,\n",
      "               'name': 'stopwords',\n",
      "               'nltk_stopwords': None,\n",
      "               'stopwords': None,\n",
      "               'stopwords_path': None,\n",
      "               'verbose': False},\n",
      " 'stopwords_path': None,\n",
      " 'tagset': None,\n",
      " 'tokenize': {'flatten': True,\n",
      "              'include_whitespace_token': True,\n",
      "              'lowercase': False,\n",
      "              'postag_delim': '/',\n",
      "              'postag_length': None,\n",
      "              'punct_postags': ['SF', 'SP', 'SSO', 'SSC', 'SY'],\n",
      "              'strip_pos': False,\n",
      "              'tokenize_each_word': False,\n",
      "              'userdic_path': None,\n",
      "              'wordpieces_prefix': '##'},\n",
      " 'tokenize_article': {'sentence_separator': '\\\\n'},\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "from ekorpkit import eKonf\n",
    "config_group='preprocessor/tokenizer=nltk'\n",
    "cfg = eKonf.compose(config_group=config_group)\n",
    "eKonf.pprint(cfg)\n",
    "nltk = eKonf.instantiate(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8e24687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i/PRP',\n",
       " 'shall/MD',\n",
       " 'reemphas/VB',\n",
       " 'some/DT',\n",
       " 'of/IN',\n",
       " 'those/DT',\n",
       " 'thought/NNS',\n",
       " 'today/NN',\n",
       " 'in/IN',\n",
       " 'the/DT',\n",
       " 'context/NN',\n",
       " 'of/IN',\n",
       " 'legisl/JJ',\n",
       " 'propos/NNS',\n",
       " 'that/WDT',\n",
       " 'are/VBP',\n",
       " 'now/RB',\n",
       " 'befor/IN',\n",
       " 'the/DT',\n",
       " 'current/JJ',\n",
       " 'congress/NNP',\n",
       " './.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I shall reemphasize some of those thoughts today in the context of legislative proposals that are now before the current Congress.\"\n",
    "nltk.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc652e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thought', 'today', 'context', 'propos', 'congress']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.nouns(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fa8606",
   "metadata": {},
   "source": [
    "#### compose a config for the mecab class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db11280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_target_': 'ekorpkit.preprocessors.tokenizer.MecabTokenizer',\n",
      " 'extract': {'noun_postags': ['NNG', 'NNP', 'XSN', 'SL', 'XR', 'NNB', 'NR'],\n",
      "             'postag_delim': '/',\n",
      "             'postag_length': None,\n",
      "             'postags': None,\n",
      "             'stop_postags': ['SP', 'SF', 'SE', 'SSO', 'SSC', 'SC', 'SY', 'SH'],\n",
      "             'strip_pos': True},\n",
      " 'mecab': {'backend': 'mecab-python3', 'userdic_path': None, 'verbose': False},\n",
      " 'normalize': None,\n",
      " 'return_as_list': False,\n",
      " 'stopwords': {'_target_': 'ekorpkit.preprocessors.stopwords.Stopwords',\n",
      "               'lowercase': True,\n",
      "               'name': 'stopwords',\n",
      "               'nltk_stopwords': None,\n",
      "               'stopwords': None,\n",
      "               'stopwords_path': None,\n",
      "               'verbose': False},\n",
      " 'stopwords_path': None,\n",
      " 'tagset': None,\n",
      " 'tokenize': {'flatten': True,\n",
      "              'include_whitespace_token': True,\n",
      "              'lowercase': False,\n",
      "              'postag_delim': '/',\n",
      "              'postag_length': None,\n",
      "              'punct_postags': ['SF', 'SP', 'SSO', 'SSC', 'SY'],\n",
      "              'strip_pos': False,\n",
      "              'tokenize_each_word': False,\n",
      "              'userdic_path': None,\n",
      "              'wordpieces_prefix': '##'},\n",
      " 'tokenize_article': {'sentence_separator': '\\\\n'},\n",
      " 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "config_group='preprocessor/tokenizer=mecab'\n",
    "cfg = eKonf.compose(config_group=config_group)\n",
    "eKonf.pprint(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05c995b",
   "metadata": {},
   "source": [
    "#### intantiate a mecab config and tokenize a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13099647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMF/SL',\n",
       " '가/JKS',\n",
       " '/SP',\n",
       " '推定/NNG',\n",
       " '한/XSA+ETM',\n",
       " '/SP',\n",
       " '우리나라/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " 'GDP/SL',\n",
       " '갭/NNG',\n",
       " '률/XSN',\n",
       " '은/JX',\n",
       " '/SP',\n",
       " '今年/NNG',\n",
       " '에/JKB',\n",
       " '도/JX',\n",
       " '/SP',\n",
       " '소폭/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " '마이너스/NNG',\n",
       " '(/SSO',\n",
       " '−)/SY',\n",
       " '를/JKO',\n",
       " '/SP',\n",
       " '持續/NNG',\n",
       " '하/XSV',\n",
       " '고/EC',\n",
       " '/SP',\n",
       " '있/VX',\n",
       " '다/EF',\n",
       " './SF']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mecab = eKonf.instantiate(cfg)\n",
    "text = 'IMF가 推定한 우리나라의 GDP갭률은 今年에도 소폭의 마이너스(−)를 持續하고 있다.'\n",
    "mecab.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c425f4",
   "metadata": {},
   "source": [
    "#### compose and instantiate a `formal_ko` config for the normalizer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cadf1fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IMF가 추정한 우리나라의 GDP갭률은 금년에도 소폭의 마이너스(-)를 지속하고 있다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_group='preprocessor/normalizer=formal_ko'\n",
    "cfg_norm = eKonf.compose(config_group=config_group)\n",
    "norm = eKonf.instantiate(cfg_norm)\n",
    "norm(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19fea55",
   "metadata": {},
   "source": [
    "#### instantiate a mecab config with the above normalizer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59b5991c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMF/SL',\n",
       " '가/JKS',\n",
       " '/SP',\n",
       " '추정/NNG',\n",
       " '한/XSA+ETM',\n",
       " '/SP',\n",
       " '우리나라/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " 'GDP/SL',\n",
       " '갭/NNG',\n",
       " '률/XSN',\n",
       " '은/JX',\n",
       " '/SP',\n",
       " '금년/NNG',\n",
       " '에/JKB',\n",
       " '도/JX',\n",
       " '/SP',\n",
       " '소폭/NNG',\n",
       " '의/JKG',\n",
       " '/SP',\n",
       " '마이너스/NNG',\n",
       " '(/SSO',\n",
       " '-)/SY',\n",
       " '를/JKO',\n",
       " '/SP',\n",
       " '지속/NNG',\n",
       " '하/XSV',\n",
       " '고/EC',\n",
       " '/SP',\n",
       " '있/VX',\n",
       " '다/EF',\n",
       " './SF']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_group='preprocessor/tokenizer=mecab'\n",
    "cfg = eKonf.compose(config_group=config_group)\n",
    "cfg.normalize = cfg_norm\n",
    "mecab = eKonf.instantiate(cfg)\n",
    "mecab.tokenize(text)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "source_map": [
   11,
   17,
   19,
   23,
   36,
   42,
   47,
   49,
   55,
   61,
   67,
   75,
   80,
   82,
   86,
   90,
   94,
   98,
   102,
   107,
   111
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}