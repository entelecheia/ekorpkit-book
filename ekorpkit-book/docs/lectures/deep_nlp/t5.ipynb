{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {},
   "source": [
    "# T5: Text-To-Text Transfer Transformer\n",
    "\n",
    "![](../figs/deep_nlp/t5/t5.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef336780",
   "metadata": {},
   "source": [
    "“Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer” {cite}`raffel2020exploring`\n",
    "\n",
    "- A unified framework that converts all text-based language problems into a text-to-text format by framing them as conditional text generation tasks.\n",
    "- Combining the pre-training objectives of BERT and GPT-2, T5 is trained on a very large number of tasks and is able to perform well on a wide range of tasks with minimal task-specific architecture modifications.\n",
    "- C4 (Corpus of Cleaned Web Crawled Text) is used as the training corpus, which is a large-scale dataset of 3.3 billion web pages.\n",
    "- Achieves state-of-the-art results on 11 out of 15 tasks in GLUE, SuperGLUE, and SQuAD v1.1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ac5b6",
   "metadata": {},
   "source": [
    "## T5: Text-to-Text Framework\n",
    "\n",
    "![](../figs/deep_nlp/t5/t5-training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c0924d",
   "metadata": {},
   "source": [
    "### Unified Input & Output Format\n",
    "\n",
    "- T5 means \"`T`ext-`T`o-`T`ext `T`ransfer `T`ransformer\".\n",
    "- Every task considered by T5 is framed as a conditional text generation task with a single input and output sequence.\n",
    "- Translation: `translate English to German: How old are you?` $\\rightarrow$ `Wie alt bist du?`\n",
    "- Text classification: `classify sentiment: This movie is so bad.` $\\rightarrow$ `negative`\n",
    "- Text summarization: `summarize: The movie was not good. The animation and the graphics were good. This is a good movie.` $\\rightarrow$ `The movie was not good.`\n",
    "- Entailment: `entailment: I like to eat broccoli and bananas. I eat a banana every day.` $\\rightarrow$ `neutral`\n",
    "- MNLI (entailment): `mnli: Premise: A person on a horse jumps over a broken down airplane. Hypothesis: The person is training his horse for a competition.` $\\rightarrow$ `entailment`\n",
    "- MNLI (neutral): `mnli: Premise: A person on a horse jumps over a broken down airplane. Hypothesis: The person is at the zoo, riding a horse.` $\\rightarrow$ `neutral`\n",
    "- Regression: `sts-b: The cat was playing in the garden. The cat was playing in the yard.` $\\rightarrow$ `5.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27451162",
   "metadata": {},
   "source": [
    "### Encoder-Decoder Transformer Model\n",
    "\n",
    "- T5 uses the same encoder-decoder Transformer architecture as BERT.\n",
    "- However, a simplified layer normalization is used the activations are only rescaled and no additive bias is applied.\n",
    "- After layer normalization, a residual skip connection, originated from ResNet, adds each subcomponent's input to its output.\n",
    "- Also, istead of using a fixed positional encoding, T5 uses a relative positional encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [T5: Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html)\n",
    "- [A Full Guide to Finetuning T5 for Text2Text and Building a Demo with Streamlit](https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887)\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd8c41",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
