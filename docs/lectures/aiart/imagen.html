
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Imagen &#8212; eKorpkit Tutorials</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/ekorpkit.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Machine Learning Systems Design" href="../mlops/index.html" />
    <link rel="prev" title="DALLÂ·E 2" href="dalle2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FN4GFT8HP8"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-FN4GFT8HP8');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/ekorpkit.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">eKorpkit Tutorials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    eKonomic Research Python Toolkit
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basics/index.html">
   Getting started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/install.html">
     Installation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/usage.html">
     Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basics/features/index.html">
   Key features
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/easy_config.html">
     Easy Configuration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/no_boiler.html">
     No Boilerplate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/workflows.html">
     Workflows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/share.html">
     Sharable and Reproducible
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/plug.html">
     Pluggable Architece
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/config/index.html">
   Configuring ekorpkit
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/config/eKonf.html">
     Using eKonf class
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/datasets/index.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/corpora/corpus.html">
     Build and Load Corpora
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/datasets/dataset.html">
     Build and Load Datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/corpora/pipeline.html">
     Corpus task pipelines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/models/index.html">
   Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/models/automl/index.html">
     Auto ML
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/embeddings/index.html">
     Word Embeddings
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/embeddings/word2vec_basics.html">
       Word2Vec Basics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/embeddings/eval_vectors.html">
       Evaluate pretrained embeddings
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/ngram/index.html">
     N-Grams
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/ngram/ngram.html">
       N-Grams
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/ngram/ngram_for_lexicons.html">
       N-Gram model for ngram lexicon features
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/ngram/ngram_for_words.html">
       N-Gram model for unigram lexicon features
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/sentiment/index.html">
     Sentiment Analyers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/sentiment/lbsa_en.html">
       Lexicon-based Sentiment Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/sentiment/financial_phrasebank_lm.html">
       Evaluate LM with financial phrasebank
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/sentiment/sentiment.html">
       LM Dictionary vs. finbert vs. T5
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/models/transformers/index.html">
     Transformers
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/art/index.html">
     AI Art (Text-to-Image)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/art/disco.html">
       Disco Diffusion
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/art/dalle-mini.html">
       DALLÂ·E Mini
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/pipelines/index.html">
   Pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/pipelines/pipeline.html">
     Instantiating pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/preprocessors/index.html">
   Preprocessors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/preprocessors/normalizer/index.html">
     Normalizers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/preprocessors/normalizer/normalizer.html">
       Normalizers
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/preprocessors/segmenter/index.html">
     Segmenters
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/preprocessors/segmenter/segmenter.html">
       Segmenters
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/preprocessors/tokenizer/index.html">
     Tokenizers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/preprocessors/tokenizer/mecab.html">
       Mecab Tokenizer
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/visualizers/index.html">
   Visualizers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/visualizers/plot.html">
     Plots
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tutorials/workflow/index.html">
   Workflows
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datasets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../corpus/ekorpkot_corpus.html">
   The eKorpkit Corpus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use Cases
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/fomc/index.html">
   FOMC
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/02_FOMC_numerical_data.html">
     Preparing Numerical Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/03_FOMC_corpus.html">
     Preparing Textual Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/04_FOMC_EDA_numericals.html">
     EDA on Numerical Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/05_FOMC_features.html">
     Visualizing Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/06_FOMC_AutoML.html">
     Checking Baseline with AutoML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/07_FOMC_sentiments.html">
     Predicting Sentiments of FOMC Corpus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/08_FOMC_EDA_sentiments.html">
     EDA on Sentiment Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/09_FOMC_AutoML_with_tones.html">
     Predicting the next decisions with tones
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../usecases/bok/index.html">
   Bank of Korea
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/edgar/index.html">
   EDGAR
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/edgar/predict_edgar.html">
     Prediciting Sentiments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/esg/index.html">
   ESG
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/snorkel-polarity.html">
     Preparing polarity classification datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/rubrix.html">
     Improving classification datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/classifiers.html">
     Training Classifiers for ESG Ratings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/econ_news_corpus.html">
     Building
     <code class="docutils literal notranslate">
      <span class="pre">
       econ_news_kr
      </span>
     </code>
     corpus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/predict_news.html">
     Predicting ESG Categories and Polarities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/rubrix_classifiers.html">
     Preparing classifiers for active learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/predict_for_learning.html">
     Preparing active learning data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/esg-en/index.html">
   ESG (English)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg-en/esg_corpus.html">
     Building
     <code class="docutils literal notranslate">
      <span class="pre">
       JOCo
      </span>
     </code>
     corpus
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/cointax/index.html">
   Taxation on Cryptocurrency
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/cointax/coin_dataset.html">
     Improving classification datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Research
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../research/esg_topics/analyst.html">
   ESG Topic Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../research/esg_topics/rethink_esg.html">
   Rethinking ESG
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../intro_nlp/index.html">
   Introduction to NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/ekorpkit.html">
     Getting started with ekorpkit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/research.html">
     Research Applications
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/topic.html">
     Topic Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/topic_models.html">
     Topic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/topic_coherence.html">
     Topic Coherence Measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/sentiments.html">
     Sentiment Analysis
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/tokenization.html">
     Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/word_segmentation.html">
     Word Segmentation and Association
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/vectorization.html">
     Vector Semantics and Representation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_nlp/lm_evaluation.html">
     Language Model Evaluation
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../deep_nlp/index.html">
   Deep Learning for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/ekorpkit.html">
     Getting started with ekorpkit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/zeroshot.html">
     Zero Shot, Prompt, and Search Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/bloom.html">
     What is BLOOM?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/bloom_apps.html">
     Bloom Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/transformers.html">
     Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/bert.html">
     BERT: Bidirectional Encoder Representations from Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/t5.html">
     T5: Text-To-Text Transfer Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/tokenization.html">
     Tokenization
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/sentencepiece.html">
     SentencePiece Tokenizer
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   AI Art (Text-to-Image)
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="project-themes.html">
     Project Themes - A Brave New World
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dalle1.html">
     DALLÂ·E 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="dalle2.html">
     DALLÂ·E 2
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Imagen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/index.html">
   Machine Learning Systems Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ds/index.html">
   Data Science for Economics and Finance
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/index.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/cite.html">
   Citation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/entelecheia/ekorpkit-book/main?urlpath=tree/ekorpkit-book/docs/lectures/aiart/imagen.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/entelecheia/ekorpkit-book/blob/main/ekorpkit-book/docs/lectures/aiart/imagen.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/entelecheia/ekorpkit-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/entelecheia/ekorpkit-book/issues/new?title=Issue%20on%20page%20%2Fdocs/lectures/aiart/imagen.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/docs/lectures/aiart/imagen.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-to-image-model">
   Text-to-image model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-imagen-works-a-bird-s-eye-view">
   How Imagen Works: A Birdâs-Eye View
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-encoder">
     Text Encoder
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-generator">
     Image Generator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caption-conditioning">
     Caption Conditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-super-resolution">
     Image Super-Resolution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-imagen-works-a-deep-dive">
   How Imagen Works: A Deep Dive
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-encoder-t5">
     Text Encoder: T5
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-generator-network-architecture">
     Image Generator:  Network Architecture
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#timestep-conditioning">
     Timestep Conditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Caption Conditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classifier-free-guidance">
     Classifier-Free Guidance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-guidance-weight-samplers">
     Large Guidance Weight Samplers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#static-thresholding">
       Static Thresholding
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dynamic-thresholding">
       Dynamic Thresholding
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparison">
       Comparison
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#super-resolution-models">
     Super-Resolution Models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#robust-cascaded-diffusion-models">
       Robust Cascaded Diffusion Models
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#results-and-analysis">
     Results and Analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-is-imagen-better-than-dall-e-2">
     Why is Imagen Better than DALL-E 2?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Imagen</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#text-to-image-model">
   Text-to-image model
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-imagen-works-a-bird-s-eye-view">
   How Imagen Works: A Birdâs-Eye View
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-encoder">
     Text Encoder
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-generator">
     Image Generator
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caption-conditioning">
     Caption Conditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-super-resolution">
     Image Super-Resolution
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-imagen-works-a-deep-dive">
   How Imagen Works: A Deep Dive
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#text-encoder-t5">
     Text Encoder: T5
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#image-generator-network-architecture">
     Image Generator:  Network Architecture
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#timestep-conditioning">
     Timestep Conditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Caption Conditioning
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classifier-free-guidance">
     Classifier-Free Guidance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#large-guidance-weight-samplers">
     Large Guidance Weight Samplers
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#static-thresholding">
       Static Thresholding
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dynamic-thresholding">
       Dynamic Thresholding
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#comparison">
       Comparison
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#super-resolution-models">
     Super-Resolution Models
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#robust-cascaded-diffusion-models">
       Robust Cascaded Diffusion Models
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#results-and-analysis">
     Results and Analysis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#why-is-imagen-better-than-dall-e-2">
     Why is Imagen Better than DALL-E 2?
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion">
   Conclusion
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="imagen">
<h1>Imagen<a class="headerlink" href="#imagen" title="Permalink to this headline">#</a></h1>
<p><img alt="Imagen" src="../../../_images/the-toronto-skyline-with-google-brain-logo.jpg" /></p>
<section id="text-to-image-model">
<h2>Text-to-image model<a class="headerlink" href="#text-to-image-model" title="Permalink to this headline">#</a></h2>
<p><img alt="Text-to-image model" src="../../../_images/text-to-image-model.png" /></p>
<ul class="simple">
<li><p>High-performing text-to-image models willÂ necessarily be able to combine unrelated concepts and objects in semantically plausible ways.</p></li>
<li><p>Challenges</p>
<ul>
<li><p>capturing spatial relationships</p></li>
<li><p>understanding cardinality</p></li>
<li><p>properly interpreting how words in the description relate to one another</p></li>
<li><p>âA brain riding a rocketship heading towards the moonâ</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="../../../_images/brain-rocketship-moon.png" /></p>
</section>
<section id="how-imagen-works-a-bird-s-eye-view">
<h2>How Imagen Works: A Birdâs-Eye View<a class="headerlink" href="#how-imagen-works-a-bird-s-eye-view" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>The caption is input into aÂ <code class="docutils literal notranslate"><span class="pre">text</span> <span class="pre">encoder</span></code>. This encoder converts the textual caption to a numerical representation thatÂ <code class="docutils literal notranslate"><span class="pre">encapsulates</span> <span class="pre">the</span> <span class="pre">semantic</span> <span class="pre">information</span> <span class="pre">within</span> <span class="pre">the</span> <span class="pre">text</span></code>.</p></li>
<li><p>An image-generation model creates an image by starting with noise and slowly transforming it into an output image. To guide this process, the image-generation model receives the text encoding as an input, which has the effect ofÂ <code class="docutils literal notranslate"><span class="pre">telling</span> <span class="pre">the</span> <span class="pre">model</span> <span class="pre">what</span> <span class="pre">is</span> <span class="pre">in</span> <span class="pre">the</span> <span class="pre">caption</span></code>Â so it can create a corresponding image. The output is a small image that reflects visually the caption we input to the text encoder!</p></li>
<li><p>The small image is then passed into aÂ <code class="docutils literal notranslate"><span class="pre">super-resolution</span> <span class="pre">model</span></code>, which grows the image to a higher resolution.Â This model also takes the text encoding as input, which helps the model decide how to behave as it âfills in the gapsâ of missing information that necessarily arise from quadrupling the size of our image. The result is aÂ <code class="docutils literal notranslate"><span class="pre">medium</span> <span class="pre">sized</span> <span class="pre">image</span></code>Â of what we want.</p></li>
<li><p>Finally, this medium sized image is then passed into yetÂ <code class="docutils literal notranslate"><span class="pre">another</span> <span class="pre">super-resolution</span> <span class="pre">model</span></code>, which operates near-identically to the previous one, except this time it takes ourÂ mediumÂ sized image and grows it to aÂ <code class="docutils literal notranslate"><span class="pre">high-resolutionÂ image</span></code>. The result is 1024 x 1024 pixel image that visually reflects the semantics within our caption.</p></li>
</ol>
<section id="text-encoder">
<h3>Text Encoder<a class="headerlink" href="#text-encoder" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The text encoder is critical to Imagenâs performance. It conditionsÂ allÂ of Imagenâs other components and is responsible for encoding the textual caption in a useful way.</p></li>
<li><p>The text encoder in Imagen is a Transformer encoder.</p></li>
<li><p>Encoder ensures that theÂ text encoding understands how the words within the caption relate to one anotherÂ (by a method called âself-attentionâ).Â 
The English language encodes information via its syntactic structure that affects the semantic meaning of a given sentence.
The text-encoder isÂ frozenÂ during training, meaning that it does not learn or change the way it creates the encodings. It isÂ onlyÂ used to generate encodings that are fed to the rest of the model, whichÂ isÂ trained.</p></li>
</ul>
<p>A lack of consideration for how words relate to one another could yield an extremely poor result:</p>
<p><img alt="" src="../../../_images/imagen-bad.png" /></p>
</section>
<section id="image-generator">
<h3>Image Generator<a class="headerlink" href="#image-generator" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Imagen uses aÂ Diffusion Model to generate an image.</p></li>
<li><p>Diffusion Models are a method of creating data that is similar to a set of training data. They train by destroying the training data through the addition of noise, and then learning to recover the data by reversing this noising process.</p></li>
</ul>
<p><img alt="" src="../../../_images/diffusion-model1.png" />
<img alt="" src="../../../_images/diffusion-model2.png" /></p>
</section>
<section id="caption-conditioning">
<h3>Caption Conditioning<a class="headerlink" href="#caption-conditioning" title="Permalink to this headline">#</a></h3>
<p><img alt="" src="../../../_images/caption-conditioning.gif" /></p>
</section>
<section id="image-super-resolution">
<h3>Image Super-Resolution<a class="headerlink" href="#image-super-resolution" title="Permalink to this headline">#</a></h3>
<p><img alt="" src="../../../_images/super-res.gif" /></p>
</section>
</section>
<section id="how-imagen-works-a-deep-dive">
<h2>How Imagen Works: A Deep Dive<a class="headerlink" href="#how-imagen-works-a-deep-dive" title="Permalink to this headline">#</a></h2>
<section id="text-encoder-t5">
<h3>Text Encoder: T5<a class="headerlink" href="#text-encoder-t5" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>The text encoder in Imagen is the encoder network of T5 (Text-to-TextÂ TransferÂ Transformer), a language model released by Google in 2019.</p></li>
<li><p>T5 is intended to be finetuned for any NLP task that can be cast in this text-to-text manner.</p></li>
<li><p>Some other text-to-image models like DALL-E 2 use text-encoders which are trained on image-caption pairs and an associated objective that is explicitly designed for the purpose of linking textual and visual representations of the same semantic concept.</p></li>
<li><p>The central intuition in using T5 is thatÂ extremely large language models, by virtue of their sheer size alone,Â may still learn useful representationsÂ despite the fact that they are not explicitly trained with any text/image task in mind.</p></li>
<li><p>âwhether or not a massive language model trained on a massive dataset independent of the task of image generation is a worthwhile trade-off for a non-specialized text encoder.â</p></li>
</ul>
<p><img alt="" src="../../../_images/t5.gif" /></p>
<p>Image Generator:  Network Architecture</p>
<ul class="simple">
<li><p>A Diffusion Model is sort of a âmetamodelâ framework that tells usÂ howÂ to useÂ a neural modelÂ to denoise images.</p></li>
<li><p>U-Net architecture byÂ Nichol and Dhariwa.</p></li>
</ul>
<p><img alt="" src="../../../_images/unet.png" /></p>
</section>
<section id="image-generator-network-architecture">
<h3>Image Generator:  Network Architecture<a class="headerlink" href="#image-generator-network-architecture" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Each residual block is composed of two sub-blocks, and each of these sub-blocks is composed of a Batch Normalization, ReLU, and 3x3 Convolution in sequence.</p></li>
</ul>
<p><img alt="" src="../../../_images/residual-block.png" /></p>
</section>
<section id="timestep-conditioning">
<h3>Timestep Conditioning<a class="headerlink" href="#timestep-conditioning" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>In Imagen, the same denoising U-Net is used at every timestep.</p></li>
<li><p>We must therefore devise a way to inject timestep information into the model (i.e.Â conditionÂ on the timestep).</p></li>
<li><p>The Imagen authors utilize a technique introduced by the original Transformer paper calledÂ positional encoding.</p></li>
</ul>
<p><img alt="" src="../../../_images/pos_enc.gif" /></p>
<ul class="simple">
<li><p>A uniqueÂ timestep encoding vectorÂ is generated for each timestep (corresponding to âword positionâ in the original positional embedding implementation).</p></li>
<li><p>At different resolutions in the U-Net, this vector is projected to havingÂ cÂ components, whereÂ cÂ is the number of channels in the U-Net at that resolution.</p></li>
<li><p>After projection, each component of the vector is added to the corresponding channel (across its height and width) in the image.</p></li>
</ul>
<p><img alt="" src="../../../_images/time_enc.gif" /></p>
</section>
<section id="id1">
<h3>Caption Conditioning<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>First, the output vectors from the T5 text encoder are pooled and added into the timestep embedding from above.</p></li>
<li><p>Next, the model is conditioned on the entire encodingÂ sequenceÂ by adding cross attention over the text embeddings at several resolutions. The cross attention is implemented by concatenating the text embedding sequence to the key-value pairs of each self-attention layer.</p></li>
</ul>
<p><img alt="" src="../../../_images/caption-conditioning.png" /></p>
</section>
<section id="classifier-free-guidance">
<h3>Classifier-Free Guidance<a class="headerlink" href="#classifier-free-guidance" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Classifier-Free Guidance is a method of increasing the image fidelity of a Diffusion Model at the cost of image diversity.</p></li>
<li><p>Classifier Guidance is a method for trading off the fidelity and diversity of images generated by a Diffusion Model.</p></li>
<li><p>The theoretical cost of Classifier Guidance method is diversity, because images will be encouraged to have features that are frequently observed for the given class.</p></li>
<li><p>The practical costs of the method are</p>
<ol class="simple">
<li><p>needing to train a classifier in addition to the diffusion model</p></li>
<li><p>poor image quality when the conditional term is scaled too high (too high of a âguidance weightâ).</p></li>
</ol>
</li>
<li><p><a class="reference external" href="https://benanne.github.io/2022/05/26/guidance.html">https://benanne.github.io/2022/05/26/guidance.html</a></p></li>
</ul>
<ul class="simple">
<li><p>Classifier-Free Guidance works by training a Diffusion Model to be both conditional and unconditionalÂ at the same time.</p></li>
<li><p>the Diffusion Model is cast as a conditional model and is trained with the conditioning information randomly dropped out a small fraction of the time (by replacing the conditional information with a NULL value).</p></li>
<li><p>To use the model in an unconditional way, the NULL value is simply provided as the âconditional informationâ to the model.</p></li>
<li><p>Classifier-Free guidance works loosely byÂ interpolating between the unconditional and conditional gradientsÂ during inference.</p></li>
<li><p>By magnifying the effect of the conditional gradient (i.e. making the âguidance weightâ greater than 1), better samples can be obtained.</p></li>
</ul>
<p>GLIDE images generated by the prompt âa religious placeâ</p>
<p><img alt="" src="../../../_images/guidance.png" /></p>
</section>
<section id="large-guidance-weight-samplers">
<h3>Large Guidance Weight Samplers<a class="headerlink" href="#large-guidance-weight-samplers" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Imagen depends critically on classifier-free guidance for effective text conditioning.</p></li>
<li><p>Classifier-Free Guidance is a very powerful way to improve the caption alignment of generated images, but it hasÂ beenÂ previouslyÂ observedÂ that extremely high guidance weights damage fidelity by yielding saturated and unnatural images.</p></li>
<li><p>This phenomenon arises from aÂ train-test mismatch.</p></li>
<li><p>The pixel values for the training data are scaled to the range [-1, 1], butÂ high guidance weights cause the network outputs to exceed these boundsÂ at given timestep.</p></li>
<li><p>High guidance weights are found to be crucial for achieving State-of-the-Art image quality, so avoiding the problem by simply using lower guidance weights is not an option.</p></li>
</ul>
<section id="static-thresholding">
<h4>Static Thresholding<a class="headerlink" href="#static-thresholding" title="Permalink to this headline">#</a></h4>
<p>The pixel values at each timestep are clipped to the range [-1, 1]</p>
<p><img alt="" src="../../../_images/static_threshold.gif" /></p>
</section>
<section id="dynamic-thresholding">
<h4>Dynamic Thresholding<a class="headerlink" href="#dynamic-thresholding" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>A certain percentile absolute pixel value is chosen.</p></li>
<li><p>At each timestep, if that percentile valueÂ sÂ exceeds 1, then the pixel values are thresholded to [-s,Â s] and divided byÂ s.</p></li>
</ul>
<p><img alt="" src="../../../_images/dynamic_threshold.gif" /></p>
</section>
<section id="comparison">
<h4>Comparison<a class="headerlink" href="#comparison" title="Permalink to this headline">#</a></h4>
<p>The effects of increasing the guidance weight for three models</p>
<p><img alt="" src="../../../_images/threshold_comparison.png" /></p>
</section>
</section>
<section id="super-resolution-models">
<h3>Super-Resolution Models<a class="headerlink" href="#super-resolution-models" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Diffusion Model (or âbase modelâ) outputs 64x64 images.</p></li>
<li><p>Imagen uses two conditional diffusion models to bring the image up to 1024x1024 resolution.</p></li>
<li><p>The Small-to-Medium (STM) super-resolution model âtakes inâ (is conditioned on) the 64x64 image generated by the base model and super-resolves it to a 256x256 image.</p></li>
<li><p>The STM model is yet another diffusion model, and is also conditioned on the caption encoding in addition to the low-resolution image.</p></li>
<li><p>The Medium-to-Large (MTL) super-resolution model super-resolves the 256x256 image generated by the STM model to a 1024x1204 image.</p></li>
<li><p>The architecture is generally similar to the STM model except that the self-attention layers are removed. Since there are no self-attention layers in this model, explicit cross-attention layers are added to attend over the text embeddings in contrast to the base and STM models.</p></li>
</ul>
<section id="robust-cascaded-diffusion-models">
<h4>Robust Cascaded Diffusion Models<a class="headerlink" href="#robust-cascaded-diffusion-models" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Imagen uses noise conditioning augmentation in the super-resolution models in order to make them aware of the amount of noise added.</p></li>
<li><p>This conditioning improves sample quality and the ability of the models to handle artifacts resulting from the lower resolution models.</p></li>
<li><p>TheÂ authors find this approach to be critical for generating high fidelity images.</p></li>
</ul>
<p><img alt="" src="../../../_images/conditioning_augmentation.png" /></p>
</section>
</section>
<section id="results-and-analysis">
<h3>Results and Analysis<a class="headerlink" href="#results-and-analysis" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Quantitative</p>
<ul>
<li><p>COCO is a dataset used to evaluate text-to-image models, with FID used to measure image fidelity and CLIP used to measure image-caption alignment.</p></li>
<li><p>The authors find thatÂ Imagen achieves a State-of-the-Art zero-shot FID of 7.27Â on COCO, outperforming DALL-E 2 and even models that wereÂ trainedÂ on COCO.</p></li>
</ul>
</li>
<li><p>Qualitative</p>
<ul>
<li><p>Quality:Â âWhich image is more photorealistic (looks more real)?â</p></li>
<li><p>Imagen achieves a preference rate of 39.2% for photorealism.</p></li>
<li><p>Caption Similarity: âDoes the caption accurately describe the above image?â</p></li>
<li><p>Imagen is on-par with original reference images for caption similarity.</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>DrawBench</p>
<ul>
<li><p>a comprehensive and challenging set of prompts that is intended to support the evaluation and comparison of text-to-image models.</p></li>
</ul>
</li>
</ul>
<p><img alt="" src="../../../_images/drabench.png" /></p>
</section>
<section id="why-is-imagen-better-than-dall-e-2">
<h3>Why is Imagen Better than DALL-E 2?<a class="headerlink" href="#why-is-imagen-better-than-dall-e-2" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>DALL-E 2 uses a contrastive objective to determine how related a text encoding is to an image (essentially CLIP). The text and image encoders tune their parameters such that the cosine similarities of like caption-image pairs are maximized, while the cosine similarities of differing caption-image pairs are minimized.</p></li>
<li><p>Sheer Size</p></li>
<li><p>The effect of scaling up the text encoder is shockingly high, and that of scaling up the U-Net is shockingly low.</p></li>
</ul>
<p><img alt="" src="../../../_images/encoder-unet-size.png" /></p>
<ul class="simple">
<li><p>The Image Encoder Crutch</p>
<ul>
<li><p>During CLIP training, both the text encoder and image encoder are tuned to satisfy the demands of the objective function.</p></li>
<li><p>The image encoder in CLIP learns to produce richer encodings more quickly than the text encoder, adapting to the relatively lower performance of the text encoder.</p></li>
</ul>
</li>
<li><p>Similar Concepts in Different Data Points</p></li>
<li><p>The potential shortcoming of the CLIP text-encoding method is that the blanket objective of maximizing the cosine similarity of corresponding caption-image pairs while minimizing that of differing onesÂ does not account for similar concepts in distinct data points.</p></li>
</ul>
</section>
</section>
<section id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Scaling the text encoder is very effective</p></li>
<li><p>Scaling the text encoder is more important than U-Net size</p></li>
<li><p>Dynamic thresholding is critical</p></li>
<li><p>Noise conditioning augmentation in the super-resolution models is critical</p></li>
<li><p>Text conditioning via cross attention is critical</p></li>
<li><p>Efficient U-Net is critical</p></li>
</ul>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://imagen.research.google/">Imagen</a></p></li>
<li><p><a class="reference external" href="https://www.assemblyai.com/blog/how-imagen-actually-works/">How Imagen Actually Works</a></p></li>
<li><p><a class="reference external" href="https://www.assemblyai.com/blog/minimagen-build-your-own-imagen-text-to-image-model/">MinImagen</a></p></li>
</ul>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/lectures/aiart"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="dalle2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">DALLÂ·E 2</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../mlops/index.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Machine Learning Systems Design</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Young Joon Lee<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>