{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfdc61fb",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "![](../figs/intro_nlp/tokenization/entelecheia_puzzle_pieces.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d50cc3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "NLP systems have three main components that help machines understand natural language:\n",
    "\n",
    "- **Tokenization**: Splitting a string into a list of tokens.\n",
    "- **Embedding**: Mapping tokens to vectors.\n",
    "- **Model**: A neural network that takes token vectors as input and outputs predictions.\n",
    "\n",
    "Tokenization is the first step in the NLP pipeline. \n",
    "\n",
    "- Tokenization is the process of splitting a string into a list of tokens. \n",
    "- For example, the sentence \"I like to eat apples\" can be tokenized into the list of tokens `[\"I\", \"like\", \"to\", \"eat\", \"apples\"]`. \n",
    "- The tokens can be words, characters, or subwords."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39810160",
   "metadata": {},
   "source": [
    "## What is Tokenization?\n",
    "\n",
    "- Tokenization is the process of representing a text in smaller units called tokens.\n",
    "- In a very simple case, we can simply map every word in the text to a numerical index.\n",
    "- For example, the sentence \"I like to eat apples\" can be tokenized into the list of tokens:\n",
    "  > `[\"I\", \"like\", \"to\", \"eat\", \"apples\"]`. \n",
    "- Then, each token can be mapped to a unique index, such as:\n",
    "  > `{\"I\": 0, \"like\": 1, \"to\": 2, \"eat\": 3, \"apples\": 4}`.\n",
    "- There are more linguistic features to consider when tokenizing a text, such as punctuation, capitalization, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609cc5c5",
   "metadata": {},
   "source": [
    "## Why do we need tokenization?\n",
    "\n",
    "- \"How can we make a machine read a sentence?\"\n",
    "- Machines donâ€™t know any language, nor do they understand sounds or phonetics.\n",
    "- They need to be taught from scratch.\n",
    "- The first step is to break down the sentence into smaller units that the machine can process.\n",
    "- Tokenization determines how the input is represented to the model.\n",
    "- This decision has a huge impact on the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29cf2e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
