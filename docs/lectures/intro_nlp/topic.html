
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Topic Modeling &#8212; eKorpkit Tutorials</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/ekorpkit.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Topic Models" href="topic_models.html" />
    <link rel="prev" title="Research Applications" href="research.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-FN4GFT8HP8"></script>
<script>
                    window.dataLayer = window.dataLayer || [];
                    function gtag(){ dataLayer.push(arguments); }
                    gtag('js', new Date());
                    gtag('config', 'G-FN4GFT8HP8');
                </script>

  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/ekorpkit.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">eKorpkit Tutorials</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../intro.html">
                    eKonomic Research Python Toolkit
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Basics
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basics/index.html">
   Getting started
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/install.html">
     Installation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/usage.html">
     Usage
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../basics/features/index.html">
   Key features
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/easy_config.html">
     Easy Configuration
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/no_boiler.html">
     No Boilerplate
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/workflows.html">
     Workflows
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/share.html">
     Sharable and Reproducible
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../basics/features/plug.html">
     Pluggable Architece
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tutorials
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/config/index.html">
   Configuring ekorpkit
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/config/eKonf.html">
     Using eKonf class
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/datasets/index.html">
   Datasets
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/corpora/corpus.html">
     Build and Load Corpora
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/datasets/dataset.html">
     Build and Load Datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/corpora/pipeline.html">
     Corpus task pipelines
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/models/index.html">
   Models
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/models/automl/index.html">
     Auto ML
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/embeddings/index.html">
     Word Embeddings
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/embeddings/word2vec_basics.html">
       Word2Vec Basics
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/embeddings/eval_vectors.html">
       Evaluate pretrained embeddings
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/ngram/index.html">
     N-Grams
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/ngram/ngram.html">
       N-Grams
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/ngram/ngram_for_lexicons.html">
       N-Gram model for ngram lexicon features
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/ngram/ngram_for_words.html">
       N-Gram model for unigram lexicon features
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/sentiment/index.html">
     Sentiment Analyers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
    <label for="toctree-checkbox-8">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/sentiment/lbsa_en.html">
       Lexicon-based Sentiment Analysis
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/sentiment/financial_phrasebank_lm.html">
       Evaluate LM with financial phrasebank
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/sentiment/sentiment.html">
       LM Dictionary vs. finbert vs. T5
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/models/transformers/index.html">
     Transformers
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/models/art/index.html">
     AI Art (Text-to-Image)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/art/disco.html">
       Disco Diffusion
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/models/art/dalle-mini.html">
       DALL·E Mini
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/pipelines/index.html">
   Pipelines
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/pipelines/pipeline.html">
     Instantiating pipeline
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/preprocessors/index.html">
   Preprocessors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/preprocessors/normalizer/index.html">
     Normalizers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/preprocessors/normalizer/normalizer.html">
       Normalizers
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/preprocessors/segmenter/index.html">
     Segmenters
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/preprocessors/segmenter/segmenter.html">
       Segmenters
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../tutorials/preprocessors/tokenizer/index.html">
     Tokenizers
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../tutorials/preprocessors/tokenizer/mecab.html">
       Mecab Tokenizer
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../tutorials/visualizers/index.html">
   Visualizers
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../tutorials/visualizers/plot.html">
     Plots
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../tutorials/workflow/index.html">
   Workflows
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Datasets
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../corpus/ekorpkot_corpus.html">
   The eKorpkit Corpus
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Use Cases
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/fomc/index.html">
   FOMC
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/02_FOMC_numerical_data.html">
     Preparing Numerical Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/03_FOMC_corpus.html">
     Preparing Textual Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/04_FOMC_EDA_numericals.html">
     EDA on Numerical Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/05_FOMC_features.html">
     Visualizing Features
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/06_FOMC_AutoML.html">
     Checking Baseline with AutoML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/07_FOMC_sentiments.html">
     Predicting Sentiments of FOMC Corpus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/08_FOMC_EDA_sentiments.html">
     EDA on Sentiment Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/fomc/09_FOMC_AutoML_with_tones.html">
     Predicting the next decisions with tones
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../usecases/bok/index.html">
   Bank of Korea
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/edgar/index.html">
   EDGAR
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
  <label for="toctree-checkbox-17">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/edgar/predict_edgar.html">
     Prediciting Sentiments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/esg/index.html">
   ESG
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
  <label for="toctree-checkbox-18">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/snorkel-polarity.html">
     Preparing polarity classification datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/rubrix.html">
     Improving classification datasets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/classifiers.html">
     Training Classifiers for ESG Ratings
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/econ_news_corpus.html">
     Building
     <code class="docutils literal notranslate">
      <span class="pre">
       econ_news_kr
      </span>
     </code>
     corpus
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/predict_news.html">
     Predicting ESG Categories and Polarities
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/rubrix_classifiers.html">
     Preparing classifiers for active learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg/predict_for_learning.html">
     Preparing active learning data
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/esg-en/index.html">
   ESG (English)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
  <label for="toctree-checkbox-19">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/esg-en/esg_corpus.html">
     Building
     <code class="docutils literal notranslate">
      <span class="pre">
       JOCo
      </span>
     </code>
     corpus
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../usecases/cointax/index.html">
   Taxation on Cryptocurrency
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
  <label for="toctree-checkbox-20">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../usecases/cointax/coin_dataset.html">
     Improving classification datasets
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Research
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../research/esg_topics/analyst.html">
   ESG Topic Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../research/esg_topics/rethink_esg.html">
   Rethinking ESG
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Lectures
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="index.html">
   Introduction to NLP
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
  <label for="toctree-checkbox-21">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="ekorpkit.html">
     Getting started with ekorpkit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="research.html">
     Research Applications
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Topic Modeling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="topic_models.html">
     Topic Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="topic_coherence.html">
     Topic Coherence Measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sentiments.html">
     Sentiment Analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../deep_nlp/index.html">
   Deep Learning for NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
  <label for="toctree-checkbox-22">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/ekorpkit.html">
     Getting started with ekorpkit
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/zeroshot.html">
     Zero Shot, Prompt, and Search Strategies
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/bloom.html">
     What is BLOOM?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/bloom_apps.html">
     Bloom Examples
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/transformers.html">
     Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/bert.html">
     BERT: Bidirectional Encoder Representations from Transformers
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../deep_nlp/t5.html">
     T5: Text-To-Text Transfer Transformer
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../aiart/index.html">
   AI Art (Text-to-Image)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
  <label for="toctree-checkbox-23">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../aiart/intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../aiart/project-themes.html">
     Project Themes - A Brave New World
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../aiart/dalle1.html">
     DALL·E 1
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../aiart/dalle2.html">
     DALL·E 2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../aiart/imagen.html">
     Imagen
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../mlops/index.html">
   Machine Learning Systems Design
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../ds/index.html">
   Data Science for Economics and Finance
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  About
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/index.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../about/cite.html">
   Citation
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/entelecheia/ekorpkit-book/main?urlpath=tree/ekorpkit-book/docs/lectures/intro_nlp/topic.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/entelecheia/ekorpkit-book/blob/main/ekorpkit-book/docs/lectures/intro_nlp/topic.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/entelecheia/ekorpkit-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/entelecheia/ekorpkit-book/issues/new?title=Issue%20on%20page%20%2Fdocs/lectures/intro_nlp/topic.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/docs/lectures/intro_nlp/topic.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topic-models">
   Topic Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#latent-dirichlet-allocation-lda">
   Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-negative-matrix-factorization-nmf">
   Non-negative Matrix Factorization (NMF)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topic-modeling-example-using-nmf-and-svd">
   Topic Modeling Example using NMF and SVD
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-problem">
     The problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation">
     Motivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stopwords-stemming-lemmatization">
     Stopwords, stemming, lemmatization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stopwords">
       Stopwords
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stemming-and-lemmatization">
       Stemming and Lemmatization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-processing">
     Data Processing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#singular-value-decomposition-svd">
     Singular Value Decomposition (SVD)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Non-negative Matrix Factorization (NMF)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nmf-applications">
       NMF Applications
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nmf-from-sklearn">
       NMF from sklearn
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nmf-in-summary">
       NMF in summary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#truncated-svd">
     Truncated SVD
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#shortcomings-of-classical-algorithms-for-decomposition">
       Shortcomings of classical algorithms for decomposition:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#advantages-of-randomized-algorithms">
       Advantages of randomized algorithms:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#timing-comparison">
       Timing comparison
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#document-clustering">
   Document Clustering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cosine-similarity">
     Cosine Similarity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cosine-similarity-example">
     Cosine Similarity Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dimensionality-reduction">
     Dimensionality Reduction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#swiss-roll-reduction-with-lle">
     Swiss Roll reduction with LLE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca-principal-component-analysis-svd-singular-value-decompositio">
     PCA (principal component analysis) / SVD (singular value decompositio)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca-nmf-for-dimension-reduction">
     PCA/NMF for Dimension Reduction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-means-clustering">
     k-means clustering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-clustering-algorithms">
     Other clustering algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Topic Modeling</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topic-models">
   Topic Models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#latent-dirichlet-allocation-lda">
   Latent Dirichlet Allocation (LDA)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#non-negative-matrix-factorization-nmf">
   Non-negative Matrix Factorization (NMF)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#topic-modeling-example-using-nmf-and-svd">
   Topic Modeling Example using NMF and SVD
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-problem">
     The problem
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#motivation">
     Motivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stopwords-stemming-lemmatization">
     Stopwords, stemming, lemmatization
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stopwords">
       Stopwords
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stemming-and-lemmatization">
       Stemming and Lemmatization
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#data-processing">
     Data Processing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#singular-value-decomposition-svd">
     Singular Value Decomposition (SVD)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Non-negative Matrix Factorization (NMF)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nmf-applications">
       NMF Applications
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nmf-from-sklearn">
       NMF from sklearn
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#nmf-in-summary">
       NMF in summary
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#truncated-svd">
     Truncated SVD
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#shortcomings-of-classical-algorithms-for-decomposition">
       Shortcomings of classical algorithms for decomposition:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#advantages-of-randomized-algorithms">
       Advantages of randomized algorithms:
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#timing-comparison">
       Timing comparison
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#document-clustering">
   Document Clustering
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cosine-similarity">
     Cosine Similarity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#cosine-similarity-example">
     Cosine Similarity Example
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#dimensionality-reduction">
     Dimensionality Reduction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#swiss-roll-reduction-with-lle">
     Swiss Roll reduction with LLE
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca-principal-component-analysis-svd-singular-value-decompositio">
     PCA (principal component analysis) / SVD (singular value decompositio)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca-nmf-for-dimension-reduction">
     PCA/NMF for Dimension Reduction
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#k-means-clustering">
     k-means clustering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#other-clustering-algorithms">
     Other clustering algorithms
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="topic-modeling">
<h1>Topic Modeling<a class="headerlink" href="#topic-modeling" title="Permalink to this headline">#</a></h1>
<p><img alt="" src="../../../_images/entelecheia_grouping.png" /></p>
<section id="topic-models">
<h2>Topic Models<a class="headerlink" href="#topic-models" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>summarize unstructured text</p></li>
<li><p>use words within document to infer subject</p></li>
<li><p>useful for dimension reduction</p></li>
<li><p>topic models are more interpretable than other dimension reduction methods, such as PCA.</p></li>
</ul>
</section>
<section id="latent-dirichlet-allocation-lda">
<h2>Latent Dirichlet Allocation (LDA)<a class="headerlink" href="#latent-dirichlet-allocation-lda" title="Permalink to this headline">#</a></h2>
<p><img alt="" src="../../../_images/14.png" /></p>
<p><code class="docutils literal notranslate"><span class="pre">Latent</span></code> means hidden, <code class="docutils literal notranslate"><span class="pre">Dirichlet</span></code> is a type of probability distribution. Latent Dirichlet Allocation means that we are trying to find all the probability distributions and they are hidden.</p>
<p>Latent Dirichlet Allocation (LDA):</p>
<ul class="simple">
<li><p>Each topic is a distribution over words.</p></li>
<li><p>Each document is a distribution over topics.</p></li>
</ul>
<p>Input: <span class="math notranslate nohighlight">\(N \times M\)</span> document-term count matrix <span class="math notranslate nohighlight">\(X\)</span></p>
<p>Assume: there are <span class="math notranslate nohighlight">\(K\)</span> topics (tunable hyperparameter, use coherence).</p>
<p>Like PCA or NMF, LDA works by factorizing <span class="math notranslate nohighlight">\(X\)</span> into:</p>
<ul class="simple">
<li><p>an <span class="math notranslate nohighlight">\(N \times K\)</span> document-topic matrix</p></li>
<li><p>an <span class="math notranslate nohighlight">\(K \times M\)</span> topic-term matrix</p></li>
</ul>
<p>When we fit these 4 questions to LDA, it will give us back something like this:</p>
<p><img alt="" src="../../../_images/161.png" /></p>
<p>The 1st question is 100% of Topic A, the 3rd question is 100% of Topic B, and the last question is split of Topic A and Topic B.</p>
<p>The word “football” has the highest weight in Topic A, followed by “NFL” followed by “player”. So we could infer that this topic is about sport.</p>
<p>The word “politics” has the highest weight in Topic B, followed by “leader”, followed by “world”. So we could infer that this topic is about politics. As shown below:</p>
<ul class="simple">
<li><p>Topic A: 40% football, 30% NFL, 10% player … Sport</p></li>
<li><p>Topic B: 30% political, 20% leader, 10% world … Politics</p></li>
</ul>
<p>Then we go back to our original questions, here are the topics!</p>
<p><img alt="" src="../../../_images/171.png" /></p>
<p>To dive a little deeper, every questions is a mix of topics, and every topic is a mix of words.</p>
<p><img alt="" src="../../../_images/181.png" /></p>
<p>A question is a probability distribution of topics, and every topic is a probability distribution of words.</p>
<p>What LDA does is that when you fit it with all those questions, it is trying its best to find the best topic mix and the best word mix.</p>
</section>
<section id="non-negative-matrix-factorization-nmf">
<h2>Non-negative Matrix Factorization (NMF)<a class="headerlink" href="#non-negative-matrix-factorization-nmf" title="Permalink to this headline">#</a></h2>
<p>We take the term-document matrix, decompose to two matrices, first one has every topic and what terms in it, and 2nd one has every document and what topics in it.</p>
<p><img alt="" src="../../../_images/191.png" /></p>
<p>On the left we have 3 questions, on the right we have term-document matrix for these 3 questions. We choose k=2 topics.</p>
<p><img alt="" src="../../../_images/20.png" /></p>
<p>After decomposition, we got two non-negative matrices of the original n words by k topics and those same k topics by the m original documents.</p>
<p><img alt="" src="../../../_images/211.png" /></p>
</section>
<section id="topic-modeling-example-using-nmf-and-svd">
<h2>Topic Modeling Example using NMF and SVD<a class="headerlink" href="#topic-modeling-example-using-nmf-and-svd" title="Permalink to this headline">#</a></h2>
<section id="the-problem">
<h3>The problem<a class="headerlink" href="#the-problem" title="Permalink to this headline">#</a></h3>
<p><strong>term-document matrix</strong>:</p>
<p>We can decompose this into one tall thin matrix times one wide short matrix (possibly with a diagonal matrix in between).</p>
<p>Notice that this representation does not take into account word order or sentence structure.  It’s an example of a <strong>bag of words</strong> approach.</p>
<p><img alt="" src="../../../_images/document_term.png" /></p>
<p>source: <a class="reference external" href="http://player.slideplayer.com/15/4528582/">Introduction to Information Retrieval</a></p>
</section>
<section id="motivation">
<h3>Motivation<a class="headerlink" href="#motivation" title="Permalink to this headline">#</a></h3>
<p>Consider the most extreme case - reconstructing the matrix using an outer product of two vectors. Clearly, in most cases we won’t be able to reconstruct the matrix exactly. But if we had one vector with the relative frequency of each vocabulary word out of the total word count, and one with the average number of words per document, then that outer product would be as close as we can get.</p>
<p>Now consider increasing that matrices to two columns and two rows. The optimal decomposition would now be to cluster the documents into two groups, each of which has as different a distribution of words as possible to each other, but as similar as possible amongst the documents in the cluster. We will call those two groups “topics”. And we would cluster the words into two groups, based on those which most frequently appear in each of the topics.</p>
<p>We’ll take a dataset of documents in several different categories, and find topics (consisting of groups of words) for them.  Knowing the actual categories helps us evaluate if the topics we find make sense.</p>
<p>We will try this with two different matrix factorizations: <strong>Singular Value Decomposition (SVD)</strong> and <strong>Non-negative Matrix Factorization (NMF)</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/datasets/twenty_newsgroups.html">Data source</a>: Newsgroups are discussion groups on Usenet, which was popular in the 80s and 90s before the web really took off.  This dataset includes 18,000 newsgroups posts with 20 topics.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format=&#39;retina&#39;
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_20newsgroups</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">decomposition</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">linalg</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;wordnet&#39;</span><span class="p">)</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;omw-1.4&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package stopwords to /root/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to /root/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
[nltk_data] Downloading package omw-1.4 to /root/nltk_data...
[nltk_data]   Package omw-1.4 is already up-to-date!
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;alt.atheism&#39;</span><span class="p">,</span> <span class="s1">&#39;talk.religion.misc&#39;</span><span class="p">,</span> <span class="s1">&#39;comp.graphics&#39;</span><span class="p">,</span> <span class="s1">&#39;sci.space&#39;</span><span class="p">]</span>
<span class="n">remove</span> <span class="o">=</span> <span class="p">(</span><span class="s1">&#39;headers&#39;</span><span class="p">,</span> <span class="s1">&#39;footers&#39;</span><span class="p">,</span> <span class="s1">&#39;quotes&#39;</span><span class="p">)</span>
<span class="n">newsgroups_train</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="n">remove</span><span class="p">)</span>
<span class="n">newsgroups_test</span> <span class="o">=</span> <span class="n">fetch_20newsgroups</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">categories</span><span class="o">=</span><span class="n">categories</span><span class="p">,</span> <span class="n">remove</span><span class="o">=</span><span class="n">remove</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">filenames</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((2034,), (2034,))
</pre></div>
</div>
</div>
</div>
<p>Let’s look at some of the data.  Can you guess which category these messages are in?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="mi">2</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hi,

I&#39;ve noticed that if you only save a model (with all your mapping planes
positioned carefully) to a .3DS file that when you reload it after restarting
3DS, they are given a default position and orientation.  But if you save
to a .PRJ file their positions/orientation are preserved.  Does anyone
know why this information is not stored in the .3DS file?  Nothing is
explicitly said in the manual about saving texture rules in the .PRJ file. 
I&#39;d like to be able to read the texture rule information, does anyone have 
the format for the .PRJ file?

Is the .CEL file format available from somewhere?

Rych


Seems to be, barring evidence to the contrary, that Koresh was simply
another deranged fanatic who thought it neccessary to take a whole bunch of
folks with him, children and all, to satisfy his delusional mania. Jim
Jones, circa 1993.


Nope - fruitcakes like Koresh have been demonstrating such evil corruption
for centuries.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target_names</span><span class="p">)[</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">3</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;comp.graphics&#39;, &#39;talk.religion.misc&#39;, &#39;sci.space&#39;], dtype=&#39;&lt;U18&#39;)
</pre></div>
</div>
</div>
</div>
<p>The target attribute is the integer index of the category.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">target</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_topics</span><span class="p">,</span> <span class="n">num_top_words</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="stopwords-stemming-lemmatization">
<h3>Stopwords, stemming, lemmatization<a class="headerlink" href="#stopwords-stemming-lemmatization" title="Permalink to this headline">#</a></h3>
<section id="stopwords">
<h4>Stopwords<a class="headerlink" href="#stopwords" title="Permalink to this headline">#</a></h4>
<p>From <a class="reference external" href="https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html">Intro to Information Retrieval</a>:</p>
<p><em>Some extremely common words which would appear to be of little value in helping select documents matching a user need are excluded from the vocabulary entirely. These words are called stop words.</em></p>
<p><em>The general trend in IR systems over time has been from standard use of quite large stop lists (200-300 terms) to very small stop lists (7-12 terms) to no stop list whatsoever. Web search engines generally do not use stop lists.</em></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>

<span class="n">STOPWORDS</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">STOPWORDS</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">STOPWORDS</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>179
[&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &quot;you&#39;re&quot;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="stemming-and-lemmatization">
<h4>Stemming and Lemmatization<a class="headerlink" href="#stemming-and-lemmatization" title="Permalink to this headline">#</a></h4>
<p>from <a class="reference external" href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">Information Retrieval</a> textbook:</p>
<p>Are the below words the same?</p>
<p><em>organize, organizes, and organizing</em></p>
<p><em>democracy, democratic, and democratization</em></p>
<p>Stemming and Lemmatization both generate the root form of the words.</p>
<p>Lemmatization uses the rules about a language.  The resulting tokens are all actual words</p>
<p>“Stemming is the poor-man’s lemmatization.” (Noah Smith, 2011) Stemming is a crude heuristic that chops the ends off of words.  The resulting tokens may not be actual words. Stemming is faster.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nltk</span> <span class="kn">import</span> <span class="n">stem</span>

<span class="n">wnl</span> <span class="o">=</span> <span class="n">stem</span><span class="o">.</span><span class="n">WordNetLemmatizer</span><span class="p">()</span>
<span class="n">porter</span> <span class="o">=</span> <span class="n">stem</span><span class="o">.</span><span class="n">porter</span><span class="o">.</span><span class="n">PorterStemmer</span><span class="p">()</span>

<span class="n">word_list</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;feet&#39;</span><span class="p">,</span> <span class="s1">&#39;foot&#39;</span><span class="p">,</span> <span class="s1">&#39;foots&#39;</span><span class="p">,</span> <span class="s1">&#39;footing&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">wnl</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_list</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;foot&#39;, &#39;foot&#39;, &#39;foot&#39;, &#39;footing&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">porter</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">word_list</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;feet&#39;, &#39;foot&#39;, &#39;foot&#39;, &#39;foot&#39;]
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="data-processing">
<h3>Data Processing<a class="headerlink" href="#data-processing" title="Permalink to this headline">#</a></h3>
<p>Next, scikit learn has a method that will extract all the word counts for us.  In the next lesson, we’ll learn how to write our own version of CountVectorizer, to see what’s happening underneath the hood.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span><span class="p">,</span> <span class="n">TfidfVectorizer</span>

<span class="n">vectorizer</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">stop_words</span><span class="o">=</span><span class="s1">&#39;english&#39;</span><span class="p">)</span> <span class="c1">#, tokenizer=LemmaTokenizer())</span>

<span class="n">vectors</span> <span class="o">=</span> <span class="n">vectorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">todense</span><span class="p">()</span> <span class="c1"># (documents, vocab)</span>

<span class="nb">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">newsgroups_train</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2034 (2034, 26576)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">vectorizer</span><span class="o">.</span><span class="n">get_feature_names_out</span><span class="p">())</span>
<span class="n">vocab</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(26576,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">vocab</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;zurich&#39;, &#39;zurvanism&#39;, &#39;zus&#39;, &#39;zvi&#39;, &#39;zwaartepunten&#39;, &#39;zwak&#39;,
       &#39;zwakke&#39;, &#39;zware&#39;, &#39;zwarte&#39;, &#39;zyxel&#39;], dtype=object)
</pre></div>
</div>
</div>
</div>
</section>
<section id="singular-value-decomposition-svd">
<h3>Singular Value Decomposition (SVD)<a class="headerlink" href="#singular-value-decomposition-svd" title="Permalink to this headline">#</a></h3>
<p>We would clearly expect that the words that appear most frequently in one topic would appear less frequently in the other - otherwise that word wouldn’t make a good choice to separate out the two topics. Therefore, we expect the topics to be <strong>orthogonal</strong>.</p>
<p>The SVD algorithm factorizes a matrix into one matrix with <strong>orthogonal columns</strong> and one with <strong>orthogonal rows</strong> (along with a diagonal matrix, which contains the <strong>relative importance</strong> of each factor).</p>
<p>SVD is an <strong>exact decomposition</strong>, since the matrices it creates are big enough to fully cover the original matrix. SVD is extremely widely used in linear algebra, and specifically in data science, including:</p>
<ul class="simple">
<li><p>semantic analysis</p></li>
<li><p>collaborative filtering/recommendations (<a class="reference external" href="https://datajobs.com/data-science-repo/Recommender-Systems-%5BNetflix%5D.pdf">winning entry for Netflix Prize</a>)</p></li>
<li><p>calculate Moore-Penrose pseudoinverse</p></li>
<li><p>data compression</p></li>
<li><p>principal component analysis</p></li>
</ul>
<p><img alt="" src="../../../_images/svd_fb.png" /></p>
<p>(source: <a class="reference external" href="https://research.fb.com/fast-randomized-svd/">Facebook Research: Fast Randomized SVD</a>)</p>
<p>Latent Semantic Analysis (LSA) uses SVD.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span> 
<span class="n">U</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">Vh</span> <span class="o">=</span> <span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 24min 42s, sys: 28min 17s, total: 52min 59s
Wall time: 25.7 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">U</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">s</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">Vh</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(2034, 2034) (2034,) (2034, 26576)
</pre></div>
</div>
</div>
</div>
<p>What can we say about the singular values s?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/topic_42_0.png" src="../../../_images/topic_42_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">s</span><span class="p">[:</span><span class="mi">10</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/topic_43_0.png" src="../../../_images/topic_43_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_top_words</span><span class="o">=</span><span class="mi">8</span>

<span class="k">def</span> <span class="nf">show_topics</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>
    <span class="n">top_words</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">t</span><span class="p">)[:</span><span class="o">-</span><span class="n">num_top_words</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="n">topic_words</span> <span class="o">=</span> <span class="p">([</span><span class="n">top_words</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">a</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">t</span><span class="p">)</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">topic_words</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show_topics</span><span class="p">(</span><span class="n">Vh</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;critus ditto propagandist surname galacticentric kindergarten surreal imaginative&#39;,
 &#39;jpeg gif file color quality image jfif format&#39;,
 &#39;graphics edu pub mail 128 3d ray ftp&#39;,
 &#39;jesus god matthew people atheists atheism does graphics&#39;,
 &#39;image data processing analysis software available tools display&#39;,
 &#39;god atheists atheism religious believe religion argument true&#39;,
 &#39;space nasa lunar mars probe moon missions probes&#39;,
 &#39;image probe surface lunar mars probes moon orbit&#39;,
 &#39;argument fallacy conclusion example true ad argumentum premises&#39;,
 &#39;space larson image theory universe physical nasa material&#39;]
</pre></div>
</div>
</div>
</div>
<p>We get topics that match the kinds of clusters we would expect! This is despite the fact that this is an <strong>unsupervised algorithm</strong> - which is to say, we never actually told the algorithm how our documents are grouped.</p>
</section>
<section id="id1">
<h3>Non-negative Matrix Factorization (NMF)<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>Rather than constraining our factors to be <em>orthogonal</em>, another idea would to constrain them to be <em>non-negative</em>. NMF is a factorization of a non-negative data set <span class="math notranslate nohighlight">\(V\)</span>: $<span class="math notranslate nohighlight">\( V = W H\)</span><span class="math notranslate nohighlight">\( into non-negative matrices \)</span>W,; H$. Often positive factors will be <strong>more easily interpretable</strong> (and this is the reason behind NMF’s popularity).</p>
<p>Nonnegative matrix factorization (NMF) is a non-exact factorization that factors into one skinny positive matrix and one short positive matrix.  NMF is NP-hard and non-unique.  There are a number of variations on it, created by adding different constraints.</p>
<p><img alt="" src="../../../_images/nmf_doc.png" /></p>
<p>(source: <a class="reference external" href="http://perso.telecom-paristech.fr/~essid/teach/NMF_tutorial_ICME-2014.pdf">NMF Tutorial</a>)</p>
<section id="nmf-applications">
<h4>NMF Applications<a class="headerlink" href="#nmf-applications" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p><a class="reference external" href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html#sphx-glr-auto-examples-decomposition-plot-faces-decomposition-py">Face Decompositions</a></p></li>
<li><p><a class="reference external" href="http://www.quuxlabs.com/blog/2010/09/matrix-factorization-a-simple-tutorial-and-implementation-in-python/">Collaborative Filtering, eg movie recommendations</a></p></li>
<li><p><a class="reference external" href="https://pdfs.semanticscholar.org/cc88/0b24791349df39c5d9b8c352911a0417df34.pdf">Audio source separation</a></p></li>
<li><p><a class="reference external" href="http://ieeexplore.ieee.org/document/1532909/">Chemistry</a></p></li>
<li><p><a class="reference external" href="https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-015-0485-4">Bioinformatics</a> and <a class="reference external" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2623306/">Gene Expression</a></p></li>
<li><p>Topic Modeling</p></li>
</ul>
</section>
<section id="nmf-from-sklearn">
<h4>NMF from sklearn<a class="headerlink" href="#nmf-from-sklearn" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span>
<span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">vectors</span><span class="o">.</span><span class="n">shape</span>
<span class="n">d</span> <span class="o">=</span> <span class="mi">5</span>  <span class="c1"># num topics</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">NMF</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="n">d</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">W1</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">vectors</span><span class="p">))</span>
<span class="n">H1</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">components_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 4min 4s, sys: 3min 28s, total: 7min 32s
Wall time: 3.96 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">show_topics</span><span class="p">(</span><span class="n">H1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;jpeg image gif file color images format quality&#39;,
 &#39;edu graphics pub mail 128 ray ftp send&#39;,
 &#39;space launch satellite nasa commercial satellites year market&#39;,
 &#39;jesus god people matthew atheists does atheism said&#39;,
 &#39;image data available software processing ftp edu analysis&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="nmf-in-summary">
<h4>NMF in summary<a class="headerlink" href="#nmf-in-summary" title="Permalink to this headline">#</a></h4>
<p>Benefits: Fast and easy to use!</p>
<p>Downsides: took years of research and expertise to create</p>
<p>Notes:</p>
<ul class="simple">
<li><p>For NMF, matrix needs to be at least as tall as it is wide, or we get an error with fit_transform</p></li>
<li><p>Can use df_min in CountVectorizer to only look at words that were in at least k of the split texts</p></li>
</ul>
</section>
</section>
<section id="truncated-svd">
<h3>Truncated SVD<a class="headerlink" href="#truncated-svd" title="Permalink to this headline">#</a></h3>
<p>We saved a lot of time when we calculated NMF by only calculating the subset of columns we were interested in. Is there a way to get this benefit with SVD? Yes there is! It’s called truncated SVD.  We are just interested in the vectors corresponding to the <strong>largest</strong> singular values.</p>
<section id="shortcomings-of-classical-algorithms-for-decomposition">
<h4>Shortcomings of classical algorithms for decomposition:<a class="headerlink" href="#shortcomings-of-classical-algorithms-for-decomposition" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>Matrices are “stupendously big”</p></li>
<li><p>Data are often <strong>missing or inaccurate</strong>.  Why spend extra computational resources when imprecision of input limits precision of the output?</p></li>
<li><p><strong>Data transfer</strong> now plays a major role in time of algorithms.  Techniques the require fewer passes over the data may be substantially faster, even if they require more flops (flops = floating point operations).</p></li>
<li><p>Important to take advantage of <strong>GPUs</strong>.</p></li>
</ul>
</section>
<section id="advantages-of-randomized-algorithms">
<h4>Advantages of randomized algorithms:<a class="headerlink" href="#advantages-of-randomized-algorithms" title="Permalink to this headline">#</a></h4>
<ul class="simple">
<li><p>inherently stable</p></li>
<li><p>performance guarantees do not depend on subtle spectral properties</p></li>
<li><p>needed matrix-vector products can be done in parallel</p></li>
</ul>
<p>(source: <a class="reference external" href="https://arxiv.org/abs/0909.4061">Halko</a>)</p>
</section>
<section id="timing-comparison">
<h4>Timing comparison<a class="headerlink" href="#timing-comparison" title="Permalink to this headline">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span> 
<span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">svd</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">full_matrices</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 22min 10s, sys: 36min 12s, total: 58min 23s
Wall time: 28.3 s
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%time</span> 
<span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">decomposition</span><span class="o">.</span><span class="n">randomized_svd</span><span class="p">(</span><span class="n">vectors</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>CPU times: user 1min 47s, sys: 4min 3s, total: 5min 50s
Wall time: 4.16 s
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="document-clustering">
<h2>Document Clustering<a class="headerlink" href="#document-clustering" title="Permalink to this headline">#</a></h2>
<section id="cosine-similarity">
<h3>Cosine Similarity<a class="headerlink" href="#cosine-similarity" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Representatio nof document <span class="math notranslate nohighlight">\(i\)</span> as a vector <span class="math notranslate nohighlight">\(x_i\)</span></p>
<ul>
<li><p>for example <span class="math notranslate nohighlight">\(x_i\)</span> = term counts or <span class="math notranslate nohighlight">\(x_i\)</span> = IDF-weighted term frequencies</p></li>
</ul>
</li>
<li><p>Each document is a non-negative vector in an <span class="math notranslate nohighlight">\(n_x\)</span>-space, where <span class="math notranslate nohighlight">\(n_x\)</span> = vocabulary size</p>
<ul>
<li><p>documents are rays, and similar documents have similar vectors</p></li>
</ul>
</li>
<li><p>Can measure similarity between documents <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> by the cosine of the angle between <span class="math notranslate nohighlight">\(x_i\)</span> and <span class="math notranslate nohighlight">\(x_j\)</span>:</p>
<ul>
<li><p>With perfectly collinear documents (that is, <span class="math notranslate nohighlight">\(x_i = α x_j\)</span>, <span class="math notranslate nohighlight">\(α \gt 0\)</span>), <span class="math notranslate nohighlight">\(cos(0) = 1\)</span></p></li>
<li><p>For orthogonal documents (no words in common), <span class="math notranslate nohighlight">\(cos(\pi/2)=0\)</span></p></li>
</ul>
</li>
</ul>
<ul>
<li><p>Cosine similarity is computable as the normalized dot product between the vectors:</p>
<p><span class="math notranslate nohighlight">\( cos\_sim(x_1,x_2) = \frac{x_1 \cdot x_2}{\|x_1\|\|x_2\|}\)</span></p>
</li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics.pairwise</span> <span class="kn">import</span> <span class="n">cosine_similarity</span>
<span class="c1"># between two vectors:</span>
<span class="n">sim</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="c1"># between all rows of a matrix:</span>
<span class="n">sims</span> <span class="o">=</span> <span class="n">cosine_similarity</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="cosine-similarity-example">
<h3>Cosine Similarity Example<a class="headerlink" href="#cosine-similarity-example" title="Permalink to this headline">#</a></h3>
<p><img alt="" src="../../../_images/210.png" /></p>
<p><img alt="" src="../../../_images/3-800x852.png" /></p>
</section>
<section id="dimensionality-reduction">
<h3>Dimensionality Reduction<a class="headerlink" href="#dimensionality-reduction" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Datasets are not distributed uniformly across the feature space.</p></li>
<li><p>They have a lower-dimensional latent structure – a manifold – that can be learned.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Dimensonality</span> <span class="pre">reduction</span></code> makes data more interpretable – for example by projecting down to two dimensions for visualization.</p></li>
<li><p>improves computational tractability.</p></li>
<li><p>can improve model performance.</p></li>
</ul>
</section>
<section id="swiss-roll-reduction-with-lle">
<h3>Swiss Roll reduction with LLE<a class="headerlink" href="#swiss-roll-reduction-with-lle" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">config</span> InlineBackend.figure_format=&#39;retina&#39;
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span>

<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">manifold</span><span class="p">,</span> <span class="n">datasets</span>

<span class="n">X</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_swiss_roll</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1500</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Computing LLE embedding&quot;</span><span class="p">)</span>
<span class="n">X_r</span><span class="p">,</span> <span class="n">err</span> <span class="o">=</span> <span class="n">manifold</span><span class="o">.</span><span class="n">locally_linear_embedding</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done. Reconstruction error: </span><span class="si">%g</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">err</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Computing LLE embedding
Done. Reconstruction error: 1.23163e-07
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>

<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s2">&quot;3d&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Original data&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_r</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_r</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">Spectral</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;tight&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([]),</span> <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">([])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Projected data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/topic_65_0.png" src="../../../_images/topic_65_0.png" />
</div>
</div>
</section>
<section id="pca-principal-component-analysis-svd-singular-value-decompositio">
<h3>PCA (principal component analysis) / SVD (singular value decompositio)<a class="headerlink" href="#pca-principal-component-analysis-svd-singular-value-decompositio" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>PCA computes the dimension in data explaining most variance.</p></li>
<li><p>after the first component, subsequent components learn the (orthogonal) dimensions explaining most variance in dataset after projecting out first component.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">X_train_pca</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
<p><img alt="" src="../../../_images/81.png" /></p>
<p><img alt="" src="../../../_images/91.png" /></p>
</section>
<section id="pca-nmf-for-dimension-reduction">
<h3>PCA/NMF for Dimension Reduction<a class="headerlink" href="#pca-nmf-for-dimension-reduction" title="Permalink to this headline">#</a></h3>
<p>Data can be reduced by projecting down to first principal component dimensions.</p>
<ul class="simple">
<li><p>Distance metrics between observations (e.g. cosine similarity) are approximately preserved.</p></li>
<li><p>For supervised learning, reduced matrix be used as predictors instead of the original matrix.</p>
<ul>
<li><p>but might destroy (a lot of) predictive information in your dataset.</p></li>
<li><p>compromise: use feature selection to keep strong predictors, and take principal components of weak predictors.</p></li>
</ul>
</li>
<li><p>PCA dimensions are not interpretable.</p></li>
<li><p>For non-negative data (e.g. counts or frequencies), Non-negative Matrix Factorization (NMF) provides more interpretable factors than PCA.</p></li>
</ul>
</section>
<section id="k-means-clustering">
<h3>k-means clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Matrix of predictors treated as a Euclidean space (should standardize all columns)</p></li>
<li><p>algorithm: initialize cluster centroids randomly, then shift around to minimize sum of within-cluster squared distance</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">Kmeans</span>
<span class="n">kmeans</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">kmeans</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">assigned_cluster</span> <span class="o">=</span> <span class="n">kmeans</span><span class="o">.</span><span class="n">labels_</span>
</pre></div>
</div>
<p><img alt="" src="../../../_images/101.png" /></p>
<p><img alt="" src="../../../_images/111.png" /></p>
</section>
<section id="other-clustering-algorithms">
<h3>Other clustering algorithms<a class="headerlink" href="#other-clustering-algorithms" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>“k-medoid” clustering use L1 distance rather than Euclidean distance; produces the “medoid” (median vector) for each cluster rather than “centroid” (mean vector).</p>
<ul>
<li><p>less sensitive to outliers, and medoid can be used as representative data point.</p></li>
</ul>
</li>
<li><p>DBSCAN defines clusters as continous regions of high density.</p>
<ul>
<li><p>detects and excludes outliers automatically</p></li>
</ul>
</li>
<li><p>Agglomerative (hierarchical) clustering makes nested clusters.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs/lectures/intro_nlp"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="research.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Research Applications</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="topic_models.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Topic Models </p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Young Joon Lee<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>